{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cec6769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 09:06:40.517545: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-24 09:06:40.669635: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-24 09:06:40.674771: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-24 09:06:40.674792: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-24 09:06:41.357827: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-24 09:06:41.357937: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-24 09:06:41.357945: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# basic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# gnn and train\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_gnn as tfgnn\n",
    "from tensorflow_gnn.models import gat_v2, graph_sage\n",
    "\n",
    "# demo\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8edf1b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fp = './tfgnn_dataset/nexmark_isBP_train.tfrecord'\n",
    "# val_fp = './tfgnn_dataset/nexmark_isBP_val.tfrecord'\n",
    "# test_fp = './tfgnn_dataset/nexmark_isBP_test.tfrecord'\n",
    "# schema_fp = './tfgnn_dataset/schema_poc.pbtxt'\n",
    "\n",
    "train_fp = './tfgnn_dataset/nexmark_isBP_train_fixed.tfrecord'\n",
    "val_fp = './tfgnn_dataset/nexmark_isBP_val_fixed.tfrecord'\n",
    "test_fp = './tfgnn_dataset/nexmark_isBP_test_fixed.tfrecord'\n",
    "schema_fp = './tfgnn_dataset/schema_poc.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ee7f0af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset of tf.Example protos for training.\n",
    "train_ds = tf.data.TFRecordDataset(filenames=[train_fp])\n",
    "val_ds = tf.data.TFRecordDataset(filenames=[val_fp])\n",
    "test_ds = tf.data.TFRecordDataset(filenames=[test_fp])\n",
    "# Parse the GraphTensor values.\n",
    "graph_schema = tfgnn.read_schema(schema_fp)\n",
    "example_input_spec = tfgnn.create_graph_spec_from_schema_pb(graph_schema) # spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "438e02bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_fn(serialized):\n",
    "    return tfgnn.parse_single_example(example_input_spec, serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9eb37564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphTensorSpec({'context': ContextSpec({'features': {'label_isBP': TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), 'bytes_input_rate': TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name=None), 'records_input_rate': TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name=None)}, 'sizes': TensorSpec(shape=(None, 1), dtype=tf.int32, name=None)}, TensorShape([None]), tf.int32, None), 'node_sets': {'source': NodeSetSpec({'features': {'parallelism': RaggedTensorSpec(TensorShape([None, None, 1]), tf.float32, 1, tf.int32)}, 'sizes': TensorSpec(shape=(None, 1), dtype=tf.int32, name=None)}, TensorShape([None]), tf.int32, None), 'operate': NodeSetSpec({'features': {'parallelism': RaggedTensorSpec(TensorShape([None, None, 1]), tf.float32, 1, tf.int32), 'bytes_selectivity': RaggedTensorSpec(TensorShape([None, None, 1]), tf.float32, 1, tf.int32), 'utilization_embedding': RaggedTensorSpec(TensorShape([None, None, 6]), tf.float32, 1, tf.int32), 'records_selectivity': RaggedTensorSpec(TensorShape([None, None, 1]), tf.float32, 1, tf.int32)}, 'sizes': TensorSpec(shape=(None, 1), dtype=tf.int32, name=None)}, TensorShape([None]), tf.int32, None)}, 'edge_sets': {'src2op': EdgeSetSpec({'features': {}, 'sizes': TensorSpec(shape=(None, 1), dtype=tf.int32, name=None), 'adjacency': AdjacencySpec({'#index.0': RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int32), '#index.1': RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int32)}, TensorShape([None]), tf.int32, {'#index.0': 'source', '#index.1': 'operate'})}, TensorShape([None]), tf.int32, None), 'op2op': EdgeSetSpec({'features': {}, 'sizes': TensorSpec(shape=(None, 1), dtype=tf.int32, name=None), 'adjacency': AdjacencySpec({'#index.0': RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int32), '#index.1': RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int32)}, TensorShape([None]), tf.int32, {'#index.0': 'operate', '#index.1': 'operate'})}, TensorShape([None]), tf.int32, None)}}, TensorShape([None]), tf.int32, None)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 256\n",
    "train_ds = train_ds.map(encode_fn).shuffle(10000).batch(BATCH_SIZE)\n",
    "val_ds = val_ds.map(encode_fn).batch(BATCH_SIZE)\n",
    "test_ds = test_ds.map(encode_fn)\n",
    "\n",
    "preproc_input_spec = train_ds.element_spec\n",
    "preproc_input_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a0aa6311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pre-process model for initial hidden states, actually all partial models\n",
    "def node_sets_fn(node_set, *, node_set_name):\n",
    "    if node_set_name == 'source':\n",
    "        return node_set['parallelism']\n",
    "    elif node_set_name == 'operate':\n",
    "        stacked_non_embed = tf.keras.layers.Concatenate()([node_set['bytes_selectivity'], \n",
    "                                                           node_set['records_selectivity'], \n",
    "                                                           node_set['parallelism'],])\n",
    "        return tf.keras.layers.Concatenate()([node_set['utilization_embedding'], \n",
    "                                              stacked_non_embed,])\n",
    "\n",
    "def context_fn(context):\n",
    "    stacked_cont = tf.keras.layers.Concatenate()([context['bytes_input_rate'], \n",
    "                                                  context['records_input_rate'],],)\n",
    "    return {'hidden_state': stacked_cont,\n",
    "            'label_isBP': context['label_isBP']}\n",
    "\n",
    "def split_fn(graph):\n",
    "    labels = tfgnn.keras.layers.Readout(from_context=True, \n",
    "                                        feature_name=\"label_isBP\")(graph)\n",
    "    graph = graph.remove_features(context=['label_isBP'])\n",
    "    assert \"label_isBP\" not in graph.context.features\n",
    "    return graph, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0cb8c168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and apply the preprocessing model. (now starts to define a graph model with the view of a scalar sample)\n",
    "preproc_input = tf.keras.layers.Input(type_spec=preproc_input_spec)\n",
    "graph = tfgnn.keras.layers.MapFeatures(node_sets_fn=node_sets_fn, \n",
    "                                       context_fn=context_fn,)(preproc_input)  # With preprocessed features, see below.\n",
    "graph = graph.merge_batch_to_components()  # See section \"Merging a batch\".\n",
    "graph, labels = split_fn(graph) # See section \"Splitting the label off ...\".\n",
    "\n",
    "preproc_model = tf.keras.Model(preproc_input, (graph, labels, )) # now we defined the pp-model\n",
    "# above is just a defined computing process, the following is the process process on the whole dataset\n",
    "train_ds = train_ds.map(preproc_model)\n",
    "val_ds = val_ds.map(preproc_model)\n",
    "test_ds = test_ds.map(preproc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a11f4e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['hidden_state'], ['hidden_state'])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assert list(graph.node_sets[\"operate\"].keys()) == [tfgnn.HIDDEN_STATE]\n",
    "# BUG: not working, use manual checking:\n",
    "list(graph.node_sets['operate'].get_features_dict().keys()),list(graph.node_sets['source'].get_features_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d9473bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense(units, activation=\"relu\"):\n",
    "    \"\"\"A Dense layer with regularization (L2 and Dropout).\"\"\"\n",
    "    regularizer = tf.keras.regularizers.l2(5e-4)\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units,\n",
    "                              activation=activation,\n",
    "                              kernel_regularizer=regularizer,\n",
    "                              bias_regularizer=regularizer),\n",
    "        tf.keras.layers.Dropout(0.1)])\n",
    "\n",
    "def convolution(message_dim, receiver_tag):\n",
    "    return tfgnn.keras.layers.SimpleConv(dense(message_dim), \"mean\",\n",
    "                                         receiver_tag=receiver_tag)\n",
    "\n",
    "def next_state(next_state_dim):\n",
    "    return tfgnn.keras.layers.NextStateFromConcat(dense(next_state_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "de5f072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def MotherFuckerGraphUpdate_use(graph, units=5):\n",
    "#     graph = tfgnn.keras.layers.GraphUpdate(\n",
    "#         node_sets = {'source': tfgnn.keras.layers.NodeSetUpdate(\n",
    "#                         {'src2op': tfgnn.keras.layers.SimpleConv(tf.keras.layers.Dense(units, 'relu'), 'mean', receiver_tag=tfgnn.SOURCE), \n",
    "#                          'src2op': tfgnn.keras.layers.SimpleConv(tf.keras.layers.Dense(units, 'relu'), 'mean', receiver_tag=tfgnn.TARGET),},\n",
    "#                         tfgnn.keras.layers.NextStateFromConcat(tf.keras.layers.Dense(units, 'relu')),\n",
    "#                         context_input_feature=tfgnn.HIDDEN_STATE),\n",
    "#                      'operate': tfgnn.keras.layers.NodeSetUpdate(\n",
    "#                          {'src2op': tfgnn.keras.layers.SimpleConv(tf.keras.layers.Dense(units, 'relu'), 'mean', receiver_tag=tfgnn.SOURCE),\n",
    "#                           'src2op': tfgnn.keras.layers.SimpleConv(tf.keras.layers.Dense(units, 'relu'), 'mean', receiver_tag=tfgnn.SOURCE),\n",
    "#                           'op2op': tfgnn.keras.layers.SimpleConv(tf.keras.layers.Dense(units, 'relu'), 'mean', receiver_tag=tfgnn.TARGET),\n",
    "#                           'op2op': tfgnn.keras.layers.SimpleConv(tf.keras.layers.Dense(units, 'relu'), 'mean', receiver_tag=tfgnn.TARGET),},\n",
    "#                          tfgnn.keras.layers.NextStateFromConcat(tf.keras.layers.Dense(units, 'relu')),\n",
    "#                          context_input_feature=tfgnn.HIDDEN_STATE),},\n",
    "#         context = tfgnn.keras.layers.ContextUpdate( \n",
    "#             {'source': tfgnn.keras.layers.Pool(tfgnn.CONTEXT, 'mean'), \n",
    "#              'operate': tfgnn.keras.layers.Pool(tfgnn.CONTEXT, 'mean')},\n",
    "#             tfgnn.keras.layers.NextStateFromConcat(tf.keras.layers.Dense(units)))\n",
    "#         )(graph)\n",
    "#     return graph\n",
    "\n",
    "# def MotherFuckerGraphUpdate_use(graph, units=5):\n",
    "#     graph = tfgnn.keras.layers.GraphUpdate(\n",
    "#         node_sets = {'operate': tfgnn.keras.layers.NodeSetUpdate(\n",
    "#                          {\n",
    "# #                           'src2op': tfgnn.keras.layers.SimpleConv(tf.keras.layers.Dense(units, 'relu'), 'mean', receiver_tag=tfgnn.SOURCE),\n",
    "#                           'src2op': tfgnn.keras.layers.SimpleConv(tf.keras.layers.Dense(units, 'relu'), 'mean', receiver_tag=tfgnn.TARGET),\n",
    "# #                           'op2op': tfgnn.keras.layers.SimpleConv(tf.keras.layers.Dense(units, 'relu'), 'mean', receiver_tag=tfgnn.SOURCE),\n",
    "#                           'op2op': tfgnn.keras.layers.SimpleConv(tf.keras.layers.Dense(units, 'relu'), 'mean', receiver_tag=tfgnn.TARGET),\n",
    "#                          },\n",
    "#                          tfgnn.keras.layers.NextStateFromConcat(tf.keras.layers.Dense(units, 'relu')),\n",
    "#                          context_input_feature=tfgnn.HIDDEN_STATE),\n",
    "#                     },\n",
    "#         context = tfgnn.keras.layers.ContextUpdate( \n",
    "#             {'operate': tfgnn.keras.layers.Pool(tfgnn.CONTEXT, 'mean')},\n",
    "#             tfgnn.keras.layers.NextStateFromConcat(tf.keras.layers.Dense(units, 'relu')))\n",
    "#         )(graph)\n",
    "#     return graph\n",
    "\n",
    "def MotherFuckerGraphUpdate_use(graph, units=5):\n",
    "    message_width=2*units\n",
    "    graph = tfgnn.keras.layers.GraphUpdate(\n",
    "        node_sets = {'operate': tfgnn.keras.layers.NodeSetUpdate(\n",
    "                         {\n",
    "#                           'src2op': tfgnn.keras.layers.SimpleConv(tf.keras.layers.Dense(units, 'relu'), 'mean', receiver_tag=tfgnn.SOURCE),\n",
    "                          'src2op': tfgnn.keras.layers.SimpleConv(tf.keras.layers.Dense(units, activation='relu', use_bias=True,), 'mean', receiver_tag=tfgnn.TARGET),\n",
    "#                           'src2op': gat_v2.GATv2Conv(2, units, receiver_tag=tfgnn.TARGET),\n",
    "#                           'op2op': tfgnn.keras.layers.SimpleConv(tf.keras.layers.Dense(units, 'relu'), 'mean', receiver_tag=tfgnn.SOURCE),\n",
    "                          'op2op': tfgnn.keras.layers.SimpleConv(tf.keras.layers.Dense(units, activation='relu', use_bias=True,), 'mean', receiver_tag=tfgnn.TARGET),\n",
    "#                           'op2op': gat_v2.GATv2Conv(2, units, receiver_tag=tfgnn.TARGET),\n",
    "                         },\n",
    "                         tfgnn.keras.layers.NextStateFromConcat(tf.keras.layers.Dense(units, activation='relu', use_bias=True,)),\n",
    "                         context_input_feature=tfgnn.HIDDEN_STATE),\n",
    "                    },\n",
    "        context = tfgnn.keras.layers.ContextUpdate( \n",
    "            {'operate': tfgnn.keras.layers.Pool(tfgnn.CONTEXT, 'mean')},\n",
    "            tfgnn.keras.layers.NextStateFromConcat(tf.keras.layers.Dense(units, activation='relu', use_bias=True,)))\n",
    "        )(graph)\n",
    "    return graph\n",
    "\n",
    "def ReuseableGraphUpdate_use(graph, units=5):\n",
    "    \n",
    "    graph = tfgnn.keras.layers.GraphUpdate(\n",
    "        node_sets = {'operate': tfgnn.keras.layers.NodeSetUpdate(\n",
    "                         {\n",
    "#                           'src2op': tfgnn.keras.layers.SimpleConv(tf.keras.layers.Dense(units, 'relu'), 'mean', receiver_tag=tfgnn.SOURCE),\n",
    "                          'src2op': tfgnn.keras.layers.SimpleConv(tf.keras.layers.Dense(units, activation='relu', use_bias=True,), 'mean', receiver_tag=tfgnn.TARGET),\n",
    "#                           'src2op': gat_v2.GATv2Conv(2, units, receiver_tag=tfgnn.TARGET),\n",
    "#                           'op2op': tfgnn.keras.layers.SimpleConv(tf.keras.layers.Dense(units, 'relu'), 'mean', receiver_tag=tfgnn.SOURCE),\n",
    "                          'op2op': tfgnn.keras.layers.SimpleConv(tf.keras.layers.Dense(units, activation='relu', use_bias=True,), 'mean', receiver_tag=tfgnn.TARGET),\n",
    "#                           'op2op': gat_v2.GATv2Conv(2, units, receiver_tag=tfgnn.TARGET),\n",
    "                         },\n",
    "                         tfgnn.keras.layers.NextStateFromConcat(tf.keras.layers.Dense(units, activation='relu', use_bias=True,)),\n",
    "                         context_input_feature=tfgnn.HIDDEN_STATE),\n",
    "                    },\n",
    "        context = tfgnn.keras.layers.ContextUpdate( \n",
    "            {'operate': tfgnn.keras.layers.Pool(tfgnn.CONTEXT, 'mean')},\n",
    "            tfgnn.keras.layers.NextStateFromConcat(tf.keras.layers.Dense(units, activation='relu', use_bias=True,)))\n",
    "        )(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5a5492e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define gnn update logic (using gatv2)\n",
    "# def gnn(graph):\n",
    "#     for i in range(2):\n",
    "#         graph = gat_v2.GATv2MPNNGraphUpdate(units=5, message_dim=4, num_heads=1, receiver_tag=tfgnn.SOURCE)(graph)\n",
    "#         graph = gat_v2.GATv2MPNNGraphUpdate(units=5, message_dim=4, num_heads=1, receiver_tag=tfgnn.TARGET,)(graph)\n",
    "#     return graph\n",
    "\n",
    "def gnn(graph):\n",
    "    for i in range(3):\n",
    "        graph = MotherFuckerGraphUpdate_use(graph, units=20)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fd748526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphTensorSpec({'context': ContextSpec({'features': {'hidden_state': TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)}, 'sizes': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, None), 'node_sets': {'source': NodeSetSpec({'features': {'hidden_state': TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)}, 'sizes': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, None), 'operate': NodeSetSpec({'features': {'hidden_state': TensorSpec(shape=(None, 9), dtype=tf.float32, name=None)}, 'sizes': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, None)}, 'edge_sets': {'src2op': EdgeSetSpec({'features': {}, 'sizes': TensorSpec(shape=(None,), dtype=tf.int32, name=None), 'adjacency': AdjacencySpec({'#index.0': TensorSpec(shape=(None,), dtype=tf.int32, name=None), '#index.1': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, {'#index.0': 'source', '#index.1': 'operate'})}, TensorShape([]), tf.int32, None), 'op2op': EdgeSetSpec({'features': {}, 'sizes': TensorSpec(shape=(None,), dtype=tf.int32, name=None), 'adjacency': AdjacencySpec({'#index.0': TensorSpec(shape=(None,), dtype=tf.int32, name=None), '#index.1': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, {'#index.0': 'operate', '#index.1': 'operate'})}, TensorShape([]), tf.int32, None)}}, TensorShape([]), tf.int32, None)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_input_spec, _, = train_ds.element_spec # Drop the spec for the labels.\n",
    "model_input_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "728ea06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_23 (InputLayer)       [()]                      0         \n",
      "                                                                 \n",
      " graph_update_9 (GraphUpdate  ()                       2100      \n",
      " )                                                               \n",
      "                                                                 \n",
      " graph_update_10 (GraphUpdat  ()                       3700      \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_11 (GraphUpdat  ()                       3700      \n",
      " e)                                                              \n",
      "                                                                 \n",
      " pool_21 (Pool)              (None, 20)                0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,521\n",
      "Trainable params: 9,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define and train the main model.\n",
    "model_input = tf.keras.layers.Input(type_spec=model_input_spec)\n",
    "graph = gnn(model_input) # apply gnn model\n",
    "# Classifying each graph as a whole, based on an aggregation of the node states from one node set\n",
    "pooled_features_s = tfgnn.keras.layers.Pool(tfgnn.CONTEXT, \"mean\", node_set_name=\"source\")(graph)\n",
    "pooled_features_op = tfgnn.keras.layers.Pool(tfgnn.CONTEXT, \"mean\", node_set_name=\"operate\")(graph)\n",
    "pooled_features = tf.keras.layers.concatenate([pooled_features_s, pooled_features_op, ]) # concat states of both sets\n",
    "\n",
    "# logits = tf.keras.layers.Dense(1)(pooled_features) # output\n",
    "logits = tf.keras.layers.Dense(1)(pooled_features_op) # output\n",
    "# logits = tf.keras.layers.Activation(tf.keras.activations.sigmoid)(logits) # sigmod for classification\n",
    "# logits = tf.round(logits)\n",
    "\n",
    "model = tf.keras.Model(model_input, logits) # make the model\n",
    "\n",
    "# compile this model for binary classification\n",
    "model.compile(tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d646cbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['graph_update_8/context_update_8/next_state_from_concat_17/dense_38/kernel:0', 'graph_update_8/context_update_8/next_state_from_concat_17/dense_38/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['graph_update_8/context_update_8/next_state_from_concat_17/dense_38/kernel:0', 'graph_update_8/context_update_8/next_state_from_concat_17/dense_38/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['graph_update_8/context_update_8/next_state_from_concat_17/dense_38/kernel:0', 'graph_update_8/context_update_8/next_state_from_concat_17/dense_38/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['graph_update_8/context_update_8/next_state_from_concat_17/dense_38/kernel:0', 'graph_update_8/context_update_8/next_state_from_concat_17/dense_38/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "11/11 [==============================] - 4s 91ms/step - loss: 1355653.8750 - val_loss: 1052077.6250\n",
      "Epoch 2/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 679567.1250 - val_loss: 335678.5938\n",
      "Epoch 3/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 95077.7500 - val_loss: 13225.6357\n",
      "Epoch 4/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 23472.6367 - val_loss: 24630.3047\n",
      "Epoch 5/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 30514.2773 - val_loss: 25412.6348\n",
      "Epoch 6/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 28925.8574 - val_loss: 22122.1562\n",
      "Epoch 7/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 22712.1895 - val_loss: 13944.5449\n",
      "Epoch 8/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 13224.4697 - val_loss: 9297.7803\n",
      "Epoch 9/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 10417.0059 - val_loss: 8935.2568\n",
      "Epoch 10/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 10032.5273 - val_loss: 8772.6680\n",
      "Epoch 11/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 9616.6084 - val_loss: 8526.6504\n",
      "Epoch 12/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 9385.5508 - val_loss: 8336.2559\n",
      "Epoch 13/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 9101.1689 - val_loss: 8066.2612\n",
      "Epoch 14/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 8748.1504 - val_loss: 7768.3701\n",
      "Epoch 15/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 8489.1719 - val_loss: 7674.0420\n",
      "Epoch 16/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 8317.9727 - val_loss: 7398.2446\n",
      "Epoch 17/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 8065.9814 - val_loss: 7174.9546\n",
      "Epoch 18/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 7810.7837 - val_loss: 6996.6987\n",
      "Epoch 19/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 7606.3530 - val_loss: 6769.4478\n",
      "Epoch 20/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 7383.9038 - val_loss: 6606.3682\n",
      "Epoch 21/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 7140.9033 - val_loss: 6435.1323\n",
      "Epoch 22/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 6895.0688 - val_loss: 6152.3281\n",
      "Epoch 23/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 6729.0566 - val_loss: 6129.1172\n",
      "Epoch 24/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 6609.2778 - val_loss: 5969.5713\n",
      "Epoch 25/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 6543.8379 - val_loss: 6225.6182\n",
      "Epoch 26/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 6526.0093 - val_loss: 5794.7344\n",
      "Epoch 27/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 6386.5454 - val_loss: 5772.6616\n",
      "Epoch 28/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 6262.7866 - val_loss: 5664.0430\n",
      "Epoch 29/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 6241.5278 - val_loss: 5733.0107\n",
      "Epoch 30/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 6235.4644 - val_loss: 5534.7246\n",
      "Epoch 31/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 6066.6973 - val_loss: 5502.2070\n",
      "Epoch 32/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 6052.0840 - val_loss: 5800.5854\n",
      "Epoch 33/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 6007.9189 - val_loss: 5335.4424\n",
      "Epoch 34/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 5932.7925 - val_loss: 5322.9189\n",
      "Epoch 35/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 5795.4106 - val_loss: 5250.1167\n",
      "Epoch 36/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 5823.2227 - val_loss: 5154.7144\n",
      "Epoch 37/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 5640.3325 - val_loss: 5112.9219\n",
      "Epoch 38/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 5643.0596 - val_loss: 5083.6807\n",
      "Epoch 39/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 5654.4531 - val_loss: 5008.1108\n",
      "Epoch 40/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 5528.7500 - val_loss: 5034.6455\n",
      "Epoch 41/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 5497.8872 - val_loss: 4827.6099\n",
      "Epoch 42/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 5523.9180 - val_loss: 5014.2036\n",
      "Epoch 43/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 5477.0127 - val_loss: 4812.4268\n",
      "Epoch 44/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 5417.8394 - val_loss: 4680.9277\n",
      "Epoch 45/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 5265.1445 - val_loss: 4738.4336\n",
      "Epoch 46/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 5143.5171 - val_loss: 4596.5220\n",
      "Epoch 47/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 5013.1494 - val_loss: 4474.3633\n",
      "Epoch 48/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 5241.2241 - val_loss: 4494.0820\n",
      "Epoch 49/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 4840.0781 - val_loss: 4368.9458\n",
      "Epoch 50/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 4993.0645 - val_loss: 4418.4126\n",
      "Epoch 51/4000\n",
      "11/11 [==============================] - 1s 37ms/step - loss: 4730.8813 - val_loss: 4137.2456\n",
      "Epoch 52/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4486.2246 - val_loss: 3989.7388\n",
      "Epoch 53/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 4435.7891 - val_loss: 4156.1167\n",
      "Epoch 54/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 4425.0522 - val_loss: 3995.4080\n",
      "Epoch 55/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4376.6973 - val_loss: 3775.5403\n",
      "Epoch 56/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 4155.4561 - val_loss: 3709.4778\n",
      "Epoch 57/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4077.1748 - val_loss: 3628.2302\n",
      "Epoch 58/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4147.0654 - val_loss: 3790.6060\n",
      "Epoch 59/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4141.0239 - val_loss: 3719.5444\n",
      "Epoch 60/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4040.2288 - val_loss: 3455.2036\n",
      "Epoch 61/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3916.5581 - val_loss: 3468.2949\n",
      "Epoch 62/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3783.5151 - val_loss: 3287.4351\n",
      "Epoch 63/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3728.5322 - val_loss: 3344.0481\n",
      "Epoch 64/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3966.5972 - val_loss: 3694.2131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 3897.2319 - val_loss: 3637.4741\n",
      "Epoch 66/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 3661.9170 - val_loss: 3308.8418\n",
      "Epoch 67/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 3449.3567 - val_loss: 3036.9092\n",
      "Epoch 68/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3311.8389 - val_loss: 3066.5088\n",
      "Epoch 69/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3335.7930 - val_loss: 2871.0242\n",
      "Epoch 70/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3069.4482 - val_loss: 2808.0850\n",
      "Epoch 71/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3071.2700 - val_loss: 2619.9104\n",
      "Epoch 72/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 3499.9648 - val_loss: 3390.2031\n",
      "Epoch 73/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3665.6626 - val_loss: 3572.6294\n",
      "Epoch 74/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3288.8259 - val_loss: 2631.4434\n",
      "Epoch 75/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2732.5845 - val_loss: 2420.4004\n",
      "Epoch 76/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2658.6206 - val_loss: 2599.5229\n",
      "Epoch 77/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3552.5161 - val_loss: 2906.3235\n",
      "Epoch 78/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3238.2471 - val_loss: 2827.6340\n",
      "Epoch 79/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3191.0618 - val_loss: 2204.5513\n",
      "Epoch 80/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2543.4114 - val_loss: 2353.9373\n",
      "Epoch 81/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2899.8396 - val_loss: 2298.1423\n",
      "Epoch 82/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2489.0532 - val_loss: 2070.8950\n",
      "Epoch 83/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2234.7349 - val_loss: 1883.2494\n",
      "Epoch 84/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2256.7681 - val_loss: 1934.6614\n",
      "Epoch 85/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 2180.7190 - val_loss: 1850.3457\n",
      "Epoch 86/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 2020.2631 - val_loss: 1705.9761\n",
      "Epoch 87/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2034.8198 - val_loss: 1964.6428\n",
      "Epoch 88/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2208.0312 - val_loss: 1705.9393\n",
      "Epoch 89/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2065.0288 - val_loss: 1449.7642\n",
      "Epoch 90/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1708.4280 - val_loss: 1276.5275\n",
      "Epoch 91/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1473.8848 - val_loss: 1857.4072\n",
      "Epoch 92/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2058.9692 - val_loss: 1641.8279\n",
      "Epoch 93/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1823.8705 - val_loss: 1411.0232\n",
      "Epoch 94/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1450.8030 - val_loss: 1028.6653\n",
      "Epoch 95/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1211.7247 - val_loss: 1001.7210\n",
      "Epoch 96/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1647.0675 - val_loss: 4497.7979\n",
      "Epoch 97/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4585.8081 - val_loss: 974.4808\n",
      "Epoch 98/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3046.5227 - val_loss: 6298.8091\n",
      "Epoch 99/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2259.1599 - val_loss: 1086.6799\n",
      "Epoch 100/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2511.1616 - val_loss: 2191.0056\n",
      "Epoch 101/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 7374.6245 - val_loss: 7350.8047\n",
      "Epoch 102/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 4656.7852 - val_loss: 5192.9336\n",
      "Epoch 103/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 8390.9990 - val_loss: 4983.4043\n",
      "Epoch 104/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 4893.1323 - val_loss: 8475.9062\n",
      "Epoch 105/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 10807.6230 - val_loss: 5595.0142\n",
      "Epoch 106/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3303.3848 - val_loss: 2271.4919\n",
      "Epoch 107/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2692.1650 - val_loss: 2174.0125\n",
      "Epoch 108/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2459.2734 - val_loss: 2399.6133\n",
      "Epoch 109/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2283.3181 - val_loss: 1649.8250\n",
      "Epoch 110/4000\n",
      "11/11 [==============================] - 1s 37ms/step - loss: 1715.7228 - val_loss: 1672.8730\n",
      "Epoch 111/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1427.0671 - val_loss: 1141.3817\n",
      "Epoch 112/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1315.8955 - val_loss: 1073.0508\n",
      "Epoch 113/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 1231.3868 - val_loss: 1010.1294\n",
      "Epoch 114/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1275.3417 - val_loss: 917.0760\n",
      "Epoch 115/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1037.0604 - val_loss: 1128.5298\n",
      "Epoch 116/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1144.0096 - val_loss: 880.6715\n",
      "Epoch 117/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 3507.0771 - val_loss: 4813.3115\n",
      "Epoch 118/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2606.2683 - val_loss: 889.5554\n",
      "Epoch 119/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2096.3230 - val_loss: 5862.5229\n",
      "Epoch 120/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 7078.8643 - val_loss: 2061.6230\n",
      "Epoch 121/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2852.3337 - val_loss: 1713.6874\n",
      "Epoch 122/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1219.2725 - val_loss: 1255.7031\n",
      "Epoch 123/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1178.6027 - val_loss: 906.9829\n",
      "Epoch 124/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1714.3470 - val_loss: 4365.7007\n",
      "Epoch 125/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4434.6670 - val_loss: 889.6537\n",
      "Epoch 126/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2541.7976 - val_loss: 3880.8660\n",
      "Epoch 127/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 3845.6907 - val_loss: 2041.3873\n",
      "Epoch 128/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2976.4382 - val_loss: 2230.5684\n",
      "Epoch 129/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3170.4978 - val_loss: 4628.8545\n",
      "Epoch 130/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3298.3284 - val_loss: 2000.9611\n",
      "Epoch 131/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2261.0701 - val_loss: 2624.9534\n",
      "Epoch 132/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 3044.0261 - val_loss: 3907.8660\n",
      "Epoch 133/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 6667.9995 - val_loss: 6697.3384\n",
      "Epoch 134/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4241.6416 - val_loss: 3191.9370\n",
      "Epoch 135/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 6263.1890 - val_loss: 3824.2144\n",
      "Epoch 136/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2129.4631 - val_loss: 2070.0129\n",
      "Epoch 137/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2479.4075 - val_loss: 4737.7056\n",
      "Epoch 138/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 5409.1318 - val_loss: 979.5855\n",
      "Epoch 139/4000\n",
      "11/11 [==============================] - 1s 37ms/step - loss: 2477.7966 - val_loss: 1161.9866\n",
      "Epoch 140/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 3949.9343 - val_loss: 5105.4663\n",
      "Epoch 141/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3357.6313 - val_loss: 1674.9153\n",
      "Epoch 142/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2030.6924 - val_loss: 3282.4966\n",
      "Epoch 143/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 4657.1807 - val_loss: 3083.6882\n",
      "Epoch 144/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2050.1582 - val_loss: 3270.7798\n",
      "Epoch 145/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2640.6565 - val_loss: 1317.9390\n",
      "Epoch 146/4000\n",
      "11/11 [==============================] - 1s 37ms/step - loss: 1306.2468 - val_loss: 894.3423\n",
      "Epoch 147/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 932.2762 - val_loss: 608.2604\n",
      "Epoch 148/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 695.4813 - val_loss: 838.3614\n",
      "Epoch 149/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 680.9789 - val_loss: 840.1237\n",
      "Epoch 150/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2342.0950 - val_loss: 3683.4485\n",
      "Epoch 151/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2202.9360 - val_loss: 579.0127\n",
      "Epoch 152/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1910.0626 - val_loss: 3941.9949\n",
      "Epoch 153/4000\n",
      "11/11 [==============================] - 1s 37ms/step - loss: 3211.0503 - val_loss: 1571.6594\n",
      "Epoch 154/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1788.2841 - val_loss: 1912.2002\n",
      "Epoch 155/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2276.5618 - val_loss: 3416.9358\n",
      "Epoch 156/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2940.9106 - val_loss: 2638.4507\n",
      "Epoch 157/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3397.5627 - val_loss: 2457.6736\n",
      "Epoch 158/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1899.1820 - val_loss: 5183.5220\n",
      "Epoch 159/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1774.3229 - val_loss: 434.6243\n",
      "Epoch 160/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3541.8237 - val_loss: 4423.0566\n",
      "Epoch 161/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2961.7410 - val_loss: 1765.1049\n",
      "Epoch 162/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2197.0261 - val_loss: 4110.7915\n",
      "Epoch 163/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 4968.2563 - val_loss: 1277.2874\n",
      "Epoch 164/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4049.6086 - val_loss: 4748.5166\n",
      "Epoch 165/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3381.6748 - val_loss: 2414.4736\n",
      "Epoch 166/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2821.2759 - val_loss: 1248.1642\n",
      "Epoch 167/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 3004.6313 - val_loss: 859.7067\n",
      "Epoch 168/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2725.5715 - val_loss: 2373.7886\n",
      "Epoch 169/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2580.7021 - val_loss: 3087.3811\n",
      "Epoch 170/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2544.5530 - val_loss: 1417.5266\n",
      "Epoch 171/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1489.5144 - val_loss: 1739.8698\n",
      "Epoch 172/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1793.5542 - val_loss: 673.1296\n",
      "Epoch 173/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 960.1923 - val_loss: 858.3654\n",
      "Epoch 174/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2882.1748 - val_loss: 2609.2029\n",
      "Epoch 175/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1716.1022 - val_loss: 700.3027\n",
      "Epoch 176/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 3608.3345 - val_loss: 4528.1543\n",
      "Epoch 177/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2914.6440 - val_loss: 891.3513\n",
      "Epoch 178/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2216.8489 - val_loss: 3028.8816\n",
      "Epoch 179/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2346.1965 - val_loss: 1812.6947\n",
      "Epoch 180/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2872.5244 - val_loss: 3681.5942\n",
      "Epoch 181/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2334.4600 - val_loss: 1144.0123\n",
      "Epoch 182/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2242.0002 - val_loss: 4007.8933\n",
      "Epoch 183/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 3513.2144 - val_loss: 2236.4868\n",
      "Epoch 184/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 4519.8555 - val_loss: 2346.2773\n",
      "Epoch 185/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1942.8549 - val_loss: 1119.2712\n",
      "Epoch 186/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1795.1534 - val_loss: 1191.8744\n",
      "Epoch 187/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2609.0457 - val_loss: 3121.0874\n",
      "Epoch 188/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1891.1843 - val_loss: 889.6767\n",
      "Epoch 189/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 704.5688 - val_loss: 444.3535\n",
      "Epoch 190/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 590.5587 - val_loss: 416.7169\n",
      "Epoch 191/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 458.1634 - val_loss: 355.7077\n",
      "Epoch 192/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 658.3680 - val_loss: 2068.5657\n",
      "Epoch 193/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 2896.1384 - val_loss: 1231.7283\n",
      "Epoch 194/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1870.8057 - val_loss: 684.4993\n",
      "Epoch 195/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3206.7781 - val_loss: 3552.1780\n",
      "Epoch 196/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2306.9585 - val_loss: 691.0417\n",
      "Epoch 197/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 4809.4927 - val_loss: 5036.3511\n",
      "Epoch 198/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 3388.3411 - val_loss: 1492.0162\n",
      "Epoch 199/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1841.0149 - val_loss: 2654.3845\n",
      "Epoch 200/4000\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 2228.5591 - val_loss: 1082.5978\n",
      "Epoch 201/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1921.3901 - val_loss: 2955.3267\n",
      "Epoch 202/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2386.2883 - val_loss: 941.1224\n",
      "Epoch 203/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1508.6642 - val_loss: 2195.4802\n",
      "Epoch 204/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 1959.6558 - val_loss: 3047.6650\n",
      "Epoch 205/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 3185.3433 - val_loss: 793.4240\n",
      "Epoch 206/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1290.5358 - val_loss: 2879.5691\n",
      "Epoch 207/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3038.8755 - val_loss: 495.8344\n",
      "Epoch 208/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 3238.0803 - val_loss: 2811.4082\n",
      "Epoch 209/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2207.8040 - val_loss: 1655.9108\n",
      "Epoch 210/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1497.2561 - val_loss: 1815.7769\n",
      "Epoch 211/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1536.2828 - val_loss: 1487.2351\n",
      "Epoch 212/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2275.7344 - val_loss: 2780.6345\n",
      "Epoch 213/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2859.5356 - val_loss: 2749.0366\n",
      "Epoch 214/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 3161.1643 - val_loss: 3508.3303\n",
      "Epoch 215/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 43ms/step - loss: 1207.6470 - val_loss: 1240.6531\n",
      "Epoch 216/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 4661.4561 - val_loss: 3585.3623\n",
      "Epoch 217/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2049.0417 - val_loss: 745.1605\n",
      "Epoch 218/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 673.3796 - val_loss: 496.8550\n",
      "Epoch 219/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1431.2955 - val_loss: 1482.6271\n",
      "Epoch 220/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1991.3962 - val_loss: 3928.6235\n",
      "Epoch 221/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 3181.0010 - val_loss: 1344.5548\n",
      "Epoch 222/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1899.1428 - val_loss: 595.2638\n",
      "Epoch 223/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2335.6812 - val_loss: 1707.4967\n",
      "Epoch 224/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1634.8057 - val_loss: 743.7219\n",
      "Epoch 225/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 3541.8167 - val_loss: 3352.0928\n",
      "Epoch 226/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 3884.2712 - val_loss: 3024.5693\n",
      "Epoch 227/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 2921.5229 - val_loss: 2159.3887\n",
      "Epoch 228/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2354.8586 - val_loss: 1823.2921\n",
      "Epoch 229/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1983.8763 - val_loss: 1590.8070\n",
      "Epoch 230/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1739.6543 - val_loss: 1468.3495\n",
      "Epoch 231/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1481.4092 - val_loss: 1211.9038\n",
      "Epoch 232/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1268.9714 - val_loss: 1254.2611\n",
      "Epoch 233/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1486.5333 - val_loss: 1255.2878\n",
      "Epoch 234/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1163.1797 - val_loss: 811.1330\n",
      "Epoch 235/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1027.7297 - val_loss: 1982.7646\n",
      "Epoch 236/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2693.3325 - val_loss: 4406.5801\n",
      "Epoch 237/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 4483.1655 - val_loss: 2896.9482\n",
      "Epoch 238/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1523.6267 - val_loss: 1769.6476\n",
      "Epoch 239/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2732.2351 - val_loss: 628.2965\n",
      "Epoch 240/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2824.1628 - val_loss: 2844.2405\n",
      "Epoch 241/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2215.9021 - val_loss: 1657.9939\n",
      "Epoch 242/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2678.0090 - val_loss: 3526.7529\n",
      "Epoch 243/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2457.7625 - val_loss: 1395.3687\n",
      "Epoch 244/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1177.2631 - val_loss: 862.3445\n",
      "Epoch 245/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 997.0239 - val_loss: 868.7232\n",
      "Epoch 246/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 886.8085 - val_loss: 567.9619\n",
      "Epoch 247/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 616.5958 - val_loss: 463.5769\n",
      "Epoch 248/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 537.0831 - val_loss: 1209.9197\n",
      "Epoch 249/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2834.7544 - val_loss: 400.1696\n",
      "Epoch 250/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2463.4150 - val_loss: 2376.4631\n",
      "Epoch 251/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2375.2205 - val_loss: 4558.7290\n",
      "Epoch 252/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3682.5740 - val_loss: 824.2819\n",
      "Epoch 253/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1729.0621 - val_loss: 3667.4128\n",
      "Epoch 254/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3253.9307 - val_loss: 827.8063\n",
      "Epoch 255/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2653.7957 - val_loss: 856.0524\n",
      "Epoch 256/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2898.9231 - val_loss: 1448.2311\n",
      "Epoch 257/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2261.2510 - val_loss: 1211.9648\n",
      "Epoch 258/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 3035.9473 - val_loss: 4310.8760\n",
      "Epoch 259/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3276.0320 - val_loss: 2844.9626\n",
      "Epoch 260/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3789.6453 - val_loss: 916.0786\n",
      "Epoch 261/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2861.3389 - val_loss: 1246.4364\n",
      "Epoch 262/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1200.9125 - val_loss: 1611.5986\n",
      "Epoch 263/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2510.4668 - val_loss: 1757.7040\n",
      "Epoch 264/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2042.8810 - val_loss: 2835.0647\n",
      "Epoch 265/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2473.8923 - val_loss: 2693.5569\n",
      "Epoch 266/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2241.8418 - val_loss: 3069.5559\n",
      "Epoch 267/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4100.4287 - val_loss: 1016.6805\n",
      "Epoch 268/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2477.4487 - val_loss: 854.9620\n",
      "Epoch 269/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2062.6379 - val_loss: 546.5939\n",
      "Epoch 270/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2930.1311 - val_loss: 2023.6813\n",
      "Epoch 271/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1107.8102 - val_loss: 700.8698\n",
      "Epoch 272/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 865.1718 - val_loss: 708.5404\n",
      "Epoch 273/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 710.2884 - val_loss: 466.7428\n",
      "Epoch 274/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2710.1711 - val_loss: 4473.6865\n",
      "Epoch 275/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3237.4351 - val_loss: 2194.0083\n",
      "Epoch 276/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3095.2068 - val_loss: 1540.5061\n",
      "Epoch 277/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 5272.6416 - val_loss: 8426.5508\n",
      "Epoch 278/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 8244.4814 - val_loss: 2750.1228\n",
      "Epoch 279/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 4114.5034 - val_loss: 5849.3960\n",
      "Epoch 280/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 5219.5776 - val_loss: 1167.0314\n",
      "Epoch 281/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2554.5234 - val_loss: 3141.5964\n",
      "Epoch 282/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2199.4875 - val_loss: 1556.1830\n",
      "Epoch 283/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1385.4436 - val_loss: 1129.8767\n",
      "Epoch 284/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2437.9270 - val_loss: 1504.4427\n",
      "Epoch 285/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2371.2849 - val_loss: 1261.6520\n",
      "Epoch 286/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2354.2495 - val_loss: 1164.7278\n",
      "Epoch 287/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2373.0959 - val_loss: 1597.8188\n",
      "Epoch 288/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1901.2042 - val_loss: 2315.3081\n",
      "Epoch 289/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2548.2046 - val_loss: 3320.7305\n",
      "Epoch 290/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2422.2029 - val_loss: 2631.6809\n",
      "Epoch 291/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 3241.1135 - val_loss: 654.4837\n",
      "Epoch 292/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2177.7834 - val_loss: 611.0615\n",
      "Epoch 293/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 3335.7471 - val_loss: 4221.2290\n",
      "Epoch 294/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 3017.7231 - val_loss: 1737.8287\n",
      "Epoch 295/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2519.0137 - val_loss: 5471.0811\n",
      "Epoch 296/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1752.3976 - val_loss: 2137.6428\n",
      "Epoch 297/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2957.0454 - val_loss: 2021.0635\n",
      "Epoch 298/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2123.4478 - val_loss: 1643.3024\n",
      "Epoch 299/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2747.7834 - val_loss: 3573.7361\n",
      "Epoch 300/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2451.3542 - val_loss: 542.0743\n",
      "Epoch 301/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 951.9862 - val_loss: 929.8480\n",
      "Epoch 302/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1021.1863 - val_loss: 879.9559\n",
      "Epoch 303/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1643.4370 - val_loss: 4098.3613\n",
      "Epoch 304/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3830.4932 - val_loss: 1058.2601\n",
      "Epoch 305/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2991.4673 - val_loss: 2448.1396\n",
      "Epoch 306/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2076.0198 - val_loss: 1980.5138\n",
      "Epoch 307/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1862.6710 - val_loss: 2204.2168\n",
      "Epoch 308/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2075.3635 - val_loss: 2210.9602\n",
      "Epoch 309/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1674.4255 - val_loss: 1121.9658\n",
      "Epoch 310/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 746.1429 - val_loss: 453.3203\n",
      "Epoch 311/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 951.3367 - val_loss: 3376.3879\n",
      "Epoch 312/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 4747.5239 - val_loss: 1847.9594\n",
      "Epoch 313/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2200.1538 - val_loss: 2676.9900\n",
      "Epoch 314/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1989.4767 - val_loss: 1142.2703\n",
      "Epoch 315/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1759.0504 - val_loss: 1123.1908\n",
      "Epoch 316/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1635.8992 - val_loss: 1443.1322\n",
      "Epoch 317/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1975.6927 - val_loss: 2519.9539\n",
      "Epoch 318/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2446.9421 - val_loss: 3111.9556\n",
      "Epoch 319/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2348.9827 - val_loss: 2144.0271\n",
      "Epoch 320/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1898.4503 - val_loss: 1776.1390\n",
      "Epoch 321/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3038.8467 - val_loss: 923.3790\n",
      "Epoch 322/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2433.1421 - val_loss: 1017.8176\n",
      "Epoch 323/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2323.6416 - val_loss: 1328.0587\n",
      "Epoch 324/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2525.4980 - val_loss: 2927.1670\n",
      "Epoch 325/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2757.0247 - val_loss: 4521.3779\n",
      "Epoch 326/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 5861.8037 - val_loss: 2660.5879\n",
      "Epoch 327/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2445.7568 - val_loss: 4233.4482\n",
      "Epoch 328/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 4267.0239 - val_loss: 1924.8247\n",
      "Epoch 329/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1647.3679 - val_loss: 1945.2084\n",
      "Epoch 330/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2863.2483 - val_loss: 401.0949\n",
      "Epoch 331/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1735.0774 - val_loss: 709.2690\n",
      "Epoch 332/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3677.4214 - val_loss: 4458.4536\n",
      "Epoch 333/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2890.7354 - val_loss: 799.4777\n",
      "Epoch 334/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1347.6334 - val_loss: 2119.8450\n",
      "Epoch 335/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1505.3101 - val_loss: 2197.1748\n",
      "Epoch 336/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1853.9008 - val_loss: 1302.1715\n",
      "Epoch 337/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1729.2153 - val_loss: 3242.2610\n",
      "Epoch 338/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3511.6658 - val_loss: 756.5500\n",
      "Epoch 339/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1591.2173 - val_loss: 533.7391\n",
      "Epoch 340/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 679.1499 - val_loss: 1451.6842\n",
      "Epoch 341/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2855.9055 - val_loss: 1389.5718\n",
      "Epoch 342/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 4187.7134 - val_loss: 6335.4829\n",
      "Epoch 343/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 5265.4492 - val_loss: 3018.1824\n",
      "Epoch 344/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1344.4235 - val_loss: 946.5316\n",
      "Epoch 345/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2147.8853 - val_loss: 4043.2700\n",
      "Epoch 346/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3386.9368 - val_loss: 935.1777\n",
      "Epoch 347/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2907.6921 - val_loss: 1793.6271\n",
      "Epoch 348/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1721.2020 - val_loss: 1805.7207\n",
      "Epoch 349/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3303.7551 - val_loss: 4537.9839\n",
      "Epoch 350/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3596.7322 - val_loss: 2227.5640\n",
      "Epoch 351/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4977.9590 - val_loss: 4747.1104\n",
      "Epoch 352/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2923.7090 - val_loss: 1329.9486\n",
      "Epoch 353/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2282.5691 - val_loss: 757.4835\n",
      "Epoch 354/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2507.6169 - val_loss: 589.3049\n",
      "Epoch 355/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1420.2424 - val_loss: 555.8968\n",
      "Epoch 356/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2970.9404 - val_loss: 2832.6147\n",
      "Epoch 357/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1858.0300 - val_loss: 1700.6287\n",
      "Epoch 358/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2145.8674 - val_loss: 2164.2766\n",
      "Epoch 359/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2646.6467 - val_loss: 646.7828\n",
      "Epoch 360/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2320.4319 - val_loss: 700.5098\n",
      "Epoch 361/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2325.1602 - val_loss: 2382.2632\n",
      "Epoch 362/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2041.2771 - val_loss: 2349.4746\n",
      "Epoch 363/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2063.0728 - val_loss: 2834.0383\n",
      "Epoch 364/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4098.2148 - val_loss: 1399.4431\n",
      "Epoch 365/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 39ms/step - loss: 2530.1309 - val_loss: 2768.5984\n",
      "Epoch 366/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1936.3083 - val_loss: 1797.9497\n",
      "Epoch 367/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2067.6765 - val_loss: 3867.7625\n",
      "Epoch 368/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3775.0796 - val_loss: 1013.0975\n",
      "Epoch 369/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3482.6580 - val_loss: 3720.1685\n",
      "Epoch 370/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2393.7883 - val_loss: 1370.6359\n",
      "Epoch 371/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1258.4447 - val_loss: 848.5488\n",
      "Epoch 372/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 861.7872 - val_loss: 832.7270\n",
      "Epoch 373/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3725.8945 - val_loss: 3418.0066\n",
      "Epoch 374/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2050.7292 - val_loss: 1522.3788\n",
      "Epoch 375/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2517.8977 - val_loss: 1015.5482\n",
      "Epoch 376/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2875.6316 - val_loss: 860.0262\n",
      "Epoch 377/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1503.1627 - val_loss: 1055.5155\n",
      "Epoch 378/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 603.1481 - val_loss: 379.5811\n",
      "Epoch 379/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 403.5514 - val_loss: 327.2106\n",
      "Epoch 380/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 359.1878 - val_loss: 254.3228\n",
      "Epoch 381/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2375.9414 - val_loss: 4504.2031\n",
      "Epoch 382/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3851.1213 - val_loss: 424.7210\n",
      "Epoch 383/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2657.9736 - val_loss: 3037.4880\n",
      "Epoch 384/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2769.8679 - val_loss: 2803.4067\n",
      "Epoch 385/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2569.9619 - val_loss: 2583.1309\n",
      "Epoch 386/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2531.8257 - val_loss: 944.4628\n",
      "Epoch 387/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1418.3893 - val_loss: 1997.7982\n",
      "Epoch 388/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2535.4075 - val_loss: 734.5569\n",
      "Epoch 389/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1480.8827 - val_loss: 1187.3840\n",
      "Epoch 390/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3091.8655 - val_loss: 3698.7437\n",
      "Epoch 391/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2726.6619 - val_loss: 2376.9260\n",
      "Epoch 392/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2828.3154 - val_loss: 2809.9084\n",
      "Epoch 393/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1188.7268 - val_loss: 2756.4766\n",
      "Epoch 394/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3754.9583 - val_loss: 1062.6689\n",
      "Epoch 395/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1040.3754 - val_loss: 1469.7004\n",
      "Epoch 396/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1819.6240 - val_loss: 1512.9978\n",
      "Epoch 397/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2023.8901 - val_loss: 924.0529\n",
      "Epoch 398/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1309.8500 - val_loss: 749.9741\n",
      "Epoch 399/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1018.5265 - val_loss: 398.6137\n",
      "Epoch 400/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 597.9149 - val_loss: 566.2888\n",
      "Epoch 401/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1617.8768 - val_loss: 4403.0923\n",
      "Epoch 402/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4476.7349 - val_loss: 735.6077\n",
      "Epoch 403/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4256.0498 - val_loss: 5486.3188\n",
      "Epoch 404/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4032.6145 - val_loss: 1577.5392\n",
      "Epoch 405/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1781.8762 - val_loss: 1377.4962\n",
      "Epoch 406/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1711.3748 - val_loss: 2462.4629\n",
      "Epoch 407/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2324.5361 - val_loss: 457.7495\n",
      "Epoch 408/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1732.6028 - val_loss: 3410.5291\n",
      "Epoch 409/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3127.8740 - val_loss: 1274.0204\n",
      "Epoch 410/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1837.9623 - val_loss: 2605.9814\n",
      "Epoch 411/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2367.7109 - val_loss: 812.8992\n",
      "Epoch 412/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1531.1840 - val_loss: 3110.4619\n",
      "Epoch 413/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2761.2876 - val_loss: 277.4830\n",
      "Epoch 414/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1236.2950 - val_loss: 4415.3784\n",
      "Epoch 415/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2411.6838 - val_loss: 664.1191\n",
      "Epoch 416/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1202.8690 - val_loss: 641.3629\n",
      "Epoch 417/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 752.3915 - val_loss: 328.4025\n",
      "Epoch 418/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 834.1558 - val_loss: 2757.6016\n",
      "Epoch 419/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3487.7366 - val_loss: 764.9932\n",
      "Epoch 420/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3815.8230 - val_loss: 4940.9336\n",
      "Epoch 421/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3683.8413 - val_loss: 709.5712\n",
      "Epoch 422/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1332.1094 - val_loss: 1659.6107\n",
      "Epoch 423/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2884.5684 - val_loss: 560.1014\n",
      "Epoch 424/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1269.5070 - val_loss: 1105.4734\n",
      "Epoch 425/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2748.5938 - val_loss: 2327.9167\n",
      "Epoch 426/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2257.9702 - val_loss: 2054.7434\n",
      "Epoch 427/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1986.6050 - val_loss: 2307.3735\n",
      "Epoch 428/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1758.9783 - val_loss: 1724.5586\n",
      "Epoch 429/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1232.8346 - val_loss: 491.2804\n",
      "Epoch 430/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 704.0193 - val_loss: 537.8041\n",
      "Epoch 431/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 543.6977 - val_loss: 311.5742\n",
      "Epoch 432/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 319.2719 - val_loss: 168.9495\n",
      "Epoch 433/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1075.6956 - val_loss: 3701.1299\n",
      "Epoch 434/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3469.5930 - val_loss: 1684.9751\n",
      "Epoch 435/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 3766.7590 - val_loss: 3883.2612\n",
      "Epoch 436/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2680.0125 - val_loss: 1733.6038\n",
      "Epoch 437/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1909.9847 - val_loss: 922.8694\n",
      "Epoch 438/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2432.8608 - val_loss: 1071.0667\n",
      "Epoch 439/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2552.4043 - val_loss: 2031.8147\n",
      "Epoch 440/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2461.2375 - val_loss: 3568.0537\n",
      "Epoch 441/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 3015.0664 - val_loss: 1416.9695\n",
      "Epoch 442/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2175.5935 - val_loss: 6449.0151\n",
      "Epoch 443/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2284.0322 - val_loss: 1031.3098\n",
      "Epoch 444/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2300.4258 - val_loss: 1047.6619\n",
      "Epoch 445/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 901.5179 - val_loss: 1536.7358\n",
      "Epoch 446/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2635.5859 - val_loss: 1026.8495\n",
      "Epoch 447/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1530.7350 - val_loss: 1003.6171\n",
      "Epoch 448/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1637.8156 - val_loss: 2379.1321\n",
      "Epoch 449/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1505.4485 - val_loss: 928.3178\n",
      "Epoch 450/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2144.3586 - val_loss: 4869.3926\n",
      "Epoch 451/4000\n",
      "11/11 [==============================] - 1s 37ms/step - loss: 4839.9995 - val_loss: 788.9590\n",
      "Epoch 452/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2933.0630 - val_loss: 2566.2986\n",
      "Epoch 453/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1689.6276 - val_loss: 992.9304\n",
      "Epoch 454/4000\n",
      "11/11 [==============================] - 1s 37ms/step - loss: 1210.8701 - val_loss: 1867.9640\n",
      "Epoch 455/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1828.2577 - val_loss: 2306.0100\n",
      "Epoch 456/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1645.4252 - val_loss: 827.7195\n",
      "Epoch 457/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1651.6350 - val_loss: 2552.7776\n",
      "Epoch 458/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1725.7886 - val_loss: 1861.0197\n",
      "Epoch 459/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 3409.4404 - val_loss: 1250.0302\n",
      "Epoch 460/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3911.0940 - val_loss: 6247.6899\n",
      "Epoch 461/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 5678.2446 - val_loss: 1358.4299\n",
      "Epoch 462/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2209.2598 - val_loss: 1640.3176\n",
      "Epoch 463/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2378.9333 - val_loss: 3151.1797\n",
      "Epoch 464/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2373.0032 - val_loss: 2533.8816\n",
      "Epoch 465/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 5436.2310 - val_loss: 3937.3149\n",
      "Epoch 466/4000\n",
      "11/11 [==============================] - 1s 37ms/step - loss: 2776.0754 - val_loss: 1459.4261\n",
      "Epoch 467/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2316.2078 - val_loss: 1168.6118\n",
      "Epoch 468/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2748.4849 - val_loss: 846.9741\n",
      "Epoch 469/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2102.4009 - val_loss: 1599.3538\n",
      "Epoch 470/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1690.3783 - val_loss: 1803.2374\n",
      "Epoch 471/4000\n",
      "11/11 [==============================] - 1s 37ms/step - loss: 1542.1550 - val_loss: 1341.0533\n",
      "Epoch 472/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1359.0079 - val_loss: 1594.7969\n",
      "Epoch 473/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1089.9678 - val_loss: 725.6991\n",
      "Epoch 474/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 982.1872 - val_loss: 794.9445\n",
      "Epoch 475/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1949.8491 - val_loss: 787.4696\n",
      "Epoch 476/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 644.0293 - val_loss: 350.1234\n",
      "Epoch 477/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1789.5668 - val_loss: 2072.4534\n",
      "Epoch 478/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1906.2218 - val_loss: 3792.4683\n",
      "Epoch 479/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3795.7993 - val_loss: 821.1301\n",
      "Epoch 480/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 981.9453 - val_loss: 2024.6537\n",
      "Epoch 481/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1823.0991 - val_loss: 2648.4321\n",
      "Epoch 482/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3872.1328 - val_loss: 1200.8337\n",
      "Epoch 483/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2713.8198 - val_loss: 1705.7050\n",
      "Epoch 484/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2017.9443 - val_loss: 1684.3534\n",
      "Epoch 485/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2162.8479 - val_loss: 3326.9026\n",
      "Epoch 486/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2336.4792 - val_loss: 379.5868\n",
      "Epoch 487/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 616.1838 - val_loss: 504.0107\n",
      "Epoch 488/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2550.5181 - val_loss: 2063.8457\n",
      "Epoch 489/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2786.0359 - val_loss: 5133.4722\n",
      "Epoch 490/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 5283.3066 - val_loss: 1953.6851\n",
      "Epoch 491/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1963.3088 - val_loss: 2446.0652\n",
      "Epoch 492/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2652.6458 - val_loss: 3856.9976\n",
      "Epoch 493/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3571.3154 - val_loss: 5293.2778\n",
      "Epoch 494/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1476.7615 - val_loss: 2079.2214\n",
      "Epoch 495/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 3926.7529 - val_loss: 2120.6218\n",
      "Epoch 496/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1466.9637 - val_loss: 1997.0614\n",
      "Epoch 497/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1774.3622 - val_loss: 1375.4144\n",
      "Epoch 498/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1894.8553 - val_loss: 2465.3633\n",
      "Epoch 499/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1823.5251 - val_loss: 1361.9038\n",
      "Epoch 500/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1414.7227 - val_loss: 2253.7395\n",
      "Epoch 501/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1583.5679 - val_loss: 561.0022\n",
      "Epoch 502/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1642.4764 - val_loss: 4036.7126\n",
      "Epoch 503/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3922.2104 - val_loss: 1192.2700\n",
      "Epoch 504/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 963.3347 - val_loss: 1945.5709\n",
      "Epoch 505/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3481.0247 - val_loss: 1710.7073\n",
      "Epoch 506/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1112.9999 - val_loss: 807.0462\n",
      "Epoch 507/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1058.4476 - val_loss: 906.4682\n",
      "Epoch 508/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 957.6760 - val_loss: 652.1686\n",
      "Epoch 509/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1680.6176 - val_loss: 2631.2778\n",
      "Epoch 510/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1970.9271 - val_loss: 2071.8325\n",
      "Epoch 511/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1728.6932 - val_loss: 676.7877\n",
      "Epoch 512/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 529.2111 - val_loss: 1466.2886\n",
      "Epoch 513/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 4098.0166 - val_loss: 2889.3975\n",
      "Epoch 514/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2337.3071 - val_loss: 1642.8844\n",
      "Epoch 515/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 39ms/step - loss: 1823.5594 - val_loss: 2814.8757\n",
      "Epoch 516/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2549.7991 - val_loss: 523.3743\n",
      "Epoch 517/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1180.0436 - val_loss: 1861.4078\n",
      "Epoch 518/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1991.5656 - val_loss: 3772.1252\n",
      "Epoch 519/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3903.9612 - val_loss: 761.6093\n",
      "Epoch 520/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1688.3187 - val_loss: 3982.8162\n",
      "Epoch 521/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3390.4624 - val_loss: 658.4655\n",
      "Epoch 522/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1340.5085 - val_loss: 1530.7118\n",
      "Epoch 523/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2100.9604 - val_loss: 4783.6802\n",
      "Epoch 524/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1364.3022 - val_loss: 519.4475\n",
      "Epoch 525/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1426.1610 - val_loss: 552.0889\n",
      "Epoch 526/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1646.2236 - val_loss: 3087.7478\n",
      "Epoch 527/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1263.8179 - val_loss: 285.2338\n",
      "Epoch 528/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2423.3589 - val_loss: 2132.8826\n",
      "Epoch 529/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 3166.8857 - val_loss: 5739.8843\n",
      "Epoch 530/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 6006.8965 - val_loss: 1995.2336\n",
      "Epoch 531/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2630.0959 - val_loss: 3019.6008\n",
      "Epoch 532/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2072.6670 - val_loss: 1035.9327\n",
      "Epoch 533/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1227.6951 - val_loss: 1662.0906\n",
      "Epoch 534/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1491.6241 - val_loss: 2998.2288\n",
      "Epoch 535/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 4513.4033 - val_loss: 2002.4500\n",
      "Epoch 536/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1487.3789 - val_loss: 627.5855\n",
      "Epoch 537/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 543.7184 - val_loss: 480.1716\n",
      "Epoch 538/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 678.1588 - val_loss: 2432.7063\n",
      "Epoch 539/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 4937.3555 - val_loss: 3064.4092\n",
      "Epoch 540/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2493.4990 - val_loss: 3321.6602\n",
      "Epoch 541/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2922.7285 - val_loss: 2686.7334\n",
      "Epoch 542/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2881.0596 - val_loss: 4848.4282\n",
      "Epoch 543/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1684.0480 - val_loss: 2035.3850\n",
      "Epoch 544/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3587.4749 - val_loss: 1597.4225\n",
      "Epoch 545/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1576.6608 - val_loss: 1431.2378\n",
      "Epoch 546/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1870.8916 - val_loss: 1840.0345\n",
      "Epoch 547/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1993.7362 - val_loss: 1539.9824\n",
      "Epoch 548/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1690.4352 - val_loss: 2012.6616\n",
      "Epoch 549/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1960.5503 - val_loss: 3437.4492\n",
      "Epoch 550/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 4238.3135 - val_loss: 1393.4821\n",
      "Epoch 551/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1561.4913 - val_loss: 726.8076\n",
      "Epoch 552/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 635.4993 - val_loss: 641.9476\n",
      "Epoch 553/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 713.2272 - val_loss: 535.3404\n",
      "Epoch 554/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 819.2333 - val_loss: 2397.3652\n",
      "Epoch 555/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2905.1973 - val_loss: 774.9434\n",
      "Epoch 556/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1538.7522 - val_loss: 1933.6393\n",
      "Epoch 557/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2146.6465 - val_loss: 1655.3466\n",
      "Epoch 558/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2625.6560 - val_loss: 2602.4021\n",
      "Epoch 559/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1612.1542 - val_loss: 622.3827\n",
      "Epoch 560/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1408.4808 - val_loss: 744.8311\n",
      "Epoch 561/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1399.4351 - val_loss: 834.3892\n",
      "Epoch 562/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1298.1069 - val_loss: 920.1072\n",
      "Epoch 563/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1809.3523 - val_loss: 2387.2329\n",
      "Epoch 564/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2241.1731 - val_loss: 3928.1042\n",
      "Epoch 565/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3903.2939 - val_loss: 2503.3757\n",
      "Epoch 566/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1441.5920 - val_loss: 1356.5302\n",
      "Epoch 567/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1647.4659 - val_loss: 958.0230\n",
      "Epoch 568/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1140.6688 - val_loss: 1122.3029\n",
      "Epoch 569/4000\n",
      "11/11 [==============================] - 1s 37ms/step - loss: 1444.3677 - val_loss: 744.0981\n",
      "Epoch 570/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1614.0035 - val_loss: 719.3829\n",
      "Epoch 571/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1329.5293 - val_loss: 1043.6831\n",
      "Epoch 572/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3471.5801 - val_loss: 3192.7939\n",
      "Epoch 573/4000\n",
      "11/11 [==============================] - 1s 37ms/step - loss: 2363.3823 - val_loss: 2302.8782\n",
      "Epoch 574/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2135.0789 - val_loss: 2717.7100\n",
      "Epoch 575/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2414.1975 - val_loss: 1528.8159\n",
      "Epoch 576/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2097.3547 - val_loss: 503.5521\n",
      "Epoch 577/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1769.1600 - val_loss: 582.4888\n",
      "Epoch 578/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3161.9739 - val_loss: 2871.2224\n",
      "Epoch 579/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2345.8855 - val_loss: 2317.7793\n",
      "Epoch 580/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2059.5547 - val_loss: 2799.1365\n",
      "Epoch 581/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 6493.7129 - val_loss: 5177.1841\n",
      "Epoch 582/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 3235.0234 - val_loss: 1382.3101\n",
      "Epoch 583/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2132.8379 - val_loss: 1185.5474\n",
      "Epoch 584/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 3987.0613 - val_loss: 2753.8926\n",
      "Epoch 585/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2649.5540 - val_loss: 4391.9365\n",
      "Epoch 586/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 5070.0698 - val_loss: 2447.2969\n",
      "Epoch 587/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1814.3809 - val_loss: 1946.9739\n",
      "Epoch 588/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2088.5857 - val_loss: 2384.5828\n",
      "Epoch 589/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2127.4844 - val_loss: 2177.8032\n",
      "Epoch 590/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2601.7144 - val_loss: 1183.9238\n",
      "Epoch 591/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 823.2510 - val_loss: 475.0137\n",
      "Epoch 592/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 604.5872 - val_loss: 561.6569\n",
      "Epoch 593/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 575.9127 - val_loss: 417.2589\n",
      "Epoch 594/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 747.7073 - val_loss: 2013.8492\n",
      "Epoch 595/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3501.2002 - val_loss: 1421.5990\n",
      "Epoch 596/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1814.2981 - val_loss: 1180.8258\n",
      "Epoch 597/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 723.4052 - val_loss: 480.7493\n",
      "Epoch 598/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 564.5995 - val_loss: 413.3087\n",
      "Epoch 599/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 643.2439 - val_loss: 2353.4199\n",
      "Epoch 600/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 4985.5933 - val_loss: 3148.8853\n",
      "Epoch 601/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2261.7300 - val_loss: 3567.6433\n",
      "Epoch 602/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 4072.3816 - val_loss: 954.1805\n",
      "Epoch 603/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 5241.2808 - val_loss: 6734.1470\n",
      "Epoch 604/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 5757.7959 - val_loss: 809.8535\n",
      "Epoch 605/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 4099.2681 - val_loss: 5305.4106\n",
      "Epoch 606/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3920.2529 - val_loss: 3302.2480\n",
      "Epoch 607/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3799.2444 - val_loss: 3358.2646\n",
      "Epoch 608/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2415.7236 - val_loss: 1801.9172\n",
      "Epoch 609/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1841.2874 - val_loss: 1605.4000\n",
      "Epoch 610/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2153.7893 - val_loss: 2579.5137\n",
      "Epoch 611/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1961.6622 - val_loss: 2463.4412\n",
      "Epoch 612/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2615.0701 - val_loss: 494.5316\n",
      "Epoch 613/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1803.4550 - val_loss: 549.3591\n",
      "Epoch 614/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 3592.0151 - val_loss: 5564.4756\n",
      "Epoch 615/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 4592.7124 - val_loss: 5947.4277\n",
      "Epoch 616/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 4902.5171 - val_loss: 5219.1733\n",
      "Epoch 617/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 3527.0605 - val_loss: 909.4428\n",
      "Epoch 618/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1345.0087 - val_loss: 867.7955\n",
      "Epoch 619/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1298.7390 - val_loss: 635.0612\n",
      "Epoch 620/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1270.8579 - val_loss: 2661.1709\n",
      "Epoch 621/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2224.2534 - val_loss: 1349.4917\n",
      "Epoch 622/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 5412.9180 - val_loss: 4719.0107\n",
      "Epoch 623/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3341.9097 - val_loss: 2600.3940\n",
      "Epoch 624/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 5337.4580 - val_loss: 3643.6792\n",
      "Epoch 625/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2097.7058 - val_loss: 2654.5640\n",
      "Epoch 626/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2697.1089 - val_loss: 783.7932\n",
      "Epoch 627/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1298.8765 - val_loss: 2038.0588\n",
      "Epoch 628/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2216.2607 - val_loss: 719.0635\n",
      "Epoch 629/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2284.8640 - val_loss: 1459.1086\n",
      "Epoch 630/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 851.7557 - val_loss: 912.6560\n",
      "Epoch 631/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1158.7495 - val_loss: 1041.0215\n",
      "Epoch 632/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1464.4764 - val_loss: 2280.0801\n",
      "Epoch 633/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2137.4773 - val_loss: 2018.7837\n",
      "Epoch 634/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2266.5566 - val_loss: 490.2212\n",
      "Epoch 635/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1139.6588 - val_loss: 1294.1404\n",
      "Epoch 636/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2108.3411 - val_loss: 898.9094\n",
      "Epoch 637/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2818.4666 - val_loss: 3614.0608\n",
      "Epoch 638/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2482.9077 - val_loss: 1278.5681\n",
      "Epoch 639/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1278.2444 - val_loss: 1329.5439\n",
      "Epoch 640/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1185.8440 - val_loss: 1197.0332\n",
      "Epoch 641/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1330.5046 - val_loss: 2114.4026\n",
      "Epoch 642/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1665.8917 - val_loss: 1122.4100\n",
      "Epoch 643/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1510.5327 - val_loss: 2387.6858\n",
      "Epoch 644/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1733.2295 - val_loss: 381.7181\n",
      "Epoch 645/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 620.8799 - val_loss: 595.8417\n",
      "Epoch 646/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 654.6691 - val_loss: 1201.7245\n",
      "Epoch 647/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3375.4358 - val_loss: 1931.3990\n",
      "Epoch 648/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2263.1975 - val_loss: 2496.2493\n",
      "Epoch 649/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2439.3508 - val_loss: 2659.7979\n",
      "Epoch 650/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2753.7166 - val_loss: 2771.9268\n",
      "Epoch 651/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3737.2336 - val_loss: 1267.8177\n",
      "Epoch 652/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 906.8759 - val_loss: 1238.8286\n",
      "Epoch 653/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 4734.1362 - val_loss: 4027.3320\n",
      "Epoch 654/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2423.0210 - val_loss: 2907.4778\n",
      "Epoch 655/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3305.0237 - val_loss: 2280.9207\n",
      "Epoch 656/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1993.1154 - val_loss: 1143.9880\n",
      "Epoch 657/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1276.0795 - val_loss: 1436.4862\n",
      "Epoch 658/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4056.9609 - val_loss: 3025.2090\n",
      "Epoch 659/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1816.5936 - val_loss: 1329.8036\n",
      "Epoch 660/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1466.2665 - val_loss: 2499.9302\n",
      "Epoch 661/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2565.8521 - val_loss: 4681.4570\n",
      "Epoch 662/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1238.6346 - val_loss: 508.4011\n",
      "Epoch 663/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1268.6604 - val_loss: 270.7325\n",
      "Epoch 664/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 475.8606 - val_loss: 324.7789\n",
      "Epoch 665/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 39ms/step - loss: 449.3194 - val_loss: 354.8985\n",
      "Epoch 666/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 3074.9036 - val_loss: 3099.0874\n",
      "Epoch 667/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2239.4744 - val_loss: 2458.0332\n",
      "Epoch 668/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2321.8940 - val_loss: 898.4435\n",
      "Epoch 669/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1458.5459 - val_loss: 1465.6427\n",
      "Epoch 670/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2790.5271 - val_loss: 1298.2218\n",
      "Epoch 671/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1406.9591 - val_loss: 1070.8700\n",
      "Epoch 672/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1980.0272 - val_loss: 2291.5435\n",
      "Epoch 673/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2344.9641 - val_loss: 3979.4919\n",
      "Epoch 674/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4134.8389 - val_loss: 977.3623\n",
      "Epoch 675/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2287.9758 - val_loss: 902.9486\n",
      "Epoch 676/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2137.8208 - val_loss: 991.0322\n",
      "Epoch 677/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3389.6382 - val_loss: 3329.4580\n",
      "Epoch 678/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2256.2708 - val_loss: 1934.0861\n",
      "Epoch 679/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2028.3652 - val_loss: 1494.8351\n",
      "Epoch 680/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2949.1616 - val_loss: 992.5653\n",
      "Epoch 681/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2194.4661 - val_loss: 1515.5355\n",
      "Epoch 682/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1582.9619 - val_loss: 1361.4996\n",
      "Epoch 683/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 931.5055 - val_loss: 510.0181\n",
      "Epoch 684/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2637.5254 - val_loss: 2162.2136\n",
      "Epoch 685/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1517.8644 - val_loss: 888.8459\n",
      "Epoch 686/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1576.4156 - val_loss: 1884.5731\n",
      "Epoch 687/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2080.9124 - val_loss: 3699.5510\n",
      "Epoch 688/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3844.7808 - val_loss: 557.2714\n",
      "Epoch 689/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1220.8479 - val_loss: 2985.7629\n",
      "Epoch 690/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1977.2428 - val_loss: 955.9488\n",
      "Epoch 691/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2684.7749 - val_loss: 3879.8743\n",
      "Epoch 692/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 3086.4788 - val_loss: 860.2522\n",
      "Epoch 693/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1937.4962 - val_loss: 884.2646\n",
      "Epoch 694/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2568.1353 - val_loss: 2225.4287\n",
      "Epoch 695/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2379.6870 - val_loss: 4085.8408\n",
      "Epoch 696/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3835.0298 - val_loss: 567.4871\n",
      "Epoch 697/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3522.6191 - val_loss: 4017.0449\n",
      "Epoch 698/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2852.3372 - val_loss: 1372.3270\n",
      "Epoch 699/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3986.1311 - val_loss: 3766.6755\n",
      "Epoch 700/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3067.3511 - val_loss: 4019.7109\n",
      "Epoch 701/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 6674.4287 - val_loss: 4684.3955\n",
      "Epoch 702/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2778.9380 - val_loss: 1548.8209\n",
      "Epoch 703/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1476.8060 - val_loss: 1584.0164\n",
      "Epoch 704/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3014.0544 - val_loss: 1140.5422\n",
      "Epoch 705/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1475.7850 - val_loss: 808.6910\n",
      "Epoch 706/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 676.6983 - val_loss: 568.9016\n",
      "Epoch 707/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 643.2032 - val_loss: 511.1556\n",
      "Epoch 708/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 539.4723 - val_loss: 442.8066\n",
      "Epoch 709/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 446.0065 - val_loss: 315.2899\n",
      "Epoch 710/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 325.1828 - val_loss: 311.5908\n",
      "Epoch 711/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 526.5967 - val_loss: 991.9847\n",
      "Epoch 712/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1099.1417 - val_loss: 999.4751\n",
      "Epoch 713/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1863.9283 - val_loss: 2959.5435\n",
      "Epoch 714/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2037.5682 - val_loss: 654.7654\n",
      "Epoch 715/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1753.5903 - val_loss: 2425.9861\n",
      "Epoch 716/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1794.6055 - val_loss: 3012.3552\n",
      "Epoch 717/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 5016.3770 - val_loss: 2756.3372\n",
      "Epoch 718/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1904.3110 - val_loss: 651.5023\n",
      "Epoch 719/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1971.2202 - val_loss: 1717.9774\n",
      "Epoch 720/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1611.1508 - val_loss: 1088.4393\n",
      "Epoch 721/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1218.5034 - val_loss: 2257.5815\n",
      "Epoch 722/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2042.3386 - val_loss: 1504.4397\n",
      "Epoch 723/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1620.4503 - val_loss: 1280.9109\n",
      "Epoch 724/4000\n",
      "11/11 [==============================] - 1s 37ms/step - loss: 2150.2253 - val_loss: 213.4698\n",
      "Epoch 725/4000\n",
      "11/11 [==============================] - 1s 37ms/step - loss: 2391.0637 - val_loss: 2086.5437\n",
      "Epoch 726/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1434.5333 - val_loss: 331.8043\n",
      "Epoch 727/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1736.3274 - val_loss: 887.4265\n",
      "Epoch 728/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1838.7695 - val_loss: 1688.6122\n",
      "Epoch 729/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1209.8068 - val_loss: 1274.1033\n",
      "Epoch 730/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1237.6604 - val_loss: 919.8350\n",
      "Epoch 731/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2039.0717 - val_loss: 2096.2908\n",
      "Epoch 732/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1601.6981 - val_loss: 1775.0033\n",
      "Epoch 733/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1395.2627 - val_loss: 1742.3938\n",
      "Epoch 734/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1444.3811 - val_loss: 1068.3354\n",
      "Epoch 735/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1561.4203 - val_loss: 2368.5088\n",
      "Epoch 736/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2018.1547 - val_loss: 2396.4297\n",
      "Epoch 737/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3701.3701 - val_loss: 1371.7054\n",
      "Epoch 738/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1207.2368 - val_loss: 3323.0376\n",
      "Epoch 739/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3939.8601 - val_loss: 3735.7219\n",
      "Epoch 740/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2230.1453 - val_loss: 1134.8496\n",
      "Epoch 741/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1281.4951 - val_loss: 1605.3184\n",
      "Epoch 742/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1480.8363 - val_loss: 1620.1702\n",
      "Epoch 743/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2146.6245 - val_loss: 644.0829\n",
      "Epoch 744/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1251.5648 - val_loss: 1480.7185\n",
      "Epoch 745/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1885.9537 - val_loss: 4695.9219\n",
      "Epoch 746/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1043.5465 - val_loss: 530.3017\n",
      "Epoch 747/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1429.4061 - val_loss: 273.5243\n",
      "Epoch 748/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 875.2880 - val_loss: 2186.4419\n",
      "Epoch 749/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4845.3936 - val_loss: 3525.1223\n",
      "Epoch 750/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1827.4724 - val_loss: 594.9495\n",
      "Epoch 751/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1477.9125 - val_loss: 1798.2295\n",
      "Epoch 752/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1002.2559 - val_loss: 677.1329\n",
      "Epoch 753/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 788.0355 - val_loss: 533.0013\n",
      "Epoch 754/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 684.7241 - val_loss: 1355.4293\n",
      "Epoch 755/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1843.8875 - val_loss: 838.3430\n",
      "Epoch 756/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2866.9910 - val_loss: 1587.1981\n",
      "Epoch 757/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 761.1975 - val_loss: 533.2586\n",
      "Epoch 758/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 557.1710 - val_loss: 424.2522\n",
      "Epoch 759/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2220.7590 - val_loss: 1761.2303\n",
      "Epoch 760/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1284.7825 - val_loss: 730.6439\n",
      "Epoch 761/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 566.2227 - val_loss: 353.2865\n",
      "Epoch 762/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 688.7493 - val_loss: 945.0474\n",
      "Epoch 763/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1182.2728 - val_loss: 1435.6849\n",
      "Epoch 764/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2369.1765 - val_loss: 228.2518\n",
      "Epoch 765/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1211.6005 - val_loss: 2001.7050\n",
      "Epoch 766/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2206.4512 - val_loss: 909.6616\n",
      "Epoch 767/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1396.3031 - val_loss: 639.8232\n",
      "Epoch 768/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3171.5479 - val_loss: 4443.7134\n",
      "Epoch 769/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3793.9978 - val_loss: 1629.6510\n",
      "Epoch 770/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 4537.7241 - val_loss: 3616.2500\n",
      "Epoch 771/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1881.0804 - val_loss: 416.3253\n",
      "Epoch 772/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2142.3308 - val_loss: 2605.5164\n",
      "Epoch 773/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1762.6069 - val_loss: 1785.5894\n",
      "Epoch 774/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1622.0270 - val_loss: 1717.8524\n",
      "Epoch 775/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2039.9138 - val_loss: 426.3510\n",
      "Epoch 776/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1469.5682 - val_loss: 1678.5770\n",
      "Epoch 777/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1452.7379 - val_loss: 414.4244\n",
      "Epoch 778/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1759.0154 - val_loss: 2272.8132\n",
      "Epoch 779/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1862.8801 - val_loss: 1794.2975\n",
      "Epoch 780/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1613.4603 - val_loss: 1823.5325\n",
      "Epoch 781/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1470.7629 - val_loss: 1479.5570\n",
      "Epoch 782/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1809.5023 - val_loss: 1561.2487\n",
      "Epoch 783/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2772.4128 - val_loss: 872.1212\n",
      "Epoch 784/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1002.5626 - val_loss: 414.4427\n",
      "Epoch 785/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1979.6702 - val_loss: 1513.7893\n",
      "Epoch 786/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2188.9229 - val_loss: 2696.1924\n",
      "Epoch 787/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2043.8324 - val_loss: 1902.1880\n",
      "Epoch 788/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1769.9202 - val_loss: 1299.9467\n",
      "Epoch 789/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1422.3221 - val_loss: 332.0538\n",
      "Epoch 790/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 506.3775 - val_loss: 444.7359\n",
      "Epoch 791/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 461.3436 - val_loss: 276.3897\n",
      "Epoch 792/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 274.5891 - val_loss: 151.8026\n",
      "Epoch 793/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 171.1311 - val_loss: 94.4986\n",
      "Epoch 794/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 303.4824 - val_loss: 1257.8007\n",
      "Epoch 795/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 4010.9504 - val_loss: 3109.8328\n",
      "Epoch 796/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2935.7937 - val_loss: 4866.8296\n",
      "Epoch 797/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 7225.3008 - val_loss: 4837.4263\n",
      "Epoch 798/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2940.4893 - val_loss: 516.8137\n",
      "Epoch 799/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1418.2794 - val_loss: 372.4589\n",
      "Epoch 800/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1131.0740 - val_loss: 2188.5808\n",
      "Epoch 801/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2285.9912 - val_loss: 336.3582\n",
      "Epoch 802/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1666.9058 - val_loss: 3365.1687\n",
      "Epoch 803/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3515.9534 - val_loss: 1007.5880\n",
      "Epoch 804/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1914.6255 - val_loss: 1092.1809\n",
      "Epoch 805/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2079.9319 - val_loss: 1523.2146\n",
      "Epoch 806/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1928.9178 - val_loss: 485.2205\n",
      "Epoch 807/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 983.8359 - val_loss: 1433.9288\n",
      "Epoch 808/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 505.7390 - val_loss: 361.5528\n",
      "Epoch 809/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 743.6790 - val_loss: 3119.5754\n",
      "Epoch 810/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 4689.5361 - val_loss: 2426.9507\n",
      "Epoch 811/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2459.2837 - val_loss: 4058.6733\n",
      "Epoch 812/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3829.4810 - val_loss: 6483.0234\n",
      "Epoch 813/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 5064.2378 - val_loss: 5279.4897\n",
      "Epoch 814/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4006.8384 - val_loss: 508.4660\n",
      "Epoch 815/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 40ms/step - loss: 1299.4010 - val_loss: 1321.7267\n",
      "Epoch 816/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 1731.4694 - val_loss: 477.3111\n",
      "Epoch 817/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 999.5084 - val_loss: 1429.6879\n",
      "Epoch 818/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1471.2570 - val_loss: 1029.1537\n",
      "Epoch 819/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1302.1123 - val_loss: 352.5032\n",
      "Epoch 820/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1066.7059 - val_loss: 1530.9321\n",
      "Epoch 821/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2981.1584 - val_loss: 980.5012\n",
      "Epoch 822/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2064.0544 - val_loss: 1796.8187\n",
      "Epoch 823/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1830.9446 - val_loss: 2103.3535\n",
      "Epoch 824/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1822.9565 - val_loss: 2134.1511\n",
      "Epoch 825/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1634.9148 - val_loss: 1149.9559\n",
      "Epoch 826/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1893.7590 - val_loss: 697.2952\n",
      "Epoch 827/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1790.5928 - val_loss: 277.7012\n",
      "Epoch 828/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 935.3582 - val_loss: 245.4083\n",
      "Epoch 829/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 483.8113 - val_loss: 479.4192\n",
      "Epoch 830/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 531.4656 - val_loss: 449.8647\n",
      "Epoch 831/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 363.1770 - val_loss: 204.5398\n",
      "Epoch 832/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 143.6135 - val_loss: 93.7132\n",
      "Epoch 833/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 415.2825 - val_loss: 4487.7939\n",
      "Epoch 834/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2859.3904 - val_loss: 1812.0624\n",
      "Epoch 835/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1467.9043 - val_loss: 1171.9561\n",
      "Epoch 836/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1510.1064 - val_loss: 3193.1096\n",
      "Epoch 837/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3148.0581 - val_loss: 651.8926\n",
      "Epoch 838/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1771.4836 - val_loss: 153.1090\n",
      "Epoch 839/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2182.6484 - val_loss: 1438.4855\n",
      "Epoch 840/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1707.2362 - val_loss: 3723.2371\n",
      "Epoch 841/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 4049.8289 - val_loss: 862.2123\n",
      "Epoch 842/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2127.3049 - val_loss: 1444.1288\n",
      "Epoch 843/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1576.8640 - val_loss: 1889.1993\n",
      "Epoch 844/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1351.9244 - val_loss: 868.4675\n",
      "Epoch 845/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2387.2505 - val_loss: 764.5957\n",
      "Epoch 846/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1218.2096 - val_loss: 1823.3141\n",
      "Epoch 847/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 3000.3877 - val_loss: 673.1633\n",
      "Epoch 848/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 3361.8215 - val_loss: 3975.0686\n",
      "Epoch 849/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 2899.6880 - val_loss: 589.7641\n",
      "Epoch 850/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1135.7542 - val_loss: 315.0869\n",
      "Epoch 851/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 487.2635 - val_loss: 476.3823\n",
      "Epoch 852/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 776.0029 - val_loss: 2375.8516\n",
      "Epoch 853/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2939.1060 - val_loss: 389.4595\n",
      "Epoch 854/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1198.7640 - val_loss: 793.3854\n",
      "Epoch 855/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2948.5122 - val_loss: 3172.6538\n",
      "Epoch 856/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2254.4543 - val_loss: 1214.7504\n",
      "Epoch 857/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1205.1635 - val_loss: 1671.1431\n",
      "Epoch 858/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1171.7207 - val_loss: 576.0104\n",
      "Epoch 859/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2758.5645 - val_loss: 1887.7863\n",
      "Epoch 860/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1375.0405 - val_loss: 3128.0835\n",
      "Epoch 861/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2106.5618 - val_loss: 628.7034\n",
      "Epoch 862/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1695.6527 - val_loss: 752.8428\n",
      "Epoch 863/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2970.4429 - val_loss: 3531.2949\n",
      "Epoch 864/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2671.8887 - val_loss: 1712.6554\n",
      "Epoch 865/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2057.9795 - val_loss: 456.6724\n",
      "Epoch 866/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1018.8387 - val_loss: 294.5937\n",
      "Epoch 867/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1044.4618 - val_loss: 2623.7271\n",
      "Epoch 868/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2260.0764 - val_loss: 1429.2570\n",
      "Epoch 869/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2636.7375 - val_loss: 655.9371\n",
      "Epoch 870/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 965.0594 - val_loss: 322.6953\n",
      "Epoch 871/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2414.4678 - val_loss: 2976.9827\n",
      "Epoch 872/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1905.0385 - val_loss: 1187.7356\n",
      "Epoch 873/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 983.1544 - val_loss: 1036.9110\n",
      "Epoch 874/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1579.5251 - val_loss: 528.1201\n",
      "Epoch 875/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1486.2350 - val_loss: 1045.0121\n",
      "Epoch 876/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1008.0404 - val_loss: 676.9142\n",
      "Epoch 877/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1615.2321 - val_loss: 3468.1941\n",
      "Epoch 878/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1839.6031 - val_loss: 598.1295\n",
      "Epoch 879/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2391.1277 - val_loss: 2403.3926\n",
      "Epoch 880/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1380.1722 - val_loss: 543.4059\n",
      "Epoch 881/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 668.6327 - val_loss: 541.0014\n",
      "Epoch 882/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 560.0752 - val_loss: 424.8798\n",
      "Epoch 883/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 619.3575 - val_loss: 1994.2839\n",
      "Epoch 884/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1819.7561 - val_loss: 1372.8009\n",
      "Epoch 885/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2145.8726 - val_loss: 1139.9901\n",
      "Epoch 886/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1416.6035 - val_loss: 704.0657\n",
      "Epoch 887/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1518.7954 - val_loss: 1165.8030\n",
      "Epoch 888/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1526.2499 - val_loss: 2855.6941\n",
      "Epoch 889/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2210.0190 - val_loss: 961.7751\n",
      "Epoch 890/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1155.8138 - val_loss: 1415.4998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 891/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 849.5574 - val_loss: 217.5288\n",
      "Epoch 892/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 246.4792 - val_loss: 163.6649\n",
      "Epoch 893/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 579.0627 - val_loss: 703.8738\n",
      "Epoch 894/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2033.9106 - val_loss: 695.4733\n",
      "Epoch 895/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1109.2180 - val_loss: 545.7350\n",
      "Epoch 896/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1374.6398 - val_loss: 473.1469\n",
      "Epoch 897/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1497.3363 - val_loss: 925.3810\n",
      "Epoch 898/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1063.2242 - val_loss: 945.7458\n",
      "Epoch 899/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1848.5392 - val_loss: 1791.1613\n",
      "Epoch 900/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1478.9897 - val_loss: 1171.5586\n",
      "Epoch 901/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 692.2598 - val_loss: 2127.5266\n",
      "Epoch 902/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 4369.9468 - val_loss: 2791.9365\n",
      "Epoch 903/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1798.1879 - val_loss: 1621.4949\n",
      "Epoch 904/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1797.9280 - val_loss: 645.5137\n",
      "Epoch 905/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1038.1417 - val_loss: 1490.6877\n",
      "Epoch 906/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1293.6022 - val_loss: 1268.1851\n",
      "Epoch 907/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1026.6284 - val_loss: 797.8980\n",
      "Epoch 908/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1272.4999 - val_loss: 1660.7855\n",
      "Epoch 909/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1497.2784 - val_loss: 1219.4128\n",
      "Epoch 910/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1325.9020 - val_loss: 3121.4160\n",
      "Epoch 911/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 3765.3633 - val_loss: 920.2473\n",
      "Epoch 912/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1439.6844 - val_loss: 566.2726\n",
      "Epoch 913/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1569.7037 - val_loss: 1032.8749\n",
      "Epoch 914/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1306.6669 - val_loss: 789.0447\n",
      "Epoch 915/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 500.3575 - val_loss: 325.3839\n",
      "Epoch 916/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 387.4320 - val_loss: 338.6409\n",
      "Epoch 917/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1022.7889 - val_loss: 1952.4985\n",
      "Epoch 918/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1329.0903 - val_loss: 2461.5637\n",
      "Epoch 919/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 5206.8071 - val_loss: 3825.0122\n",
      "Epoch 920/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2631.5830 - val_loss: 3309.4221\n",
      "Epoch 921/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3617.6331 - val_loss: 636.3407\n",
      "Epoch 922/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1854.7302 - val_loss: 1139.7161\n",
      "Epoch 923/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1202.9755 - val_loss: 332.3388\n",
      "Epoch 924/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1758.7000 - val_loss: 1110.4247\n",
      "Epoch 925/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1465.8260 - val_loss: 2829.4915\n",
      "Epoch 926/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2427.6331 - val_loss: 1246.8055\n",
      "Epoch 927/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1505.9598 - val_loss: 1699.3291\n",
      "Epoch 928/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1985.8491 - val_loss: 418.1741\n",
      "Epoch 929/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 862.4095 - val_loss: 3416.5667\n",
      "Epoch 930/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 4362.4629 - val_loss: 1603.0492\n",
      "Epoch 931/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2138.5627 - val_loss: 2932.1467\n",
      "Epoch 932/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1919.7042 - val_loss: 490.6923\n",
      "Epoch 933/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1287.6315 - val_loss: 1325.5664\n",
      "Epoch 934/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1853.1224 - val_loss: 5272.5117\n",
      "Epoch 935/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1472.2742 - val_loss: 592.3690\n",
      "Epoch 936/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2652.0105 - val_loss: 2676.9517\n",
      "Epoch 937/4000\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 1917.1133 - val_loss: 1610.9172\n",
      "Epoch 938/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1273.5043 - val_loss: 885.3526\n",
      "Epoch 939/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1322.9890 - val_loss: 2582.9419\n",
      "Epoch 940/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2101.4563 - val_loss: 607.4524\n",
      "Epoch 941/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1010.4994 - val_loss: 991.7897\n",
      "Epoch 942/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2490.1868 - val_loss: 4575.8677\n",
      "Epoch 943/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 4179.9707 - val_loss: 1803.1525\n",
      "Epoch 944/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1506.2180 - val_loss: 1011.4484\n",
      "Epoch 945/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2487.9180 - val_loss: 663.8350\n",
      "Epoch 946/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1130.3101 - val_loss: 297.6158\n",
      "Epoch 947/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1654.4611 - val_loss: 926.1190\n",
      "Epoch 948/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1411.9202 - val_loss: 1013.7682\n",
      "Epoch 949/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1855.4366 - val_loss: 1536.5322\n",
      "Epoch 950/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1490.9984 - val_loss: 1635.4421\n",
      "Epoch 951/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1778.1375 - val_loss: 2852.0906\n",
      "Epoch 952/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2424.6191 - val_loss: 551.6097\n",
      "Epoch 953/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 839.2013 - val_loss: 1282.1155\n",
      "Epoch 954/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 953.2683 - val_loss: 476.3270\n",
      "Epoch 955/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 710.8761 - val_loss: 602.6920\n",
      "Epoch 956/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 642.9855 - val_loss: 430.3023\n",
      "Epoch 957/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1008.8690 - val_loss: 1041.3132\n",
      "Epoch 958/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2342.4177 - val_loss: 4787.4297\n",
      "Epoch 959/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 4422.5186 - val_loss: 1790.2688\n",
      "Epoch 960/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1543.2817 - val_loss: 1790.6820\n",
      "Epoch 961/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1782.6377 - val_loss: 1570.3229\n",
      "Epoch 962/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1501.6572 - val_loss: 1114.5548\n",
      "Epoch 963/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2336.6096 - val_loss: 3684.0581\n",
      "Epoch 964/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 3063.0342 - val_loss: 179.2162\n",
      "Epoch 965/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 943.3286 - val_loss: 936.0890\n",
      "Epoch 966/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1357.7369 - val_loss: 176.9371\n",
      "Epoch 967/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 490.6389 - val_loss: 510.6087\n",
      "Epoch 968/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2375.5315 - val_loss: 1889.1083\n",
      "Epoch 969/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2234.4407 - val_loss: 3247.2754\n",
      "Epoch 970/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2688.7788 - val_loss: 1987.1145\n",
      "Epoch 971/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3411.6108 - val_loss: 3152.0078\n",
      "Epoch 972/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2621.0339 - val_loss: 4560.7344\n",
      "Epoch 973/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 6586.0278 - val_loss: 3995.4263\n",
      "Epoch 974/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2339.0488 - val_loss: 1345.7959\n",
      "Epoch 975/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1992.7847 - val_loss: 2915.4197\n",
      "Epoch 976/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3046.5120 - val_loss: 4883.2422\n",
      "Epoch 977/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2021.1448 - val_loss: 631.4888\n",
      "Epoch 978/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1417.4501 - val_loss: 627.6992\n",
      "Epoch 979/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1540.6077 - val_loss: 2522.1443\n",
      "Epoch 980/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1772.8466 - val_loss: 891.6501\n",
      "Epoch 981/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 762.4769 - val_loss: 530.3644\n",
      "Epoch 982/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1836.6851 - val_loss: 2533.4050\n",
      "Epoch 983/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1858.9778 - val_loss: 1645.7893\n",
      "Epoch 984/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1598.8691 - val_loss: 2981.5095\n",
      "Epoch 985/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 3509.8213 - val_loss: 1252.1760\n",
      "Epoch 986/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 780.2885 - val_loss: 797.6973\n",
      "Epoch 987/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3272.3037 - val_loss: 6140.3198\n",
      "Epoch 988/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 5919.0547 - val_loss: 1672.4436\n",
      "Epoch 989/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1040.9727 - val_loss: 972.9835\n",
      "Epoch 990/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2932.0676 - val_loss: 1570.3423\n",
      "Epoch 991/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 752.1042 - val_loss: 422.5853\n",
      "Epoch 992/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 522.4136 - val_loss: 377.4496\n",
      "Epoch 993/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 365.0281 - val_loss: 157.3672\n",
      "Epoch 994/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 433.1727 - val_loss: 133.7314\n",
      "Epoch 995/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2251.8953 - val_loss: 2154.7832\n",
      "Epoch 996/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1560.9065 - val_loss: 890.9431\n",
      "Epoch 997/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1556.6309 - val_loss: 1808.5475\n",
      "Epoch 998/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1384.4443 - val_loss: 2517.6387\n",
      "Epoch 999/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2543.7117 - val_loss: 6350.5337\n",
      "Epoch 1000/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3432.9460 - val_loss: 2800.6062\n",
      "Epoch 1001/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1769.8054 - val_loss: 2669.2974\n",
      "Epoch 1002/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2729.7593 - val_loss: 1519.0775\n",
      "Epoch 1003/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 785.2592 - val_loss: 1475.5022\n",
      "Epoch 1004/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1600.8256 - val_loss: 268.8977\n",
      "Epoch 1005/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1583.6329 - val_loss: 662.3370\n",
      "Epoch 1006/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1864.2225 - val_loss: 1610.1224\n",
      "Epoch 1007/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 1350.3613 - val_loss: 1000.2529\n",
      "Epoch 1008/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 582.9495 - val_loss: 392.2048\n",
      "Epoch 1009/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1618.1583 - val_loss: 3838.1492\n",
      "Epoch 1010/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 3369.5635 - val_loss: 1448.5916\n",
      "Epoch 1011/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 339.7380 - val_loss: 194.1289\n",
      "Epoch 1012/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1850.8593 - val_loss: 1912.5597\n",
      "Epoch 1013/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2008.6012 - val_loss: 3466.5759\n",
      "Epoch 1014/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3238.0068 - val_loss: 592.4305\n",
      "Epoch 1015/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1569.9714 - val_loss: 643.2061\n",
      "Epoch 1016/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1507.5001 - val_loss: 4158.8398\n",
      "Epoch 1017/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1640.0259 - val_loss: 892.0347\n",
      "Epoch 1018/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 550.5911 - val_loss: 1077.4694\n",
      "Epoch 1019/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2884.0706 - val_loss: 1322.1913\n",
      "Epoch 1020/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1594.3516 - val_loss: 814.3612\n",
      "Epoch 1021/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1915.3408 - val_loss: 2204.8799\n",
      "Epoch 1022/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1575.9663 - val_loss: 1003.2904\n",
      "Epoch 1023/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 815.3060 - val_loss: 607.3752\n",
      "Epoch 1024/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1628.4286 - val_loss: 1195.6809\n",
      "Epoch 1025/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1137.3915 - val_loss: 299.8406\n",
      "Epoch 1026/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2955.8853 - val_loss: 2653.8801\n",
      "Epoch 1027/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1721.9271 - val_loss: 2488.0508\n",
      "Epoch 1028/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2517.7410 - val_loss: 3125.4458\n",
      "Epoch 1029/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1369.9883 - val_loss: 629.8965\n",
      "Epoch 1030/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2107.1567 - val_loss: 869.9481\n",
      "Epoch 1031/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 662.8226 - val_loss: 513.5594\n",
      "Epoch 1032/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 650.4091 - val_loss: 483.0962\n",
      "Epoch 1033/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 470.5718 - val_loss: 261.0003\n",
      "Epoch 1034/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 957.0743 - val_loss: 2890.6824\n",
      "Epoch 1035/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2739.1318 - val_loss: 746.9048\n",
      "Epoch 1036/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1802.3263 - val_loss: 1393.1826\n",
      "Epoch 1037/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1585.7878 - val_loss: 623.2820\n",
      "Epoch 1038/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2117.2949 - val_loss: 1297.5482\n",
      "Epoch 1039/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1245.5150 - val_loss: 331.6408\n",
      "Epoch 1040/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2275.9231 - val_loss: 2493.5056\n",
      "Epoch 1041/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 39ms/step - loss: 1424.8546 - val_loss: 404.5467\n",
      "Epoch 1042/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2106.4651 - val_loss: 2960.6423\n",
      "Epoch 1043/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1696.3877 - val_loss: 388.1501\n",
      "Epoch 1044/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 864.0253 - val_loss: 2591.5176\n",
      "Epoch 1045/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 3564.3254 - val_loss: 1089.6051\n",
      "Epoch 1046/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1513.6188 - val_loss: 414.3343\n",
      "Epoch 1047/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1613.2299 - val_loss: 801.3346\n",
      "Epoch 1048/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1985.5239 - val_loss: 2177.4387\n",
      "Epoch 1049/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1494.7021 - val_loss: 1015.7535\n",
      "Epoch 1050/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1476.0878 - val_loss: 1994.6130\n",
      "Epoch 1051/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1916.7897 - val_loss: 2910.3730\n",
      "Epoch 1052/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3723.0200 - val_loss: 1053.9819\n",
      "Epoch 1053/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1637.6259 - val_loss: 548.7670\n",
      "Epoch 1054/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2181.5249 - val_loss: 1383.9004\n",
      "Epoch 1055/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1744.8037 - val_loss: 1732.2572\n",
      "Epoch 1056/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1030.6708 - val_loss: 691.9492\n",
      "Epoch 1057/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1526.9480 - val_loss: 1997.6434\n",
      "Epoch 1058/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1192.6749 - val_loss: 904.0354\n",
      "Epoch 1059/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1166.0236 - val_loss: 1549.8961\n",
      "Epoch 1060/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1518.1655 - val_loss: 423.1113\n",
      "Epoch 1061/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 949.6921 - val_loss: 2975.1748\n",
      "Epoch 1062/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3481.0933 - val_loss: 672.4756\n",
      "Epoch 1063/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3402.6658 - val_loss: 4882.6118\n",
      "Epoch 1064/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4320.8423 - val_loss: 1300.6129\n",
      "Epoch 1065/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1387.1377 - val_loss: 1399.4741\n",
      "Epoch 1066/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1906.2678 - val_loss: 1543.8153\n",
      "Epoch 1067/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1618.0355 - val_loss: 1085.8203\n",
      "Epoch 1068/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2824.7910 - val_loss: 4381.7319\n",
      "Epoch 1069/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 3548.8403 - val_loss: 494.3363\n",
      "Epoch 1070/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1366.2865 - val_loss: 1629.6672\n",
      "Epoch 1071/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1724.9634 - val_loss: 554.1162\n",
      "Epoch 1072/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 906.0454 - val_loss: 333.0779\n",
      "Epoch 1073/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 784.5273 - val_loss: 1565.2803\n",
      "Epoch 1074/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3045.2178 - val_loss: 1141.8765\n",
      "Epoch 1075/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2158.4329 - val_loss: 2328.7573\n",
      "Epoch 1076/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1367.2277 - val_loss: 751.7531\n",
      "Epoch 1077/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 652.6494 - val_loss: 565.1594\n",
      "Epoch 1078/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 702.6547 - val_loss: 587.2972\n",
      "Epoch 1079/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 623.6933 - val_loss: 387.2617\n",
      "Epoch 1080/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 344.9349 - val_loss: 171.5457\n",
      "Epoch 1081/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 155.7498 - val_loss: 88.0128\n",
      "Epoch 1082/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 113.3856 - val_loss: 57.9984\n",
      "Epoch 1083/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2418.8586 - val_loss: 2129.2949\n",
      "Epoch 1084/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2585.7061 - val_loss: 4387.7383\n",
      "Epoch 1085/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 4446.9678 - val_loss: 1045.6151\n",
      "Epoch 1086/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3766.7510 - val_loss: 4805.5957\n",
      "Epoch 1087/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3657.3655 - val_loss: 6141.9097\n",
      "Epoch 1088/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1578.9619 - val_loss: 1041.3572\n",
      "Epoch 1089/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1236.2510 - val_loss: 870.5251\n",
      "Epoch 1090/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1026.4232 - val_loss: 2402.2566\n",
      "Epoch 1091/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2840.7185 - val_loss: 1741.2666\n",
      "Epoch 1092/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2622.1858 - val_loss: 5441.4263\n",
      "Epoch 1093/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 6376.9712 - val_loss: 3182.4700\n",
      "Epoch 1094/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2166.1216 - val_loss: 693.4656\n",
      "Epoch 1095/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1555.1205 - val_loss: 2358.1582\n",
      "Epoch 1096/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2787.3789 - val_loss: 2769.0352\n",
      "Epoch 1097/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1460.7406 - val_loss: 2893.0212\n",
      "Epoch 1098/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4351.4307 - val_loss: 2015.3691\n",
      "Epoch 1099/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2212.9456 - val_loss: 2721.3813\n",
      "Epoch 1100/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2206.7761 - val_loss: 2071.6357\n",
      "Epoch 1101/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 4665.7529 - val_loss: 3549.4097\n",
      "Epoch 1102/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2526.3855 - val_loss: 1833.7307\n",
      "Epoch 1103/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1917.4897 - val_loss: 2261.2844\n",
      "Epoch 1104/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2243.4089 - val_loss: 293.7775\n",
      "Epoch 1105/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 993.2383 - val_loss: 864.3961\n",
      "Epoch 1106/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3698.4146 - val_loss: 3057.0364\n",
      "Epoch 1107/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2382.4543 - val_loss: 2098.2910\n",
      "Epoch 1108/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1628.5795 - val_loss: 573.1358\n",
      "Epoch 1109/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 961.8640 - val_loss: 1441.1035\n",
      "Epoch 1110/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 849.8231 - val_loss: 354.0696\n",
      "Epoch 1111/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 493.4142 - val_loss: 414.0801\n",
      "Epoch 1112/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 425.5053 - val_loss: 282.2947\n",
      "Epoch 1113/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 271.3370 - val_loss: 122.5663\n",
      "Epoch 1114/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2786.4504 - val_loss: 2907.7476\n",
      "Epoch 1115/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1432.4241 - val_loss: 371.3028\n",
      "Epoch 1116/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 42ms/step - loss: 2913.8784 - val_loss: 3252.6423\n",
      "Epoch 1117/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2421.2856 - val_loss: 1280.9779\n",
      "Epoch 1118/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1273.8898 - val_loss: 1718.1027\n",
      "Epoch 1119/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1470.9000 - val_loss: 1833.5261\n",
      "Epoch 1120/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1639.8505 - val_loss: 652.6412\n",
      "Epoch 1121/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 673.0865 - val_loss: 231.7246\n",
      "Epoch 1122/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1564.0522 - val_loss: 3364.7434\n",
      "Epoch 1123/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2716.5540 - val_loss: 567.1959\n",
      "Epoch 1124/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1307.7177 - val_loss: 1575.1014\n",
      "Epoch 1125/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 3385.1655 - val_loss: 3204.2722\n",
      "Epoch 1126/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2323.8105 - val_loss: 1398.9558\n",
      "Epoch 1127/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1435.9832 - val_loss: 1549.5911\n",
      "Epoch 1128/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1528.6274 - val_loss: 1293.9835\n",
      "Epoch 1129/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2521.8433 - val_loss: 822.2798\n",
      "Epoch 1130/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 953.5983 - val_loss: 833.5786\n",
      "Epoch 1131/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1180.4436 - val_loss: 635.5610\n",
      "Epoch 1132/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 435.8532 - val_loss: 497.3738\n",
      "Epoch 1133/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 566.4856 - val_loss: 407.3423\n",
      "Epoch 1134/4000\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 380.5406 - val_loss: 184.0161\n",
      "Epoch 1135/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 315.3909 - val_loss: 2925.8616\n",
      "Epoch 1136/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 4884.8315 - val_loss: 5074.7319\n",
      "Epoch 1137/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3705.8086 - val_loss: 5293.0522\n",
      "Epoch 1138/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3627.7312 - val_loss: 2924.9836\n",
      "Epoch 1139/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1857.5745 - val_loss: 1946.5040\n",
      "Epoch 1140/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1969.7048 - val_loss: 1533.6069\n",
      "Epoch 1141/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1147.0037 - val_loss: 1121.1068\n",
      "Epoch 1142/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2139.0166 - val_loss: 240.5189\n",
      "Epoch 1143/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2537.4548 - val_loss: 2041.1077\n",
      "Epoch 1144/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1391.3079 - val_loss: 1735.3656\n",
      "Epoch 1145/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1781.2443 - val_loss: 1332.3463\n",
      "Epoch 1146/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1650.3508 - val_loss: 1805.4397\n",
      "Epoch 1147/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1927.8248 - val_loss: 3888.2634\n",
      "Epoch 1148/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1785.4126 - val_loss: 1602.3022\n",
      "Epoch 1149/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 827.8088 - val_loss: 877.9417\n",
      "Epoch 1150/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1524.1146 - val_loss: 1487.8768\n",
      "Epoch 1151/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2277.7720 - val_loss: 2685.2148\n",
      "Epoch 1152/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1996.0510 - val_loss: 2455.6064\n",
      "Epoch 1153/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3383.8357 - val_loss: 1005.0098\n",
      "Epoch 1154/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 792.4628 - val_loss: 1071.9916\n",
      "Epoch 1155/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1938.0673 - val_loss: 794.2078\n",
      "Epoch 1156/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 370.5041 - val_loss: 190.4788\n",
      "Epoch 1157/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 179.8907 - val_loss: 128.2315\n",
      "Epoch 1158/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 151.7332 - val_loss: 274.4581\n",
      "Epoch 1159/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2174.0950 - val_loss: 3630.0872\n",
      "Epoch 1160/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2720.2231 - val_loss: 384.0479\n",
      "Epoch 1161/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 855.4258 - val_loss: 1517.0963\n",
      "Epoch 1162/4000\n",
      "11/11 [==============================] - 1s 37ms/step - loss: 1196.7864 - val_loss: 936.9287\n",
      "Epoch 1163/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1576.3226 - val_loss: 219.1245\n",
      "Epoch 1164/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 843.0942 - val_loss: 1735.7523\n",
      "Epoch 1165/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2060.6528 - val_loss: 282.0010\n",
      "Epoch 1166/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1938.9935 - val_loss: 1786.0406\n",
      "Epoch 1167/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1564.4645 - val_loss: 1550.2511\n",
      "Epoch 1168/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1821.8752 - val_loss: 2321.2083\n",
      "Epoch 1169/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1513.2085 - val_loss: 281.8439\n",
      "Epoch 1170/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 650.9098 - val_loss: 1044.0708\n",
      "Epoch 1171/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 813.3824 - val_loss: 1669.0618\n",
      "Epoch 1172/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1481.7986 - val_loss: 2664.4062\n",
      "Epoch 1173/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1737.2186 - val_loss: 605.4185\n",
      "Epoch 1174/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 553.5466 - val_loss: 1086.4507\n",
      "Epoch 1175/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3317.1016 - val_loss: 1681.4821\n",
      "Epoch 1176/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2378.0269 - val_loss: 3683.2839\n",
      "Epoch 1177/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3128.8845 - val_loss: 723.2457\n",
      "Epoch 1178/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3252.4976 - val_loss: 2533.8977\n",
      "Epoch 1179/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2188.0500 - val_loss: 3825.6550\n",
      "Epoch 1180/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4220.8667 - val_loss: 1536.2003\n",
      "Epoch 1181/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2009.5653 - val_loss: 3626.4373\n",
      "Epoch 1182/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3228.2839 - val_loss: 5956.0977\n",
      "Epoch 1183/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1704.8909 - val_loss: 2037.8013\n",
      "Epoch 1184/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1800.9329 - val_loss: 577.7349\n",
      "Epoch 1185/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2901.9321 - val_loss: 3966.7576\n",
      "Epoch 1186/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2626.6455 - val_loss: 694.9069\n",
      "Epoch 1187/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1083.5416 - val_loss: 1445.0835\n",
      "Epoch 1188/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2770.8997 - val_loss: 1099.6619\n",
      "Epoch 1189/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 761.8939 - val_loss: 819.5770\n",
      "Epoch 1190/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1103.6243 - val_loss: 2088.8074\n",
      "Epoch 1191/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 38ms/step - loss: 3657.5420 - val_loss: 1764.2219\n",
      "Epoch 1192/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 922.2116 - val_loss: 239.6459\n",
      "Epoch 1193/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 317.1171 - val_loss: 194.6185\n",
      "Epoch 1194/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 254.3935 - val_loss: 157.8159\n",
      "Epoch 1195/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2459.7175 - val_loss: 3413.1089\n",
      "Epoch 1196/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2307.0579 - val_loss: 283.4512\n",
      "Epoch 1197/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2554.5876 - val_loss: 2333.1377\n",
      "Epoch 1198/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1791.9161 - val_loss: 1199.4979\n",
      "Epoch 1199/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2249.2097 - val_loss: 2912.7654\n",
      "Epoch 1200/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2210.3130 - val_loss: 1883.5352\n",
      "Epoch 1201/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2255.2136 - val_loss: 296.9297\n",
      "Epoch 1202/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1950.7771 - val_loss: 1686.2100\n",
      "Epoch 1203/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 931.7507 - val_loss: 968.5145\n",
      "Epoch 1204/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1820.9718 - val_loss: 3522.6182\n",
      "Epoch 1205/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3662.0059 - val_loss: 643.4794\n",
      "Epoch 1206/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 966.8622 - val_loss: 952.8167\n",
      "Epoch 1207/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3442.8853 - val_loss: 2360.2576\n",
      "Epoch 1208/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1258.0480 - val_loss: 546.4793\n",
      "Epoch 1209/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 929.8781 - val_loss: 1024.6819\n",
      "Epoch 1210/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 874.6285 - val_loss: 564.2554\n",
      "Epoch 1211/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 560.5854 - val_loss: 334.4220\n",
      "Epoch 1212/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 297.2653 - val_loss: 154.8459\n",
      "Epoch 1213/4000\n",
      "11/11 [==============================] - 1s 37ms/step - loss: 547.7479 - val_loss: 1065.3420\n",
      "Epoch 1214/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 4537.4795 - val_loss: 4192.8315\n",
      "Epoch 1215/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3014.9705 - val_loss: 2064.5808\n",
      "Epoch 1216/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4643.0249 - val_loss: 3012.2419\n",
      "Epoch 1217/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2055.2463 - val_loss: 2041.9701\n",
      "Epoch 1218/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1812.8939 - val_loss: 825.2787\n",
      "Epoch 1219/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1353.1642 - val_loss: 2299.9814\n",
      "Epoch 1220/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1959.1019 - val_loss: 1313.9913\n",
      "Epoch 1221/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 5697.3433 - val_loss: 5192.5913\n",
      "Epoch 1222/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3830.9929 - val_loss: 702.4491\n",
      "Epoch 1223/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 869.4729 - val_loss: 2296.3174\n",
      "Epoch 1224/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 4566.3545 - val_loss: 2771.8621\n",
      "Epoch 1225/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2960.7292 - val_loss: 4688.2207\n",
      "Epoch 1226/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 5751.7832 - val_loss: 2737.7800\n",
      "Epoch 1227/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2059.0491 - val_loss: 1825.0498\n",
      "Epoch 1228/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1497.9775 - val_loss: 2007.1821\n",
      "Epoch 1229/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1776.6667 - val_loss: 419.0314\n",
      "Epoch 1230/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 926.5405 - val_loss: 3200.0198\n",
      "Epoch 1231/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4096.2612 - val_loss: 1836.8622\n",
      "Epoch 1232/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1427.3287 - val_loss: 2231.2935\n",
      "Epoch 1233/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1890.1825 - val_loss: 1265.8452\n",
      "Epoch 1234/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1562.7520 - val_loss: 2226.6958\n",
      "Epoch 1235/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2052.0479 - val_loss: 631.4807\n",
      "Epoch 1236/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2170.0085 - val_loss: 1079.3864\n",
      "Epoch 1237/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1277.1681 - val_loss: 1972.0846\n",
      "Epoch 1238/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1743.2927 - val_loss: 2961.2339\n",
      "Epoch 1239/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3664.1353 - val_loss: 942.4491\n",
      "Epoch 1240/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 752.7786 - val_loss: 395.7742\n",
      "Epoch 1241/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 374.4407 - val_loss: 415.0575\n",
      "Epoch 1242/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1195.6384 - val_loss: 234.8519\n",
      "Epoch 1243/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 371.7319 - val_loss: 428.9643\n",
      "Epoch 1244/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 420.7617 - val_loss: 183.5136\n",
      "Epoch 1245/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 202.1853 - val_loss: 206.9955\n",
      "Epoch 1246/4000\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 1141.3481 - val_loss: 1416.5095\n",
      "Epoch 1247/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1078.2421 - val_loss: 646.3322\n",
      "Epoch 1248/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1868.0454 - val_loss: 2660.5547\n",
      "Epoch 1249/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2143.0532 - val_loss: 1283.4202\n",
      "Epoch 1250/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1330.2491 - val_loss: 1310.5234\n",
      "Epoch 1251/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1291.7661 - val_loss: 215.2577\n",
      "Epoch 1252/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 455.8975 - val_loss: 417.2211\n",
      "Epoch 1253/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 532.5282 - val_loss: 333.9854\n",
      "Epoch 1254/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 608.6187 - val_loss: 636.9614\n",
      "Epoch 1255/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1965.3157 - val_loss: 783.8389\n",
      "Epoch 1256/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1949.7190 - val_loss: 4049.7534\n",
      "Epoch 1257/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3884.6160 - val_loss: 372.5721\n",
      "Epoch 1258/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3812.8262 - val_loss: 4676.5142\n",
      "Epoch 1259/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3440.2991 - val_loss: 3615.7039\n",
      "Epoch 1260/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 4025.0693 - val_loss: 3739.7388\n",
      "Epoch 1261/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2769.5190 - val_loss: 1473.9496\n",
      "Epoch 1262/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1206.2489 - val_loss: 373.6027\n",
      "Epoch 1263/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 368.5034 - val_loss: 166.7764\n",
      "Epoch 1264/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 362.2887 - val_loss: 943.2948\n",
      "Epoch 1265/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2078.5364 - val_loss: 1211.8121\n",
      "Epoch 1266/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 43ms/step - loss: 704.4760 - val_loss: 811.5761\n",
      "Epoch 1267/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2701.0452 - val_loss: 1416.5869\n",
      "Epoch 1268/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1198.2272 - val_loss: 1877.3955\n",
      "Epoch 1269/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1480.7406 - val_loss: 559.9226\n",
      "Epoch 1270/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2237.2742 - val_loss: 3484.6699\n",
      "Epoch 1271/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2488.3538 - val_loss: 1410.0898\n",
      "Epoch 1272/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 6623.8550 - val_loss: 6516.9683\n",
      "Epoch 1273/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 5157.4116 - val_loss: 1747.1729\n",
      "Epoch 1274/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1284.3759 - val_loss: 1079.0917\n",
      "Epoch 1275/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1909.5583 - val_loss: 1685.3077\n",
      "Epoch 1276/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1334.5271 - val_loss: 672.4026\n",
      "Epoch 1277/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 618.7910 - val_loss: 470.2031\n",
      "Epoch 1278/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1514.0095 - val_loss: 3032.6384\n",
      "Epoch 1279/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2708.1277 - val_loss: 172.3204\n",
      "Epoch 1280/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 990.4752 - val_loss: 673.5388\n",
      "Epoch 1281/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2325.3379 - val_loss: 1038.5109\n",
      "Epoch 1282/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1754.6329 - val_loss: 2732.6707\n",
      "Epoch 1283/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2118.4626 - val_loss: 1194.1410\n",
      "Epoch 1284/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1302.5714 - val_loss: 1331.4098\n",
      "Epoch 1285/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1375.4138 - val_loss: 1319.2195\n",
      "Epoch 1286/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2732.5957 - val_loss: 977.6353\n",
      "Epoch 1287/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1218.0543 - val_loss: 466.9368\n",
      "Epoch 1288/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 899.9678 - val_loss: 409.2379\n",
      "Epoch 1289/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 373.2100 - val_loss: 283.6869\n",
      "Epoch 1290/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 895.4683 - val_loss: 3027.6724\n",
      "Epoch 1291/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 3555.1013 - val_loss: 986.5154\n",
      "Epoch 1292/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1854.0558 - val_loss: 2965.4468\n",
      "Epoch 1293/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2083.9661 - val_loss: 647.2082\n",
      "Epoch 1294/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1365.8041 - val_loss: 2302.4988\n",
      "Epoch 1295/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1619.8604 - val_loss: 536.6747\n",
      "Epoch 1296/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 470.4251 - val_loss: 192.9288\n",
      "Epoch 1297/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 242.7020 - val_loss: 152.7284\n",
      "Epoch 1298/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 128.0266 - val_loss: 78.7640\n",
      "Epoch 1299/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 411.6447 - val_loss: 1747.6183\n",
      "Epoch 1300/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1586.3069 - val_loss: 1291.6842\n",
      "Epoch 1301/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2651.0181 - val_loss: 1770.2372\n",
      "Epoch 1302/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3121.2151 - val_loss: 5763.9399\n",
      "Epoch 1303/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 6616.9883 - val_loss: 3144.1240\n",
      "Epoch 1304/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1762.8195 - val_loss: 923.9972\n",
      "Epoch 1305/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 931.2177 - val_loss: 877.1890\n",
      "Epoch 1306/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1916.9305 - val_loss: 3101.7969\n",
      "Epoch 1307/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2621.4639 - val_loss: 934.1642\n",
      "Epoch 1308/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1612.0029 - val_loss: 542.2936\n",
      "Epoch 1309/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1984.9600 - val_loss: 467.6177\n",
      "Epoch 1310/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2602.0640 - val_loss: 3122.8540\n",
      "Epoch 1311/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2199.8938 - val_loss: 1012.8017\n",
      "Epoch 1312/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1103.7393 - val_loss: 682.8051\n",
      "Epoch 1313/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1363.3525 - val_loss: 2294.7112\n",
      "Epoch 1314/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1810.4446 - val_loss: 1995.8051\n",
      "Epoch 1315/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2892.7207 - val_loss: 704.1580\n",
      "Epoch 1316/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 3235.3916 - val_loss: 4839.7046\n",
      "Epoch 1317/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 4189.5215 - val_loss: 667.2032\n",
      "Epoch 1318/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1895.8264 - val_loss: 1815.0896\n",
      "Epoch 1319/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1132.7698 - val_loss: 749.7678\n",
      "Epoch 1320/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 595.7062 - val_loss: 278.2401\n",
      "Epoch 1321/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1558.8026 - val_loss: 1053.8823\n",
      "Epoch 1322/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1743.8196 - val_loss: 2044.4426\n",
      "Epoch 1323/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1297.4420 - val_loss: 1238.3350\n",
      "Epoch 1324/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 982.3569 - val_loss: 263.9014\n",
      "Epoch 1325/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 334.6245 - val_loss: 262.3818\n",
      "Epoch 1326/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 254.2157 - val_loss: 127.2692\n",
      "Epoch 1327/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 125.3015 - val_loss: 58.9215\n",
      "Epoch 1328/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2231.3372 - val_loss: 1909.9247\n",
      "Epoch 1329/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1601.9863 - val_loss: 2755.8079\n",
      "Epoch 1330/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2623.1318 - val_loss: 277.9091\n",
      "Epoch 1331/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 980.4613 - val_loss: 2180.8000\n",
      "Epoch 1332/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 3080.2122 - val_loss: 969.0432\n",
      "Epoch 1333/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1916.1782 - val_loss: 4103.0220\n",
      "Epoch 1334/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4072.0300 - val_loss: 672.4728\n",
      "Epoch 1335/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1608.1465 - val_loss: 2610.7983\n",
      "Epoch 1336/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1498.8684 - val_loss: 1345.0950\n",
      "Epoch 1337/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2050.8438 - val_loss: 799.7233\n",
      "Epoch 1338/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2940.4290 - val_loss: 4769.0361\n",
      "Epoch 1339/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 4055.0686 - val_loss: 225.6985\n",
      "Epoch 1340/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1417.3636 - val_loss: 513.2804\n",
      "Epoch 1341/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 39ms/step - loss: 2103.2590 - val_loss: 2601.5317\n",
      "Epoch 1342/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1797.4355 - val_loss: 1107.4304\n",
      "Epoch 1343/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1222.6333 - val_loss: 1661.4210\n",
      "Epoch 1344/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1536.7150 - val_loss: 392.8163\n",
      "Epoch 1345/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2244.9021 - val_loss: 2553.4451\n",
      "Epoch 1346/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1955.2312 - val_loss: 1188.6879\n",
      "Epoch 1347/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1031.6572 - val_loss: 847.9753\n",
      "Epoch 1348/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1340.8726 - val_loss: 2132.5251\n",
      "Epoch 1349/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1499.8240 - val_loss: 401.6284\n",
      "Epoch 1350/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 794.8223 - val_loss: 2452.5657\n",
      "Epoch 1351/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3558.4468 - val_loss: 1227.7688\n",
      "Epoch 1352/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2300.3127 - val_loss: 3440.1667\n",
      "Epoch 1353/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2795.1555 - val_loss: 291.1016\n",
      "Epoch 1354/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2102.0881 - val_loss: 3295.4375\n",
      "Epoch 1355/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2337.6943 - val_loss: 887.8353\n",
      "Epoch 1356/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1275.4751 - val_loss: 1784.9362\n",
      "Epoch 1357/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3521.3281 - val_loss: 1880.7567\n",
      "Epoch 1358/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1111.7684 - val_loss: 447.4952\n",
      "Epoch 1359/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 664.2145 - val_loss: 574.5066\n",
      "Epoch 1360/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 607.1752 - val_loss: 391.6569\n",
      "Epoch 1361/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 437.4611 - val_loss: 206.5072\n",
      "Epoch 1362/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1918.8810 - val_loss: 1284.0526\n",
      "Epoch 1363/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1942.4398 - val_loss: 2996.6038\n",
      "Epoch 1364/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2241.0618 - val_loss: 1715.2268\n",
      "Epoch 1365/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1918.2814 - val_loss: 4155.3857\n",
      "Epoch 1366/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 710.2523 - val_loss: 484.9242\n",
      "Epoch 1367/4000\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 3357.7437 - val_loss: 2984.3350\n",
      "Epoch 1368/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 1908.4808 - val_loss: 1625.3169\n",
      "Epoch 1369/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1143.0320 - val_loss: 1111.2173\n",
      "Epoch 1370/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1645.5117 - val_loss: 4351.1255\n",
      "Epoch 1371/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1432.0123 - val_loss: 1879.5275\n",
      "Epoch 1372/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2020.9188 - val_loss: 725.0696\n",
      "Epoch 1373/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1836.0818 - val_loss: 1756.5630\n",
      "Epoch 1374/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1189.9585 - val_loss: 800.1301\n",
      "Epoch 1375/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1629.0359 - val_loss: 2652.3875\n",
      "Epoch 1376/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1749.4249 - val_loss: 474.0757\n",
      "Epoch 1377/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1316.4042 - val_loss: 2604.2195\n",
      "Epoch 1378/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2068.8792 - val_loss: 266.4846\n",
      "Epoch 1379/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2077.9351 - val_loss: 2347.6389\n",
      "Epoch 1380/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1351.2712 - val_loss: 468.2617\n",
      "Epoch 1381/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 487.0967 - val_loss: 266.7063\n",
      "Epoch 1382/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 231.2114 - val_loss: 178.0557\n",
      "Epoch 1383/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 623.7054 - val_loss: 1727.1877\n",
      "Epoch 1384/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1263.2476 - val_loss: 732.8056\n",
      "Epoch 1385/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2961.6736 - val_loss: 2163.4338\n",
      "Epoch 1386/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1483.9473 - val_loss: 565.2962\n",
      "Epoch 1387/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2248.8872 - val_loss: 2192.2629\n",
      "Epoch 1388/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 997.0256 - val_loss: 120.2000\n",
      "Epoch 1389/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 1138.1135 - val_loss: 676.2260\n",
      "Epoch 1390/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1454.8304 - val_loss: 2460.5610\n",
      "Epoch 1391/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1499.7427 - val_loss: 626.3245\n",
      "Epoch 1392/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1738.3613 - val_loss: 2389.5994\n",
      "Epoch 1393/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1522.1235 - val_loss: 1663.3164\n",
      "Epoch 1394/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1699.7640 - val_loss: 565.3329\n",
      "Epoch 1395/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 824.8765 - val_loss: 907.1850\n",
      "Epoch 1396/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1310.7657 - val_loss: 2660.0227\n",
      "Epoch 1397/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3246.9451 - val_loss: 812.3563\n",
      "Epoch 1398/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1835.8046 - val_loss: 2458.9995\n",
      "Epoch 1399/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1733.3004 - val_loss: 1073.1703\n",
      "Epoch 1400/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1173.1604 - val_loss: 1510.7875\n",
      "Epoch 1401/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1195.2977 - val_loss: 181.2172\n",
      "Epoch 1402/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 374.5375 - val_loss: 399.2440\n",
      "Epoch 1403/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 371.8431 - val_loss: 223.6934\n",
      "Epoch 1404/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 219.8266 - val_loss: 266.7579\n",
      "Epoch 1405/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1748.2079 - val_loss: 3664.2827\n",
      "Epoch 1406/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2897.9478 - val_loss: 5505.2046\n",
      "Epoch 1407/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2146.2102 - val_loss: 1048.2032\n",
      "Epoch 1408/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1268.6165 - val_loss: 405.8431\n",
      "Epoch 1409/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2418.1147 - val_loss: 1710.3143\n",
      "Epoch 1410/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 907.6660 - val_loss: 227.1627\n",
      "Epoch 1411/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1300.1509 - val_loss: 1118.7645\n",
      "Epoch 1412/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1011.6723 - val_loss: 503.8680\n",
      "Epoch 1413/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 691.4979 - val_loss: 1113.3220\n",
      "Epoch 1414/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 359.6198 - val_loss: 282.2141\n",
      "Epoch 1415/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2291.6531 - val_loss: 2106.4812\n",
      "Epoch 1416/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 41ms/step - loss: 1079.7943 - val_loss: 311.6291\n",
      "Epoch 1417/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2434.8303 - val_loss: 2963.1895\n",
      "Epoch 1418/4000\n",
      "11/11 [==============================] - 1s 37ms/step - loss: 1809.6172 - val_loss: 533.1617\n",
      "Epoch 1419/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1255.6178 - val_loss: 2702.4451\n",
      "Epoch 1420/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2539.4683 - val_loss: 186.9075\n",
      "Epoch 1421/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1144.3740 - val_loss: 1534.8799\n",
      "Epoch 1422/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 3187.4001 - val_loss: 2759.6572\n",
      "Epoch 1423/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1635.4440 - val_loss: 1031.2432\n",
      "Epoch 1424/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 939.0292 - val_loss: 942.9741\n",
      "Epoch 1425/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 555.8846 - val_loss: 353.3804\n",
      "Epoch 1426/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 496.4472 - val_loss: 395.9268\n",
      "Epoch 1427/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2204.0039 - val_loss: 2467.6763\n",
      "Epoch 1428/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1709.6476 - val_loss: 1451.6611\n",
      "Epoch 1429/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1388.7032 - val_loss: 206.4921\n",
      "Epoch 1430/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 803.8116 - val_loss: 2229.0183\n",
      "Epoch 1431/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2070.8518 - val_loss: 933.1788\n",
      "Epoch 1432/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1433.5669 - val_loss: 168.7344\n",
      "Epoch 1433/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 316.4055 - val_loss: 143.1659\n",
      "Epoch 1434/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 321.2507 - val_loss: 247.6652\n",
      "Epoch 1435/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 949.5798 - val_loss: 495.6041\n",
      "Epoch 1436/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 708.4368 - val_loss: 300.9291\n",
      "Epoch 1437/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2091.4578 - val_loss: 1355.1692\n",
      "Epoch 1438/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1058.8763 - val_loss: 575.5870\n",
      "Epoch 1439/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2296.2791 - val_loss: 3816.9121\n",
      "Epoch 1440/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2975.6006 - val_loss: 408.6479\n",
      "Epoch 1441/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1170.2482 - val_loss: 1132.4901\n",
      "Epoch 1442/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1530.9327 - val_loss: 410.9918\n",
      "Epoch 1443/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1022.1877 - val_loss: 421.2964\n",
      "Epoch 1444/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 498.4258 - val_loss: 734.4962\n",
      "Epoch 1445/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1465.4808 - val_loss: 2643.6433\n",
      "Epoch 1446/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2337.4199 - val_loss: 534.2902\n",
      "Epoch 1447/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 866.4907 - val_loss: 2432.4053\n",
      "Epoch 1448/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 3701.1941 - val_loss: 1675.9365\n",
      "Epoch 1449/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1031.8378 - val_loss: 946.4001\n",
      "Epoch 1450/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1089.5996 - val_loss: 906.7876\n",
      "Epoch 1451/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1489.0109 - val_loss: 1471.5658\n",
      "Epoch 1452/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1009.7000 - val_loss: 569.0614\n",
      "Epoch 1453/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 284.7218 - val_loss: 169.6690\n",
      "Epoch 1454/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 455.8166 - val_loss: 1534.4343\n",
      "Epoch 1455/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1873.1942 - val_loss: 1975.2090\n",
      "Epoch 1456/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3459.2822 - val_loss: 3662.7085\n",
      "Epoch 1457/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2652.4658 - val_loss: 1118.9324\n",
      "Epoch 1458/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1273.7136 - val_loss: 1851.5402\n",
      "Epoch 1459/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2002.3793 - val_loss: 2220.1968\n",
      "Epoch 1460/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1309.7191 - val_loss: 1532.6086\n",
      "Epoch 1461/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 474.9193 - val_loss: 402.4959\n",
      "Epoch 1462/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2698.0635 - val_loss: 2521.2095\n",
      "Epoch 1463/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1172.3104 - val_loss: 196.4881\n",
      "Epoch 1464/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 391.0200 - val_loss: 1345.9423\n",
      "Epoch 1465/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1423.0009 - val_loss: 253.9838\n",
      "Epoch 1466/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1212.1102 - val_loss: 654.8104\n",
      "Epoch 1467/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 936.5016 - val_loss: 898.5986\n",
      "Epoch 1468/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2986.6372 - val_loss: 1802.1820\n",
      "Epoch 1469/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1457.5394 - val_loss: 1388.3473\n",
      "Epoch 1470/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1203.0560 - val_loss: 1214.1371\n",
      "Epoch 1471/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1691.9301 - val_loss: 3088.3928\n",
      "Epoch 1472/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2792.5803 - val_loss: 388.2740\n",
      "Epoch 1473/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 737.1429 - val_loss: 1225.2804\n",
      "Epoch 1474/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1532.4598 - val_loss: 1733.4451\n",
      "Epoch 1475/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1624.2169 - val_loss: 323.6353\n",
      "Epoch 1476/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 914.5649 - val_loss: 428.3650\n",
      "Epoch 1477/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 314.5703 - val_loss: 253.2816\n",
      "Epoch 1478/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 274.2501 - val_loss: 159.5553\n",
      "Epoch 1479/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 144.0170 - val_loss: 90.8145\n",
      "Epoch 1480/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 221.0337 - val_loss: 1209.9871\n",
      "Epoch 1481/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1985.8053 - val_loss: 1058.8527\n",
      "Epoch 1482/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 827.6852 - val_loss: 371.0486\n",
      "Epoch 1483/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2145.2844 - val_loss: 1409.2390\n",
      "Epoch 1484/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1201.6125 - val_loss: 450.0617\n",
      "Epoch 1485/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2291.2043 - val_loss: 2430.5649\n",
      "Epoch 1486/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1474.5372 - val_loss: 445.2132\n",
      "Epoch 1487/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1345.0507 - val_loss: 517.0500\n",
      "Epoch 1488/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 976.6472 - val_loss: 724.7607\n",
      "Epoch 1489/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1067.9216 - val_loss: 1560.0079\n",
      "Epoch 1490/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1390.4138 - val_loss: 2023.3856\n",
      "Epoch 1491/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 4666.2539 - val_loss: 3441.3994\n",
      "Epoch 1492/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2067.1812 - val_loss: 2468.0332\n",
      "Epoch 1493/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2725.7209 - val_loss: 830.3958\n",
      "Epoch 1494/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2870.6956 - val_loss: 3256.4287\n",
      "Epoch 1495/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2241.0601 - val_loss: 1055.1682\n",
      "Epoch 1496/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1466.2125 - val_loss: 1082.8660\n",
      "Epoch 1497/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2102.0281 - val_loss: 1599.8154\n",
      "Epoch 1498/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1124.9323 - val_loss: 1375.2848\n",
      "Epoch 1499/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1685.3859 - val_loss: 2137.8767\n",
      "Epoch 1500/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1835.1313 - val_loss: 1204.0342\n",
      "Epoch 1501/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1344.4274 - val_loss: 691.1108\n",
      "Epoch 1502/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2886.1655 - val_loss: 1779.0741\n",
      "Epoch 1503/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1318.2053 - val_loss: 909.0120\n",
      "Epoch 1504/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1827.4558 - val_loss: 2889.0259\n",
      "Epoch 1505/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2034.2125 - val_loss: 281.6250\n",
      "Epoch 1506/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 940.6015 - val_loss: 2864.3101\n",
      "Epoch 1507/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2922.3420 - val_loss: 302.5789\n",
      "Epoch 1508/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1917.6549 - val_loss: 2461.1587\n",
      "Epoch 1509/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1976.6915 - val_loss: 1665.8511\n",
      "Epoch 1510/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1572.6680 - val_loss: 573.2482\n",
      "Epoch 1511/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2607.3127 - val_loss: 1616.1658\n",
      "Epoch 1512/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1095.6520 - val_loss: 2026.7061\n",
      "Epoch 1513/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2669.7517 - val_loss: 545.0438\n",
      "Epoch 1514/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1089.0236 - val_loss: 576.2311\n",
      "Epoch 1515/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1696.7748 - val_loss: 1049.3328\n",
      "Epoch 1516/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2078.6040 - val_loss: 3430.3350\n",
      "Epoch 1517/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 2694.6611 - val_loss: 276.9731\n",
      "Epoch 1518/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 538.4218 - val_loss: 276.6847\n",
      "Epoch 1519/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 370.1035 - val_loss: 283.0671\n",
      "Epoch 1520/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 254.6145 - val_loss: 158.2906\n",
      "Epoch 1521/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 212.4564 - val_loss: 476.7499\n",
      "Epoch 1522/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1010.9136 - val_loss: 2440.7036\n",
      "Epoch 1523/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2714.7092 - val_loss: 667.4287\n",
      "Epoch 1524/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 955.9720 - val_loss: 372.1208\n",
      "Epoch 1525/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 752.0691 - val_loss: 481.6311\n",
      "Epoch 1526/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1107.5427 - val_loss: 576.4780\n",
      "Epoch 1527/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2755.6111 - val_loss: 1720.4399\n",
      "Epoch 1528/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1483.9797 - val_loss: 1679.1877\n",
      "Epoch 1529/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1203.7335 - val_loss: 2241.7432\n",
      "Epoch 1530/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2533.8428 - val_loss: 862.3979\n",
      "Epoch 1531/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 922.1328 - val_loss: 2594.6958\n",
      "Epoch 1532/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2871.2754 - val_loss: 309.5279\n",
      "Epoch 1533/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 683.6259 - val_loss: 324.1980\n",
      "Epoch 1534/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 735.6487 - val_loss: 790.9664\n",
      "Epoch 1535/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 3285.5764 - val_loss: 4725.3105\n",
      "Epoch 1536/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3829.0520 - val_loss: 2435.9041\n",
      "Epoch 1537/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1006.6627 - val_loss: 238.5334\n",
      "Epoch 1538/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 729.2421 - val_loss: 200.4886\n",
      "Epoch 1539/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 366.5429 - val_loss: 298.8114\n",
      "Epoch 1540/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 603.3624 - val_loss: 689.3671\n",
      "Epoch 1541/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 870.5779 - val_loss: 522.0741\n",
      "Epoch 1542/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 720.3651 - val_loss: 2444.4465\n",
      "Epoch 1543/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3457.7830 - val_loss: 1143.8348\n",
      "Epoch 1544/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1008.3268 - val_loss: 1477.7308\n",
      "Epoch 1545/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3550.8955 - val_loss: 3136.1641\n",
      "Epoch 1546/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2004.7522 - val_loss: 1997.8704\n",
      "Epoch 1547/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2095.5938 - val_loss: 2448.7502\n",
      "Epoch 1548/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1320.4524 - val_loss: 903.4951\n",
      "Epoch 1549/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 440.7232 - val_loss: 403.8605\n",
      "Epoch 1550/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 528.5728 - val_loss: 1145.2456\n",
      "Epoch 1551/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1525.4507 - val_loss: 476.5672\n",
      "Epoch 1552/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1342.1456 - val_loss: 671.8585\n",
      "Epoch 1553/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 510.3858 - val_loss: 346.4227\n",
      "Epoch 1554/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2504.0022 - val_loss: 2299.5813\n",
      "Epoch 1555/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1544.8640 - val_loss: 1068.6128\n",
      "Epoch 1556/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1330.0699 - val_loss: 2255.9082\n",
      "Epoch 1557/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2227.9685 - val_loss: 328.3154\n",
      "Epoch 1558/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1423.3115 - val_loss: 899.0079\n",
      "Epoch 1559/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 710.4882 - val_loss: 1238.7703\n",
      "Epoch 1560/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2082.8433 - val_loss: 268.1482\n",
      "Epoch 1561/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 834.2419 - val_loss: 116.4924\n",
      "Epoch 1562/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 235.6358 - val_loss: 245.9386\n",
      "Epoch 1563/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 347.1957 - val_loss: 260.5580\n",
      "Epoch 1564/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 276.1569 - val_loss: 183.2573\n",
      "Epoch 1565/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1951.2617 - val_loss: 2568.8313\n",
      "Epoch 1566/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 40ms/step - loss: 1492.5615 - val_loss: 1061.5336\n",
      "Epoch 1567/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1684.2482 - val_loss: 3480.0059\n",
      "Epoch 1568/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 857.2849 - val_loss: 1024.9152\n",
      "Epoch 1569/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1267.7159 - val_loss: 1778.1885\n",
      "Epoch 1570/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2602.0027 - val_loss: 711.3547\n",
      "Epoch 1571/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2586.0417 - val_loss: 2663.5376\n",
      "Epoch 1572/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2390.9902 - val_loss: 2205.5798\n",
      "Epoch 1573/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2315.1604 - val_loss: 1580.3234\n",
      "Epoch 1574/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3545.2229 - val_loss: 1920.8630\n",
      "Epoch 1575/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1183.0659 - val_loss: 793.5866\n",
      "Epoch 1576/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 452.4724 - val_loss: 262.0648\n",
      "Epoch 1577/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 651.4775 - val_loss: 478.1617\n",
      "Epoch 1578/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 862.3596 - val_loss: 1528.8595\n",
      "Epoch 1579/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1308.9111 - val_loss: 1373.3829\n",
      "Epoch 1580/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1175.8015 - val_loss: 485.0580\n",
      "Epoch 1581/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1489.2922 - val_loss: 3620.2969\n",
      "Epoch 1582/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 4099.1431 - val_loss: 1347.8367\n",
      "Epoch 1583/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1463.7426 - val_loss: 755.4255\n",
      "Epoch 1584/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 919.6024 - val_loss: 519.1467\n",
      "Epoch 1585/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2936.0459 - val_loss: 5274.9556\n",
      "Epoch 1586/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 4880.6201 - val_loss: 1131.9741\n",
      "Epoch 1587/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 633.3368 - val_loss: 138.9653\n",
      "Epoch 1588/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 243.0636 - val_loss: 208.2074\n",
      "Epoch 1589/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 216.2373 - val_loss: 201.7604\n",
      "Epoch 1590/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 635.8441 - val_loss: 1958.7667\n",
      "Epoch 1591/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2824.1992 - val_loss: 805.8257\n",
      "Epoch 1592/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 630.8282 - val_loss: 867.8797\n",
      "Epoch 1593/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 4172.6255 - val_loss: 3714.2124\n",
      "Epoch 1594/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2635.6877 - val_loss: 1599.1857\n",
      "Epoch 1595/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1930.5149 - val_loss: 3759.0674\n",
      "Epoch 1596/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 829.5572 - val_loss: 1312.0530\n",
      "Epoch 1597/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2699.9590 - val_loss: 1306.5782\n",
      "Epoch 1598/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1280.9520 - val_loss: 2171.1716\n",
      "Epoch 1599/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1801.2394 - val_loss: 886.4362\n",
      "Epoch 1600/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1101.6168 - val_loss: 1922.4200\n",
      "Epoch 1601/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1933.6549 - val_loss: 351.5633\n",
      "Epoch 1602/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1009.4093 - val_loss: 335.5781\n",
      "Epoch 1603/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 490.0128 - val_loss: 2096.8271\n",
      "Epoch 1604/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3154.6196 - val_loss: 1303.5883\n",
      "Epoch 1605/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1475.5706 - val_loss: 3224.6758\n",
      "Epoch 1606/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3433.0186 - val_loss: 525.4666\n",
      "Epoch 1607/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1613.4730 - val_loss: 390.4903\n",
      "Epoch 1608/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1367.9020 - val_loss: 556.6880\n",
      "Epoch 1609/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1595.2706 - val_loss: 1750.1481\n",
      "Epoch 1610/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 918.0061 - val_loss: 396.1431\n",
      "Epoch 1611/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 632.7454 - val_loss: 544.4271\n",
      "Epoch 1612/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 604.9133 - val_loss: 405.9860\n",
      "Epoch 1613/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 384.7084 - val_loss: 195.5173\n",
      "Epoch 1614/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 208.9184 - val_loss: 82.6258\n",
      "Epoch 1615/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 112.9836 - val_loss: 152.2971\n",
      "Epoch 1616/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1671.2665 - val_loss: 2603.4736\n",
      "Epoch 1617/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 1496.1893 - val_loss: 223.9505\n",
      "Epoch 1618/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1587.1465 - val_loss: 2127.0552\n",
      "Epoch 1619/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1415.6018 - val_loss: 924.2495\n",
      "Epoch 1620/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1032.8381 - val_loss: 543.5179\n",
      "Epoch 1621/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1820.5569 - val_loss: 2003.3396\n",
      "Epoch 1622/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1818.3031 - val_loss: 3370.0964\n",
      "Epoch 1623/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3845.6968 - val_loss: 1018.0065\n",
      "Epoch 1624/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2803.0369 - val_loss: 4109.0586\n",
      "Epoch 1625/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3050.3403 - val_loss: 7361.2002\n",
      "Epoch 1626/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1991.3344 - val_loss: 876.0847\n",
      "Epoch 1627/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1918.8000 - val_loss: 2057.0486\n",
      "Epoch 1628/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1445.3810 - val_loss: 1252.9110\n",
      "Epoch 1629/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1245.2126 - val_loss: 992.9798\n",
      "Epoch 1630/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1260.5591 - val_loss: 1657.8676\n",
      "Epoch 1631/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2338.5586 - val_loss: 1246.8253\n",
      "Epoch 1632/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 494.0147 - val_loss: 289.3369\n",
      "Epoch 1633/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1017.5319 - val_loss: 2193.8904\n",
      "Epoch 1634/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1975.0614 - val_loss: 202.2710\n",
      "Epoch 1635/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 629.8580 - val_loss: 678.0664\n",
      "Epoch 1636/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2198.8801 - val_loss: 1372.1693\n",
      "Epoch 1637/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1511.8923 - val_loss: 1365.5625\n",
      "Epoch 1638/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1556.4756 - val_loss: 2748.4421\n",
      "Epoch 1639/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2841.3230 - val_loss: 307.7407\n",
      "Epoch 1640/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 946.0123 - val_loss: 148.2147\n",
      "Epoch 1641/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 40ms/step - loss: 915.5798 - val_loss: 422.6366\n",
      "Epoch 1642/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1430.5201 - val_loss: 2529.2703\n",
      "Epoch 1643/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1878.4919 - val_loss: 707.0266\n",
      "Epoch 1644/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 972.7355 - val_loss: 1841.7827\n",
      "Epoch 1645/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2670.3586 - val_loss: 678.1603\n",
      "Epoch 1646/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1747.8882 - val_loss: 1345.3438\n",
      "Epoch 1647/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 743.5480 - val_loss: 498.2041\n",
      "Epoch 1648/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 768.4366 - val_loss: 694.9315\n",
      "Epoch 1649/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 779.5044 - val_loss: 517.9243\n",
      "Epoch 1650/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 833.7487 - val_loss: 2234.3892\n",
      "Epoch 1651/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2959.9111 - val_loss: 609.2973\n",
      "Epoch 1652/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1070.6807 - val_loss: 400.3106\n",
      "Epoch 1653/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1964.4060 - val_loss: 2296.3669\n",
      "Epoch 1654/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1636.6110 - val_loss: 894.8436\n",
      "Epoch 1655/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1034.1016 - val_loss: 1549.5081\n",
      "Epoch 1656/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1159.4835 - val_loss: 1242.8533\n",
      "Epoch 1657/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3068.5898 - val_loss: 2804.5190\n",
      "Epoch 1658/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1674.3535 - val_loss: 829.4442\n",
      "Epoch 1659/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1616.8812 - val_loss: 3520.5198\n",
      "Epoch 1660/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3568.9153 - val_loss: 1881.1577\n",
      "Epoch 1661/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1161.5249 - val_loss: 1190.5170\n",
      "Epoch 1662/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1666.7100 - val_loss: 2537.6462\n",
      "Epoch 1663/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1907.0310 - val_loss: 248.4339\n",
      "Epoch 1664/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 296.6282 - val_loss: 158.2411\n",
      "Epoch 1665/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 335.6837 - val_loss: 548.3649\n",
      "Epoch 1666/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1946.0883 - val_loss: 764.9861\n",
      "Epoch 1667/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 843.7338 - val_loss: 899.2723\n",
      "Epoch 1668/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1625.1454 - val_loss: 2079.3252\n",
      "Epoch 1669/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1607.4457 - val_loss: 1314.9409\n",
      "Epoch 1670/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1017.6375 - val_loss: 144.4089\n",
      "Epoch 1671/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 712.1472 - val_loss: 1846.7094\n",
      "Epoch 1672/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1668.4153 - val_loss: 766.1212\n",
      "Epoch 1673/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1362.0287 - val_loss: 440.1069\n",
      "Epoch 1674/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1243.6255 - val_loss: 714.5783\n",
      "Epoch 1675/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1608.3317 - val_loss: 897.4733\n",
      "Epoch 1676/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 886.1331 - val_loss: 1219.4686\n",
      "Epoch 1677/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 964.1759 - val_loss: 815.3071\n",
      "Epoch 1678/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 793.6746 - val_loss: 552.9406\n",
      "Epoch 1679/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 294.2681 - val_loss: 170.7327\n",
      "Epoch 1680/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 217.6854 - val_loss: 122.2083\n",
      "Epoch 1681/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 306.3961 - val_loss: 67.3224\n",
      "Epoch 1682/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 92.2402 - val_loss: 82.1304\n",
      "Epoch 1683/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 210.1490 - val_loss: 1577.2352\n",
      "Epoch 1684/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1395.0829 - val_loss: 281.0796\n",
      "Epoch 1685/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2633.8198 - val_loss: 3132.2163\n",
      "Epoch 1686/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2212.0413 - val_loss: 876.5426\n",
      "Epoch 1687/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 995.1444 - val_loss: 1465.6332\n",
      "Epoch 1688/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3128.2146 - val_loss: 1521.6411\n",
      "Epoch 1689/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1011.5130 - val_loss: 164.0803\n",
      "Epoch 1690/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1575.4095 - val_loss: 1122.1674\n",
      "Epoch 1691/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 662.0649 - val_loss: 350.6838\n",
      "Epoch 1692/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1399.4371 - val_loss: 1129.7135\n",
      "Epoch 1693/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1450.1691 - val_loss: 1677.9268\n",
      "Epoch 1694/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1120.9396 - val_loss: 487.0152\n",
      "Epoch 1695/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1945.9873 - val_loss: 2640.3728\n",
      "Epoch 1696/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1738.4022 - val_loss: 1030.9210\n",
      "Epoch 1697/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1118.2852 - val_loss: 1835.8542\n",
      "Epoch 1698/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1354.9257 - val_loss: 397.1962\n",
      "Epoch 1699/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1247.0272 - val_loss: 512.4548\n",
      "Epoch 1700/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1746.8076 - val_loss: 293.4594\n",
      "Epoch 1701/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1670.5804 - val_loss: 1417.7152\n",
      "Epoch 1702/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1350.8762 - val_loss: 2794.8242\n",
      "Epoch 1703/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2698.5759 - val_loss: 393.3995\n",
      "Epoch 1704/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1518.9833 - val_loss: 485.6347\n",
      "Epoch 1705/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1040.9047 - val_loss: 650.8723\n",
      "Epoch 1706/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 367.8761 - val_loss: 262.2141\n",
      "Epoch 1707/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 327.1865 - val_loss: 173.1109\n",
      "Epoch 1708/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 158.6610 - val_loss: 71.8472\n",
      "Epoch 1709/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 66.7655 - val_loss: 50.0300\n",
      "Epoch 1710/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 255.8079 - val_loss: 585.0253\n",
      "Epoch 1711/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1481.8817 - val_loss: 3427.4873\n",
      "Epoch 1712/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3047.2559 - val_loss: 656.3354\n",
      "Epoch 1713/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1573.1302 - val_loss: 760.5850\n",
      "Epoch 1714/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1186.7118 - val_loss: 2020.3885\n",
      "Epoch 1715/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1570.2389 - val_loss: 1594.6545\n",
      "Epoch 1716/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1932.7595 - val_loss: 1827.9150\n",
      "Epoch 1717/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1740.1079 - val_loss: 727.2222\n",
      "Epoch 1718/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 537.3242 - val_loss: 792.8355\n",
      "Epoch 1719/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3043.3291 - val_loss: 2828.8616\n",
      "Epoch 1720/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1555.0011 - val_loss: 391.7756\n",
      "Epoch 1721/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 957.2863 - val_loss: 1420.6826\n",
      "Epoch 1722/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1907.0781 - val_loss: 3405.5923\n",
      "Epoch 1723/4000\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 3443.2175 - val_loss: 648.2480\n",
      "Epoch 1724/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1196.8489 - val_loss: 1510.3434\n",
      "Epoch 1725/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2244.7380 - val_loss: 1350.6991\n",
      "Epoch 1726/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1182.9558 - val_loss: 1098.7869\n",
      "Epoch 1727/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1149.0164 - val_loss: 1231.8617\n",
      "Epoch 1728/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1349.6649 - val_loss: 1961.0798\n",
      "Epoch 1729/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1437.4480 - val_loss: 363.1057\n",
      "Epoch 1730/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1115.3536 - val_loss: 418.6215\n",
      "Epoch 1731/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 896.3510 - val_loss: 1162.1370\n",
      "Epoch 1732/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1997.7904 - val_loss: 271.5308\n",
      "Epoch 1733/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 576.4127 - val_loss: 1259.9377\n",
      "Epoch 1734/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2275.7153 - val_loss: 524.7625\n",
      "Epoch 1735/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1334.4908 - val_loss: 868.3127\n",
      "Epoch 1736/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 554.2415 - val_loss: 539.5502\n",
      "Epoch 1737/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 655.9732 - val_loss: 525.7354\n",
      "Epoch 1738/4000\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 534.2649 - val_loss: 303.2291\n",
      "Epoch 1739/4000\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 289.7687 - val_loss: 172.0859\n",
      "Epoch 1740/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 422.3707 - val_loss: 676.4822\n",
      "Epoch 1741/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1277.4862 - val_loss: 2067.2136\n",
      "Epoch 1742/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1278.5339 - val_loss: 706.2474\n",
      "Epoch 1743/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 857.1563 - val_loss: 759.3724\n",
      "Epoch 1744/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1262.5669 - val_loss: 1651.1633\n",
      "Epoch 1745/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1114.3590 - val_loss: 1616.4904\n",
      "Epoch 1746/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1484.3446 - val_loss: 903.8103\n",
      "Epoch 1747/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1386.3538 - val_loss: 146.3157\n",
      "Epoch 1748/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 671.0482 - val_loss: 305.8578\n",
      "Epoch 1749/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2067.7859 - val_loss: 3590.0288\n",
      "Epoch 1750/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2881.3496 - val_loss: 3328.7446\n",
      "Epoch 1751/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3041.6350 - val_loss: 2564.0139\n",
      "Epoch 1752/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1471.0006 - val_loss: 1085.0770\n",
      "Epoch 1753/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 724.9258 - val_loss: 586.2264\n",
      "Epoch 1754/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1173.2476 - val_loss: 2389.6692\n",
      "Epoch 1755/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2276.4470 - val_loss: 174.8095\n",
      "Epoch 1756/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1024.8829 - val_loss: 168.8707\n",
      "Epoch 1757/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1359.4297 - val_loss: 2559.1465\n",
      "Epoch 1758/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1831.0969 - val_loss: 545.9828\n",
      "Epoch 1759/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 880.9432 - val_loss: 1562.9930\n",
      "Epoch 1760/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1178.8368 - val_loss: 207.9474\n",
      "Epoch 1761/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 414.0739 - val_loss: 395.1756\n",
      "Epoch 1762/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 440.6520 - val_loss: 273.2542\n",
      "Epoch 1763/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 249.9957 - val_loss: 108.8710\n",
      "Epoch 1764/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 82.1182 - val_loss: 58.3365\n",
      "Epoch 1765/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 139.9584 - val_loss: 301.4951\n",
      "Epoch 1766/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1337.5383 - val_loss: 1675.8527\n",
      "Epoch 1767/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1007.5956 - val_loss: 1760.2657\n",
      "Epoch 1768/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3276.7922 - val_loss: 1625.6158\n",
      "Epoch 1769/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1543.7561 - val_loss: 613.8489\n",
      "Epoch 1770/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1399.5372 - val_loss: 444.8446\n",
      "Epoch 1771/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1391.6433 - val_loss: 592.5396\n",
      "Epoch 1772/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1038.8434 - val_loss: 649.9682\n",
      "Epoch 1773/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 388.1256 - val_loss: 636.6561\n",
      "Epoch 1774/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1037.3322 - val_loss: 1466.6970\n",
      "Epoch 1775/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1313.1757 - val_loss: 1357.3473\n",
      "Epoch 1776/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1632.5554 - val_loss: 171.4809\n",
      "Epoch 1777/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1908.2499 - val_loss: 2287.9729\n",
      "Epoch 1778/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1505.7020 - val_loss: 1035.3484\n",
      "Epoch 1779/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1422.2031 - val_loss: 3218.4316\n",
      "Epoch 1780/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3435.3853 - val_loss: 2226.4604\n",
      "Epoch 1781/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1324.6198 - val_loss: 1968.9816\n",
      "Epoch 1782/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1398.5842 - val_loss: 429.2595\n",
      "Epoch 1783/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 371.5659 - val_loss: 177.9361\n",
      "Epoch 1784/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 163.6096 - val_loss: 93.7378\n",
      "Epoch 1785/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 69.2983 - val_loss: 47.9700\n",
      "Epoch 1786/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 57.1316 - val_loss: 50.0079\n",
      "Epoch 1787/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2111.6472 - val_loss: 2013.7167\n",
      "Epoch 1788/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1252.3179 - val_loss: 1673.6450\n",
      "Epoch 1789/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1653.1897 - val_loss: 535.4687\n",
      "Epoch 1790/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 881.9074 - val_loss: 1102.2864\n",
      "Epoch 1791/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 42ms/step - loss: 1256.1927 - val_loss: 2482.5247\n",
      "Epoch 1792/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2340.6833 - val_loss: 258.5283\n",
      "Epoch 1793/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1252.9135 - val_loss: 1226.2555\n",
      "Epoch 1794/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1010.1644 - val_loss: 373.6945\n",
      "Epoch 1795/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 795.0833 - val_loss: 2123.8574\n",
      "Epoch 1796/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1055.1608 - val_loss: 1897.9154\n",
      "Epoch 1797/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2092.4260 - val_loss: 1271.6702\n",
      "Epoch 1798/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1868.7301 - val_loss: 4102.8926\n",
      "Epoch 1799/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 4468.3882 - val_loss: 1493.7616\n",
      "Epoch 1800/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1525.8939 - val_loss: 2549.2107\n",
      "Epoch 1801/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2639.2419 - val_loss: 4143.1973\n",
      "Epoch 1802/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1219.0829 - val_loss: 1033.7441\n",
      "Epoch 1803/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1339.8209 - val_loss: 644.0004\n",
      "Epoch 1804/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1049.8594 - val_loss: 961.1844\n",
      "Epoch 1805/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1559.0546 - val_loss: 1068.2908\n",
      "Epoch 1806/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 940.0308 - val_loss: 2340.1580\n",
      "Epoch 1807/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1333.8464 - val_loss: 348.0387\n",
      "Epoch 1808/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2180.7329 - val_loss: 2660.4590\n",
      "Epoch 1809/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1564.0763 - val_loss: 670.8414\n",
      "Epoch 1810/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 777.6562 - val_loss: 685.9842\n",
      "Epoch 1811/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1261.3104 - val_loss: 1685.5515\n",
      "Epoch 1812/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1151.6522 - val_loss: 2244.0181\n",
      "Epoch 1813/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3502.8674 - val_loss: 1358.1968\n",
      "Epoch 1814/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1013.5216 - val_loss: 388.0872\n",
      "Epoch 1815/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 463.1797 - val_loss: 140.1988\n",
      "Epoch 1816/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 213.2666 - val_loss: 183.7424\n",
      "Epoch 1817/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 230.2669 - val_loss: 342.0902\n",
      "Epoch 1818/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 373.2452 - val_loss: 283.3208\n",
      "Epoch 1819/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 415.3195 - val_loss: 355.9793\n",
      "Epoch 1820/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 401.4493 - val_loss: 232.6677\n",
      "Epoch 1821/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 679.6361 - val_loss: 1539.7283\n",
      "Epoch 1822/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 851.8944 - val_loss: 74.3773\n",
      "Epoch 1823/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 3061.2307 - val_loss: 3731.8191\n",
      "Epoch 1824/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2685.5217 - val_loss: 1229.7231\n",
      "Epoch 1825/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3067.2017 - val_loss: 1638.6627\n",
      "Epoch 1826/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 892.9049 - val_loss: 795.1752\n",
      "Epoch 1827/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1957.9022 - val_loss: 445.8056\n",
      "Epoch 1828/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 838.4979 - val_loss: 328.8952\n",
      "Epoch 1829/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1607.8534 - val_loss: 1815.3577\n",
      "Epoch 1830/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 866.2567 - val_loss: 129.1871\n",
      "Epoch 1831/4000\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 136.1577 - val_loss: 155.2148\n",
      "Epoch 1832/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1587.7681 - val_loss: 2619.7573\n",
      "Epoch 1833/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1640.6038 - val_loss: 2095.3870\n",
      "Epoch 1834/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 4518.3916 - val_loss: 2647.1533\n",
      "Epoch 1835/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1802.8375 - val_loss: 812.2191\n",
      "Epoch 1836/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1786.2676 - val_loss: 1623.9250\n",
      "Epoch 1837/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1370.0398 - val_loss: 2345.1875\n",
      "Epoch 1838/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1720.6049 - val_loss: 2424.9390\n",
      "Epoch 1839/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3290.0403 - val_loss: 2506.2476\n",
      "Epoch 1840/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2002.8936 - val_loss: 3137.7605\n",
      "Epoch 1841/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2850.7903 - val_loss: 3082.2983\n",
      "Epoch 1842/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1795.2069 - val_loss: 522.5619\n",
      "Epoch 1843/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2075.7795 - val_loss: 2087.8586\n",
      "Epoch 1844/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1475.0450 - val_loss: 826.7437\n",
      "Epoch 1845/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 961.8777 - val_loss: 1061.8898\n",
      "Epoch 1846/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1529.9778 - val_loss: 2928.8591\n",
      "Epoch 1847/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2585.7468 - val_loss: 1674.2948\n",
      "Epoch 1848/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 4865.0298 - val_loss: 5277.9722\n",
      "Epoch 1849/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 4058.1123 - val_loss: 127.6383\n",
      "Epoch 1850/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1715.9006 - val_loss: 3213.5798\n",
      "Epoch 1851/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2406.8040 - val_loss: 1278.6908\n",
      "Epoch 1852/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1767.4458 - val_loss: 2752.6511\n",
      "Epoch 1853/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2302.4685 - val_loss: 550.3244\n",
      "Epoch 1854/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 840.4963 - val_loss: 1060.0173\n",
      "Epoch 1855/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1100.9487 - val_loss: 1488.5651\n",
      "Epoch 1856/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1226.0983 - val_loss: 1536.0950\n",
      "Epoch 1857/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1938.8505 - val_loss: 275.4606\n",
      "Epoch 1858/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3640.2471 - val_loss: 4202.2275\n",
      "Epoch 1859/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2820.7529 - val_loss: 505.5651\n",
      "Epoch 1860/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 958.0955 - val_loss: 1827.3342\n",
      "Epoch 1861/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2734.0823 - val_loss: 1724.5898\n",
      "Epoch 1862/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1064.5359 - val_loss: 1571.4775\n",
      "Epoch 1863/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1640.2889 - val_loss: 2760.8811\n",
      "Epoch 1864/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3323.9551 - val_loss: 784.8779\n",
      "Epoch 1865/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 703.8447 - val_loss: 393.2722\n",
      "Epoch 1866/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 39ms/step - loss: 294.3188 - val_loss: 287.5073\n",
      "Epoch 1867/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 333.7517 - val_loss: 204.1215\n",
      "Epoch 1868/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 194.7273 - val_loss: 82.8153\n",
      "Epoch 1869/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 80.5317 - val_loss: 122.9047\n",
      "Epoch 1870/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 250.2062 - val_loss: 2108.9375\n",
      "Epoch 1871/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 4930.9033 - val_loss: 3756.9004\n",
      "Epoch 1872/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2048.1733 - val_loss: 431.6314\n",
      "Epoch 1873/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 950.3507 - val_loss: 1181.7158\n",
      "Epoch 1874/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1132.4042 - val_loss: 1039.5103\n",
      "Epoch 1875/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1364.2491 - val_loss: 2157.2783\n",
      "Epoch 1876/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1704.1050 - val_loss: 1454.9364\n",
      "Epoch 1877/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 3386.8689 - val_loss: 1856.5940\n",
      "Epoch 1878/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1811.0332 - val_loss: 1822.2067\n",
      "Epoch 1879/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1381.4496 - val_loss: 926.4008\n",
      "Epoch 1880/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1063.8254 - val_loss: 1721.5198\n",
      "Epoch 1881/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1552.3234 - val_loss: 111.2975\n",
      "Epoch 1882/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 571.2184 - val_loss: 975.0374\n",
      "Epoch 1883/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1389.1642 - val_loss: 814.6093\n",
      "Epoch 1884/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3034.7842 - val_loss: 1715.1702\n",
      "Epoch 1885/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1370.4990 - val_loss: 928.0803\n",
      "Epoch 1886/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 978.6003 - val_loss: 745.4094\n",
      "Epoch 1887/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1776.3453 - val_loss: 2902.6750\n",
      "Epoch 1888/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2351.3330 - val_loss: 731.5244\n",
      "Epoch 1889/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3909.2422 - val_loss: 3576.9836\n",
      "Epoch 1890/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2133.8601 - val_loss: 775.3840\n",
      "Epoch 1891/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1246.0970 - val_loss: 2518.9834\n",
      "Epoch 1892/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2270.7166 - val_loss: 2809.5051\n",
      "Epoch 1893/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 4396.1011 - val_loss: 4590.4897\n",
      "Epoch 1894/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3041.9114 - val_loss: 613.0662\n",
      "Epoch 1895/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 825.3494 - val_loss: 910.7759\n",
      "Epoch 1896/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1041.6322 - val_loss: 1853.5753\n",
      "Epoch 1897/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1855.4515 - val_loss: 329.4896\n",
      "Epoch 1898/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 391.5367 - val_loss: 361.0779\n",
      "Epoch 1899/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 450.1918 - val_loss: 311.5815\n",
      "Epoch 1900/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 309.3276 - val_loss: 161.2631\n",
      "Epoch 1901/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 436.2486 - val_loss: 540.9780\n",
      "Epoch 1902/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 916.2693 - val_loss: 2634.8213\n",
      "Epoch 1903/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2460.8425 - val_loss: 1961.4209\n",
      "Epoch 1904/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1129.1088 - val_loss: 97.2884\n",
      "Epoch 1905/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1223.9633 - val_loss: 507.2239\n",
      "Epoch 1906/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 798.6755 - val_loss: 612.2281\n",
      "Epoch 1907/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1272.9669 - val_loss: 230.0980\n",
      "Epoch 1908/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1316.4729 - val_loss: 447.6358\n",
      "Epoch 1909/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1037.0553 - val_loss: 759.9520\n",
      "Epoch 1910/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1761.4546 - val_loss: 4033.9238\n",
      "Epoch 1911/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4116.7227 - val_loss: 876.8154\n",
      "Epoch 1912/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 833.4781 - val_loss: 1038.4895\n",
      "Epoch 1913/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 277.8648 - val_loss: 213.4363\n",
      "Epoch 1914/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 278.4607 - val_loss: 381.5953\n",
      "Epoch 1915/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 966.1881 - val_loss: 2219.0464\n",
      "Epoch 1916/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2129.3145 - val_loss: 158.1511\n",
      "Epoch 1917/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1313.9325 - val_loss: 2448.8645\n",
      "Epoch 1918/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1841.0801 - val_loss: 1234.4598\n",
      "Epoch 1919/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1122.5327 - val_loss: 965.6088\n",
      "Epoch 1920/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1327.6973 - val_loss: 1468.9459\n",
      "Epoch 1921/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1080.0924 - val_loss: 860.5955\n",
      "Epoch 1922/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 550.2939 - val_loss: 208.3991\n",
      "Epoch 1923/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 742.8867 - val_loss: 2098.5894\n",
      "Epoch 1924/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1960.2604 - val_loss: 5065.4170\n",
      "Epoch 1925/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1526.1152 - val_loss: 235.9298\n",
      "Epoch 1926/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2008.4847 - val_loss: 1826.6570\n",
      "Epoch 1927/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1333.9958 - val_loss: 968.4982\n",
      "Epoch 1928/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 573.8979 - val_loss: 201.8226\n",
      "Epoch 1929/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2120.7991 - val_loss: 2528.0103\n",
      "Epoch 1930/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1680.5452 - val_loss: 1343.9562\n",
      "Epoch 1931/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1136.7565 - val_loss: 233.9509\n",
      "Epoch 1932/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 524.9537 - val_loss: 549.4947\n",
      "Epoch 1933/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 683.4223 - val_loss: 505.2177\n",
      "Epoch 1934/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 550.4474 - val_loss: 711.1439\n",
      "Epoch 1935/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2857.9741 - val_loss: 2323.8096\n",
      "Epoch 1936/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1255.6307 - val_loss: 765.3721\n",
      "Epoch 1937/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 389.1765 - val_loss: 153.6555\n",
      "Epoch 1938/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 450.7339 - val_loss: 1259.8569\n",
      "Epoch 1939/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1080.4396 - val_loss: 843.7759\n",
      "Epoch 1940/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 874.6418 - val_loss: 98.4405\n",
      "Epoch 1941/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 225.8840 - val_loss: 229.6526\n",
      "Epoch 1942/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 274.4463 - val_loss: 175.4663\n",
      "Epoch 1943/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 260.8998 - val_loss: 791.6635\n",
      "Epoch 1944/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2778.5220 - val_loss: 2195.0195\n",
      "Epoch 1945/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1388.0808 - val_loss: 688.3238\n",
      "Epoch 1946/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2208.2185 - val_loss: 777.5463\n",
      "Epoch 1947/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1568.7014 - val_loss: 645.7593\n",
      "Epoch 1948/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1736.1251 - val_loss: 1279.4215\n",
      "Epoch 1949/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1252.2637 - val_loss: 895.6119\n",
      "Epoch 1950/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 616.2264 - val_loss: 410.7865\n",
      "Epoch 1951/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1743.3701 - val_loss: 1774.2196\n",
      "Epoch 1952/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1008.6977 - val_loss: 401.0030\n",
      "Epoch 1953/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 870.2687 - val_loss: 1011.0493\n",
      "Epoch 1954/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 438.3109 - val_loss: 312.2171\n",
      "Epoch 1955/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 472.0689 - val_loss: 409.6530\n",
      "Epoch 1956/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 440.7009 - val_loss: 491.6178\n",
      "Epoch 1957/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1843.3198 - val_loss: 739.1012\n",
      "Epoch 1958/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 623.5704 - val_loss: 662.6708\n",
      "Epoch 1959/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 841.3202 - val_loss: 2519.1567\n",
      "Epoch 1960/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2702.7561 - val_loss: 132.4438\n",
      "Epoch 1961/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 998.6365 - val_loss: 82.7535\n",
      "Epoch 1962/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1848.3767 - val_loss: 1395.7623\n",
      "Epoch 1963/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1201.1807 - val_loss: 2179.9624\n",
      "Epoch 1964/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1919.1919 - val_loss: 558.1079\n",
      "Epoch 1965/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1045.3917 - val_loss: 2422.7551\n",
      "Epoch 1966/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2685.5986 - val_loss: 1009.8996\n",
      "Epoch 1967/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 808.7126 - val_loss: 325.9139\n",
      "Epoch 1968/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 952.9492 - val_loss: 2335.4841\n",
      "Epoch 1969/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1510.9600 - val_loss: 226.9803\n",
      "Epoch 1970/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1440.8873 - val_loss: 759.5646\n",
      "Epoch 1971/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 334.1803 - val_loss: 134.7307\n",
      "Epoch 1972/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 170.3157 - val_loss: 141.9590\n",
      "Epoch 1973/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 910.0139 - val_loss: 2939.4319\n",
      "Epoch 1974/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2926.7666 - val_loss: 553.9258\n",
      "Epoch 1975/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1093.2205 - val_loss: 1052.0024\n",
      "Epoch 1976/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1337.8591 - val_loss: 1415.1987\n",
      "Epoch 1977/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1423.0576 - val_loss: 1694.6747\n",
      "Epoch 1978/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1284.0442 - val_loss: 935.7793\n",
      "Epoch 1979/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1186.1337 - val_loss: 2723.1580\n",
      "Epoch 1980/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3521.0718 - val_loss: 1108.3062\n",
      "Epoch 1981/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1291.3625 - val_loss: 945.7459\n",
      "Epoch 1982/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1773.2024 - val_loss: 3486.9028\n",
      "Epoch 1983/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2747.4592 - val_loss: 5524.4312\n",
      "Epoch 1984/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1074.3693 - val_loss: 1967.3004\n",
      "Epoch 1985/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 2060.9807 - val_loss: 1127.4254\n",
      "Epoch 1986/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 650.0129 - val_loss: 350.3233\n",
      "Epoch 1987/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2959.5491 - val_loss: 3508.4875\n",
      "Epoch 1988/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2267.3835 - val_loss: 498.5921\n",
      "Epoch 1989/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 753.2340 - val_loss: 1337.4028\n",
      "Epoch 1990/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 894.5493 - val_loss: 157.6198\n",
      "Epoch 1991/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 278.3722 - val_loss: 173.8918\n",
      "Epoch 1992/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 201.9752 - val_loss: 158.3680\n",
      "Epoch 1993/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 838.1588 - val_loss: 1405.7426\n",
      "Epoch 1994/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1660.3690 - val_loss: 3030.0200\n",
      "Epoch 1995/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2552.2876 - val_loss: 5059.4531\n",
      "Epoch 1996/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1553.0894 - val_loss: 221.3167\n",
      "Epoch 1997/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 549.3915 - val_loss: 207.8667\n",
      "Epoch 1998/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 653.0779 - val_loss: 1071.3237\n",
      "Epoch 1999/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1835.2316 - val_loss: 219.2117\n",
      "Epoch 2000/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1399.0221 - val_loss: 263.6714\n",
      "Epoch 2001/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1458.0010 - val_loss: 1392.8499\n",
      "Epoch 2002/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 714.5636 - val_loss: 642.1304\n",
      "Epoch 2003/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 1213.9695 - val_loss: 2129.5542\n",
      "Epoch 2004/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1808.6249 - val_loss: 1305.1232\n",
      "Epoch 2005/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1592.9969 - val_loss: 423.2879\n",
      "Epoch 2006/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2068.9075 - val_loss: 916.8969\n",
      "Epoch 2007/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 952.3286 - val_loss: 1456.8621\n",
      "Epoch 2008/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1231.0022 - val_loss: 1209.2461\n",
      "Epoch 2009/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1072.3004 - val_loss: 988.8903\n",
      "Epoch 2010/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1088.2439 - val_loss: 2293.7642\n",
      "Epoch 2011/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2187.6133 - val_loss: 327.0027\n",
      "Epoch 2012/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1396.1663 - val_loss: 413.4038\n",
      "Epoch 2013/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 419.5384 - val_loss: 390.9554\n",
      "Epoch 2014/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 524.8336 - val_loss: 375.5182\n",
      "Epoch 2015/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 397.5905 - val_loss: 221.7731\n",
      "Epoch 2016/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 40ms/step - loss: 204.9515 - val_loss: 79.3865\n",
      "Epoch 2017/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 78.1329 - val_loss: 53.3460\n",
      "Epoch 2018/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 338.4211 - val_loss: 1410.7943\n",
      "Epoch 2019/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1074.8823 - val_loss: 620.3377\n",
      "Epoch 2020/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2447.1089 - val_loss: 1057.9661\n",
      "Epoch 2021/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2534.8735 - val_loss: 3976.6919\n",
      "Epoch 2022/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3273.9993 - val_loss: 591.4023\n",
      "Epoch 2023/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3031.1663 - val_loss: 2624.6602\n",
      "Epoch 2024/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1886.4950 - val_loss: 2288.7422\n",
      "Epoch 2025/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1965.0944 - val_loss: 557.5161\n",
      "Epoch 2026/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1033.7990 - val_loss: 584.6387\n",
      "Epoch 2027/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2656.8579 - val_loss: 1550.1099\n",
      "Epoch 2028/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2371.7388 - val_loss: 4596.1475\n",
      "Epoch 2029/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 5042.2461 - val_loss: 1746.2338\n",
      "Epoch 2030/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1276.4247 - val_loss: 854.5985\n",
      "Epoch 2031/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1217.8284 - val_loss: 1727.7322\n",
      "Epoch 2032/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1238.7281 - val_loss: 1043.5383\n",
      "Epoch 2033/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 782.2175 - val_loss: 141.0272\n",
      "Epoch 2034/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 266.2457 - val_loss: 204.4081\n",
      "Epoch 2035/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 225.1648 - val_loss: 109.9075\n",
      "Epoch 2036/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 95.9933 - val_loss: 77.3091\n",
      "Epoch 2037/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 63.1619 - val_loss: 61.1553\n",
      "Epoch 2038/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 942.2699 - val_loss: 729.8189\n",
      "Epoch 2039/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1673.6425 - val_loss: 2269.3049\n",
      "Epoch 2040/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1552.9711 - val_loss: 669.9072\n",
      "Epoch 2041/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1224.4650 - val_loss: 2594.1753\n",
      "Epoch 2042/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2639.7864 - val_loss: 492.8748\n",
      "Epoch 2043/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 912.6923 - val_loss: 992.8149\n",
      "Epoch 2044/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1454.1218 - val_loss: 1284.1785\n",
      "Epoch 2045/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1161.4497 - val_loss: 849.0754\n",
      "Epoch 2046/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1225.9498 - val_loss: 1051.6027\n",
      "Epoch 2047/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 553.6803 - val_loss: 224.4905\n",
      "Epoch 2048/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1755.8329 - val_loss: 1233.2930\n",
      "Epoch 2049/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 644.7609 - val_loss: 422.6203\n",
      "Epoch 2050/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 883.5912 - val_loss: 475.4109\n",
      "Epoch 2051/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 539.0036 - val_loss: 119.4811\n",
      "Epoch 2052/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 179.8572 - val_loss: 142.3335\n",
      "Epoch 2053/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 143.9471 - val_loss: 122.2644\n",
      "Epoch 2054/4000\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 213.3897 - val_loss: 523.9918\n",
      "Epoch 2055/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1785.6160 - val_loss: 576.2270\n",
      "Epoch 2056/4000\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 382.9269 - val_loss: 313.7630\n",
      "Epoch 2057/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 513.6180 - val_loss: 329.5997\n",
      "Epoch 2058/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1744.0205 - val_loss: 1042.5551\n",
      "Epoch 2059/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 780.2317 - val_loss: 126.8405\n",
      "Epoch 2060/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1271.0831 - val_loss: 838.4100\n",
      "Epoch 2061/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1030.2395 - val_loss: 1790.3296\n",
      "Epoch 2062/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1206.7905 - val_loss: 760.1276\n",
      "Epoch 2063/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 694.4382 - val_loss: 786.4584\n",
      "Epoch 2064/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 999.1063 - val_loss: 3630.1875\n",
      "Epoch 2065/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 5165.9478 - val_loss: 2896.9448\n",
      "Epoch 2066/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1361.8998 - val_loss: 453.0384\n",
      "Epoch 2067/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 209.1252 - val_loss: 169.5419\n",
      "Epoch 2068/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 221.2988 - val_loss: 311.5535\n",
      "Epoch 2069/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1679.7814 - val_loss: 731.7175\n",
      "Epoch 2070/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1698.5317 - val_loss: 1873.4769\n",
      "Epoch 2071/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1355.0747 - val_loss: 1684.1282\n",
      "Epoch 2072/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1441.8074 - val_loss: 1181.8931\n",
      "Epoch 2073/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1424.2493 - val_loss: 319.1973\n",
      "Epoch 2074/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1172.6425 - val_loss: 117.4467\n",
      "Epoch 2075/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 177.0355 - val_loss: 213.6625\n",
      "Epoch 2076/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 270.8410 - val_loss: 174.8179\n",
      "Epoch 2077/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 156.5557 - val_loss: 68.1942\n",
      "Epoch 2078/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 65.4691 - val_loss: 59.7860\n",
      "Epoch 2079/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 52.0126 - val_loss: 46.8756\n",
      "Epoch 2080/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 52.2925 - val_loss: 62.9103\n",
      "Epoch 2081/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 53.2100 - val_loss: 47.6236\n",
      "Epoch 2082/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 46.7827 - val_loss: 48.7617\n",
      "Epoch 2083/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 45.2383 - val_loss: 45.8875\n",
      "Epoch 2084/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 45.7045 - val_loss: 56.3144\n",
      "Epoch 2085/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 182.5272 - val_loss: 1441.9635\n",
      "Epoch 2086/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 3206.7849 - val_loss: 1374.7592\n",
      "Epoch 2087/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1088.4070 - val_loss: 644.9039\n",
      "Epoch 2088/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1165.9562 - val_loss: 3471.8513\n",
      "Epoch 2089/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 5417.7021 - val_loss: 3180.6038\n",
      "Epoch 2090/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2973.2195 - val_loss: 4741.0322\n",
      "Epoch 2091/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 5588.2993 - val_loss: 2424.4707\n",
      "Epoch 2092/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1948.6104 - val_loss: 2004.6541\n",
      "Epoch 2093/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1815.5049 - val_loss: 1435.5393\n",
      "Epoch 2094/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1832.2515 - val_loss: 364.8864\n",
      "Epoch 2095/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1178.5010 - val_loss: 1327.1664\n",
      "Epoch 2096/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1128.6490 - val_loss: 312.0034\n",
      "Epoch 2097/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 1828.9720 - val_loss: 1926.2339\n",
      "Epoch 2098/4000\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 945.7513 - val_loss: 267.8172\n",
      "Epoch 2099/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 1775.0524 - val_loss: 2561.0759\n",
      "Epoch 2100/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1592.7683 - val_loss: 2325.1001\n",
      "Epoch 2101/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2531.7534 - val_loss: 1824.4189\n",
      "Epoch 2102/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1565.8220 - val_loss: 1751.8345\n",
      "Epoch 2103/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1509.2560 - val_loss: 2138.2632\n",
      "Epoch 2104/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3510.1807 - val_loss: 1564.8856\n",
      "Epoch 2105/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1277.2700 - val_loss: 796.4390\n",
      "Epoch 2106/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1134.0841 - val_loss: 2001.6702\n",
      "Epoch 2107/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1390.4674 - val_loss: 711.0030\n",
      "Epoch 2108/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 921.0693 - val_loss: 2568.6689\n",
      "Epoch 2109/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2587.8750 - val_loss: 1481.1948\n",
      "Epoch 2110/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1519.9625 - val_loss: 2056.7988\n",
      "Epoch 2111/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1538.3710 - val_loss: 1651.1271\n",
      "Epoch 2112/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 3909.8228 - val_loss: 2607.4988\n",
      "Epoch 2113/4000\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 1758.2545 - val_loss: 1654.0713\n",
      "Epoch 2114/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1498.2803 - val_loss: 1375.7186\n",
      "Epoch 2115/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1685.6809 - val_loss: 2947.8701\n",
      "Epoch 2116/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2198.0515 - val_loss: 1375.5352\n",
      "Epoch 2117/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1296.3315 - val_loss: 1279.0792\n",
      "Epoch 2118/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1089.2633 - val_loss: 1584.6019\n",
      "Epoch 2119/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1435.8671 - val_loss: 2374.8582\n",
      "Epoch 2120/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 4092.2632 - val_loss: 2289.1309\n",
      "Epoch 2121/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1120.8381 - val_loss: 526.2219\n",
      "Epoch 2122/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1323.4376 - val_loss: 3295.5315\n",
      "Epoch 2123/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3130.5696 - val_loss: 1501.7252\n",
      "Epoch 2124/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 765.9561 - val_loss: 472.8688\n",
      "Epoch 2125/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1288.2606 - val_loss: 3391.9700\n",
      "Epoch 2126/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 916.5222 - val_loss: 2359.2559\n",
      "Epoch 2127/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2347.3909 - val_loss: 1628.8986\n",
      "Epoch 2128/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1512.3293 - val_loss: 2320.6440\n",
      "Epoch 2129/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2057.1475 - val_loss: 862.8538\n",
      "Epoch 2130/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1553.4060 - val_loss: 359.1151\n",
      "Epoch 2131/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2167.1475 - val_loss: 1931.1426\n",
      "Epoch 2132/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1537.4661 - val_loss: 1832.2640\n",
      "Epoch 2133/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1497.7284 - val_loss: 439.8231\n",
      "Epoch 2134/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 629.8352 - val_loss: 233.6884\n",
      "Epoch 2135/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 343.9959 - val_loss: 327.2668\n",
      "Epoch 2136/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 306.2008 - val_loss: 176.9441\n",
      "Epoch 2137/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 149.4535 - val_loss: 126.3102\n",
      "Epoch 2138/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 106.4734 - val_loss: 105.2934\n",
      "Epoch 2139/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 161.8806 - val_loss: 247.0761\n",
      "Epoch 2140/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 888.3400 - val_loss: 908.6218\n",
      "Epoch 2141/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1890.9485 - val_loss: 3128.0889\n",
      "Epoch 2142/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2496.2219 - val_loss: 359.5457\n",
      "Epoch 2143/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1986.9897 - val_loss: 870.6601\n",
      "Epoch 2144/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1429.6232 - val_loss: 1460.5555\n",
      "Epoch 2145/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 589.9942 - val_loss: 124.6228\n",
      "Epoch 2146/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 92.4241 - val_loss: 75.9920\n",
      "Epoch 2147/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 77.8766 - val_loss: 76.6676\n",
      "Epoch 2148/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 61.9485 - val_loss: 67.5510\n",
      "Epoch 2149/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 513.4568 - val_loss: 1729.5996\n",
      "Epoch 2150/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1569.4885 - val_loss: 1566.4590\n",
      "Epoch 2151/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 4004.7336 - val_loss: 2613.4788\n",
      "Epoch 2152/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1784.8606 - val_loss: 1089.4371\n",
      "Epoch 2153/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1203.6448 - val_loss: 1227.8376\n",
      "Epoch 2154/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1381.5043 - val_loss: 2022.9666\n",
      "Epoch 2155/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1561.5131 - val_loss: 1537.6360\n",
      "Epoch 2156/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2068.5723 - val_loss: 178.8377\n",
      "Epoch 2157/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2267.5977 - val_loss: 2029.1937\n",
      "Epoch 2158/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1795.0492 - val_loss: 2033.3291\n",
      "Epoch 2159/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1796.4623 - val_loss: 270.2038\n",
      "Epoch 2160/4000\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 1262.6862 - val_loss: 408.0559\n",
      "Epoch 2161/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 279.8684 - val_loss: 254.5305\n",
      "Epoch 2162/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 357.1466 - val_loss: 217.2003\n",
      "Epoch 2163/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 237.6830 - val_loss: 118.0723\n",
      "Epoch 2164/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 114.5232 - val_loss: 87.5054\n",
      "Epoch 2165/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 78.9195 - val_loss: 54.7726\n",
      "Epoch 2166/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 41ms/step - loss: 77.9936 - val_loss: 116.1794\n",
      "Epoch 2167/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 711.3231 - val_loss: 2864.7341\n",
      "Epoch 2168/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 3782.5437 - val_loss: 1190.0166\n",
      "Epoch 2169/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2741.7422 - val_loss: 4572.5796\n",
      "Epoch 2170/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 4247.1958 - val_loss: 912.6068\n",
      "Epoch 2171/4000\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 733.1102 - val_loss: 514.8975\n",
      "Epoch 2172/4000\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 789.7228 - val_loss: 748.5071\n",
      "Epoch 2173/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 1105.0913 - val_loss: 849.1612\n",
      "Epoch 2174/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1498.8894 - val_loss: 4193.8735\n",
      "Epoch 2175/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2213.1404 - val_loss: 914.1868\n",
      "Epoch 2176/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1092.7943 - val_loss: 561.8056\n",
      "Epoch 2177/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1515.5969 - val_loss: 1984.9233\n",
      "Epoch 2178/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1418.4039 - val_loss: 1496.3718\n",
      "Epoch 2179/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1467.1337 - val_loss: 400.1626\n",
      "Epoch 2180/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 950.4582 - val_loss: 2089.4019\n",
      "Epoch 2181/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1945.0355 - val_loss: 4773.7686\n",
      "Epoch 2182/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2295.3303 - val_loss: 1815.6510\n",
      "Epoch 2183/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 880.2812 - val_loss: 1373.8969\n",
      "Epoch 2184/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2291.0508 - val_loss: 1478.9847\n",
      "Epoch 2185/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1513.7217 - val_loss: 1053.6302\n",
      "Epoch 2186/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1551.9664 - val_loss: 1411.4529\n",
      "Epoch 2187/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1241.2180 - val_loss: 1360.0106\n",
      "Epoch 2188/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1077.6514 - val_loss: 1277.0837\n",
      "Epoch 2189/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1211.3933 - val_loss: 1095.5183\n",
      "Epoch 2190/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2317.6316 - val_loss: 724.7708\n",
      "Epoch 2191/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2177.3545 - val_loss: 2368.0200\n",
      "Epoch 2192/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1439.3545 - val_loss: 641.5983\n",
      "Epoch 2193/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 885.4923 - val_loss: 1706.8555\n",
      "Epoch 2194/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1321.4785 - val_loss: 197.1420\n",
      "Epoch 2195/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 318.7411 - val_loss: 284.5484\n",
      "Epoch 2196/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 342.1679 - val_loss: 216.9267\n",
      "Epoch 2197/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 208.9676 - val_loss: 92.8698\n",
      "Epoch 2198/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 113.0187 - val_loss: 114.3998\n",
      "Epoch 2199/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 107.6993 - val_loss: 376.0844\n",
      "Epoch 2200/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 795.6425 - val_loss: 1780.9445\n",
      "Epoch 2201/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1872.0942 - val_loss: 329.1946\n",
      "Epoch 2202/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 460.6346 - val_loss: 1107.4437\n",
      "Epoch 2203/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1357.3235 - val_loss: 1570.8146\n",
      "Epoch 2204/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1314.5770 - val_loss: 1289.0863\n",
      "Epoch 2205/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1216.2517 - val_loss: 2069.5886\n",
      "Epoch 2206/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2148.2261 - val_loss: 1483.2528\n",
      "Epoch 2207/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 840.2633 - val_loss: 2930.7573\n",
      "Epoch 2208/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2482.7263 - val_loss: 1498.4413\n",
      "Epoch 2209/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 923.9218 - val_loss: 1469.4968\n",
      "Epoch 2210/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1470.4807 - val_loss: 1742.2590\n",
      "Epoch 2211/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1849.4354 - val_loss: 276.0513\n",
      "Epoch 2212/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 971.6072 - val_loss: 2035.8047\n",
      "Epoch 2213/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2795.3618 - val_loss: 2361.4246\n",
      "Epoch 2214/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1709.6953 - val_loss: 1187.2595\n",
      "Epoch 2215/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1163.5302 - val_loss: 1722.1483\n",
      "Epoch 2216/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1630.2499 - val_loss: 4239.3193\n",
      "Epoch 2217/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1044.7816 - val_loss: 144.8378\n",
      "Epoch 2218/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1282.8727 - val_loss: 887.8254\n",
      "Epoch 2219/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2047.3630 - val_loss: 3796.4597\n",
      "Epoch 2220/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3287.0288 - val_loss: 827.4053\n",
      "Epoch 2221/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 693.9778 - val_loss: 634.3932\n",
      "Epoch 2222/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 583.8658 - val_loss: 294.1982\n",
      "Epoch 2223/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 253.4388 - val_loss: 150.1302\n",
      "Epoch 2224/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 147.2888 - val_loss: 99.1872\n",
      "Epoch 2225/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 96.4387 - val_loss: 71.2245\n",
      "Epoch 2226/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 69.0447 - val_loss: 60.7652\n",
      "Epoch 2227/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 56.5305 - val_loss: 59.3865\n",
      "Epoch 2228/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 56.0116 - val_loss: 51.6591\n",
      "Epoch 2229/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 62.5921 - val_loss: 66.8555\n",
      "Epoch 2230/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 843.3251 - val_loss: 2259.7329\n",
      "Epoch 2231/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1647.6079 - val_loss: 615.9730\n",
      "Epoch 2232/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1708.2854 - val_loss: 602.4088\n",
      "Epoch 2233/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1073.7109 - val_loss: 258.0016\n",
      "Epoch 2234/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1509.1837 - val_loss: 589.2076\n",
      "Epoch 2235/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2459.1145 - val_loss: 2745.9285\n",
      "Epoch 2236/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1759.1276 - val_loss: 704.1467\n",
      "Epoch 2237/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 816.0516 - val_loss: 1212.5894\n",
      "Epoch 2238/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2345.9893 - val_loss: 756.3084\n",
      "Epoch 2239/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 702.9089 - val_loss: 103.4238\n",
      "Epoch 2240/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1118.4646 - val_loss: 385.0200\n",
      "Epoch 2241/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2719.8672 - val_loss: 3921.9460\n",
      "Epoch 2242/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2749.3171 - val_loss: 254.7013\n",
      "Epoch 2243/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 587.7736 - val_loss: 407.9664\n",
      "Epoch 2244/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 901.7228 - val_loss: 2647.7642\n",
      "Epoch 2245/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2682.1106 - val_loss: 300.5582\n",
      "Epoch 2246/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2197.8357 - val_loss: 1286.7130\n",
      "Epoch 2247/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1141.5598 - val_loss: 1022.7941\n",
      "Epoch 2248/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 624.2230 - val_loss: 246.6902\n",
      "Epoch 2249/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 239.7141 - val_loss: 138.5872\n",
      "Epoch 2250/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 177.6317 - val_loss: 173.6133\n",
      "Epoch 2251/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 132.5578 - val_loss: 262.4464\n",
      "Epoch 2252/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 763.4928 - val_loss: 718.2920\n",
      "Epoch 2253/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1004.1485 - val_loss: 118.3659\n",
      "Epoch 2254/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2122.7988 - val_loss: 2665.4319\n",
      "Epoch 2255/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1520.0632 - val_loss: 612.6804\n",
      "Epoch 2256/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1391.8810 - val_loss: 2627.5339\n",
      "Epoch 2257/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2176.6746 - val_loss: 175.6043\n",
      "Epoch 2258/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 471.6627 - val_loss: 828.2059\n",
      "Epoch 2259/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 981.7275 - val_loss: 1448.5206\n",
      "Epoch 2260/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1969.3778 - val_loss: 514.0067\n",
      "Epoch 2261/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 371.8023 - val_loss: 304.7361\n",
      "Epoch 2262/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 655.7838 - val_loss: 1040.7812\n",
      "Epoch 2263/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 964.2291 - val_loss: 956.7800\n",
      "Epoch 2264/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1002.1791 - val_loss: 1523.2681\n",
      "Epoch 2265/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 931.4443 - val_loss: 198.7935\n",
      "Epoch 2266/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 388.7416 - val_loss: 386.4310\n",
      "Epoch 2267/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 453.8330 - val_loss: 309.4852\n",
      "Epoch 2268/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 359.6795 - val_loss: 259.5853\n",
      "Epoch 2269/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1516.1293 - val_loss: 1840.0038\n",
      "Epoch 2270/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 983.9750 - val_loss: 683.5098\n",
      "Epoch 2271/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1008.3756 - val_loss: 1597.1792\n",
      "Epoch 2272/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1846.6041 - val_loss: 2785.6978\n",
      "Epoch 2273/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2431.8601 - val_loss: 4723.2529\n",
      "Epoch 2274/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 3929.0679 - val_loss: 4391.8774\n",
      "Epoch 2275/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 3232.7122 - val_loss: 110.1825\n",
      "Epoch 2276/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1473.2968 - val_loss: 928.8513\n",
      "Epoch 2277/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1456.2421 - val_loss: 1078.6525\n",
      "Epoch 2278/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 983.1517 - val_loss: 588.3925\n",
      "Epoch 2279/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 502.5182 - val_loss: 169.0022\n",
      "Epoch 2280/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2739.2542 - val_loss: 3362.3376\n",
      "Epoch 2281/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2098.3369 - val_loss: 1711.5868\n",
      "Epoch 2282/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2218.5571 - val_loss: 1428.2688\n",
      "Epoch 2283/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1145.1079 - val_loss: 605.8182\n",
      "Epoch 2284/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 718.0866 - val_loss: 306.7021\n",
      "Epoch 2285/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 255.5614 - val_loss: 167.6675\n",
      "Epoch 2286/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 140.7072 - val_loss: 111.0593\n",
      "Epoch 2287/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 119.2579 - val_loss: 369.5529\n",
      "Epoch 2288/4000\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 599.4836 - val_loss: 988.3224\n",
      "Epoch 2289/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 1000.8824 - val_loss: 2415.4407\n",
      "Epoch 2290/4000\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 4245.1870 - val_loss: 2382.6797\n",
      "Epoch 2291/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1929.5416 - val_loss: 1303.8346\n",
      "Epoch 2292/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1394.7150 - val_loss: 2569.8923\n",
      "Epoch 2293/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2562.1609 - val_loss: 818.1599\n",
      "Epoch 2294/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1412.2401 - val_loss: 1629.0906\n",
      "Epoch 2295/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1297.6025 - val_loss: 1470.5754\n",
      "Epoch 2296/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1008.2242 - val_loss: 649.0054\n",
      "Epoch 2297/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 479.1022 - val_loss: 196.4193\n",
      "Epoch 2298/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 304.1530 - val_loss: 206.2001\n",
      "Epoch 2299/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 204.3039 - val_loss: 122.3833\n",
      "Epoch 2300/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 109.0156 - val_loss: 98.3174\n",
      "Epoch 2301/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 82.6986 - val_loss: 73.2986\n",
      "Epoch 2302/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 69.8286 - val_loss: 71.7583\n",
      "Epoch 2303/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 109.9877 - val_loss: 409.2170\n",
      "Epoch 2304/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 868.9897 - val_loss: 2056.2258\n",
      "Epoch 2305/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1898.2480 - val_loss: 158.8654\n",
      "Epoch 2306/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1064.9938 - val_loss: 1728.9260\n",
      "Epoch 2307/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 760.2887 - val_loss: 440.0749\n",
      "Epoch 2308/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2175.4150 - val_loss: 974.0513\n",
      "Epoch 2309/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1238.6335 - val_loss: 1295.8953\n",
      "Epoch 2310/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 697.7688 - val_loss: 330.9680\n",
      "Epoch 2311/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 579.2953 - val_loss: 536.9413\n",
      "Epoch 2312/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 720.2449 - val_loss: 1531.9523\n",
      "Epoch 2313/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2655.1575 - val_loss: 840.9772\n",
      "Epoch 2314/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 693.5062 - val_loss: 92.1351\n",
      "Epoch 2315/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2025.7902 - val_loss: 1785.7512\n",
      "Epoch 2316/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 40ms/step - loss: 1070.0997 - val_loss: 1475.4196\n",
      "Epoch 2317/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1775.3210 - val_loss: 327.8649\n",
      "Epoch 2318/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 743.0535 - val_loss: 1450.7140\n",
      "Epoch 2319/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1107.3689 - val_loss: 170.9203\n",
      "Epoch 2320/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 142.8027 - val_loss: 78.6406\n",
      "Epoch 2321/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 77.3902 - val_loss: 90.9475\n",
      "Epoch 2322/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 72.0073 - val_loss: 82.6847\n",
      "Epoch 2323/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 308.8163 - val_loss: 1551.3496\n",
      "Epoch 2324/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2062.3228 - val_loss: 1099.9939\n",
      "Epoch 2325/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 330.8065 - val_loss: 263.8377\n",
      "Epoch 2326/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1861.5574 - val_loss: 1934.2697\n",
      "Epoch 2327/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1543.4580 - val_loss: 1539.6405\n",
      "Epoch 2328/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1371.2648 - val_loss: 2027.8438\n",
      "Epoch 2329/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3185.8320 - val_loss: 1147.8711\n",
      "Epoch 2330/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 900.9327 - val_loss: 253.1960\n",
      "Epoch 2331/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 281.1045 - val_loss: 230.4211\n",
      "Epoch 2332/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 270.1585 - val_loss: 178.2719\n",
      "Epoch 2333/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 161.5638 - val_loss: 110.6804\n",
      "Epoch 2334/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 106.9951 - val_loss: 87.5173\n",
      "Epoch 2335/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 84.4939 - val_loss: 74.7777\n",
      "Epoch 2336/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 388.7943 - val_loss: 1546.4062\n",
      "Epoch 2337/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1273.2106 - val_loss: 439.5811\n",
      "Epoch 2338/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1535.7617 - val_loss: 162.3530\n",
      "Epoch 2339/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2760.0732 - val_loss: 3394.3433\n",
      "Epoch 2340/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2666.5750 - val_loss: 1243.1545\n",
      "Epoch 2341/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3212.1013 - val_loss: 1919.4297\n",
      "Epoch 2342/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1067.0093 - val_loss: 365.8768\n",
      "Epoch 2343/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1890.9982 - val_loss: 2347.6140\n",
      "Epoch 2344/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1388.8339 - val_loss: 885.1190\n",
      "Epoch 2345/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 868.0138 - val_loss: 1441.8875\n",
      "Epoch 2346/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1264.8524 - val_loss: 116.5275\n",
      "Epoch 2347/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 841.0881 - val_loss: 2212.5168\n",
      "Epoch 2348/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1797.2041 - val_loss: 387.7083\n",
      "Epoch 2349/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 679.9194 - val_loss: 201.6379\n",
      "Epoch 2350/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1008.7208 - val_loss: 2179.4990\n",
      "Epoch 2351/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1766.4268 - val_loss: 1811.8651\n",
      "Epoch 2352/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2531.2529 - val_loss: 470.1101\n",
      "Epoch 2353/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2236.0869 - val_loss: 2438.0068\n",
      "Epoch 2354/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1784.6600 - val_loss: 1761.5563\n",
      "Epoch 2355/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1813.9515 - val_loss: 280.7911\n",
      "Epoch 2356/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 339.9580 - val_loss: 343.4604\n",
      "Epoch 2357/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 484.8240 - val_loss: 310.4458\n",
      "Epoch 2358/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 548.7815 - val_loss: 1438.1335\n",
      "Epoch 2359/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1294.3129 - val_loss: 576.1553\n",
      "Epoch 2360/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 860.8645 - val_loss: 620.6671\n",
      "Epoch 2361/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 963.2524 - val_loss: 1606.3217\n",
      "Epoch 2362/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3862.3479 - val_loss: 2532.2646\n",
      "Epoch 2363/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1873.6493 - val_loss: 2804.5139\n",
      "Epoch 2364/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3606.5366 - val_loss: 1250.3385\n",
      "Epoch 2365/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1641.5779 - val_loss: 3250.6462\n",
      "Epoch 2366/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3041.7537 - val_loss: 356.6219\n",
      "Epoch 2367/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3602.9658 - val_loss: 4610.0381\n",
      "Epoch 2368/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3530.9490 - val_loss: 1759.7646\n",
      "Epoch 2369/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 912.2629 - val_loss: 1165.7386\n",
      "Epoch 2370/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1403.2129 - val_loss: 562.7116\n",
      "Epoch 2371/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 402.8040 - val_loss: 298.6848\n",
      "Epoch 2372/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 410.5775 - val_loss: 282.9921\n",
      "Epoch 2373/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 314.3923 - val_loss: 174.1353\n",
      "Epoch 2374/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 178.9145 - val_loss: 119.0575\n",
      "Epoch 2375/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 188.9880 - val_loss: 111.3081\n",
      "Epoch 2376/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 977.4613 - val_loss: 838.7583\n",
      "Epoch 2377/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1658.9259 - val_loss: 2609.0576\n",
      "Epoch 2378/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2154.2537 - val_loss: 1248.5425\n",
      "Epoch 2379/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 4926.4736 - val_loss: 4737.5586\n",
      "Epoch 2380/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 3306.9705 - val_loss: 147.8077\n",
      "Epoch 2381/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1017.4294 - val_loss: 464.0479\n",
      "Epoch 2382/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1839.8214 - val_loss: 1459.7850\n",
      "Epoch 2383/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1586.3552 - val_loss: 2592.5562\n",
      "Epoch 2384/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2210.6699 - val_loss: 4875.9517\n",
      "Epoch 2385/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1211.1172 - val_loss: 240.7223\n",
      "Epoch 2386/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2071.5471 - val_loss: 2156.1323\n",
      "Epoch 2387/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1240.8666 - val_loss: 561.0710\n",
      "Epoch 2388/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 778.4058 - val_loss: 1226.6700\n",
      "Epoch 2389/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1140.4744 - val_loss: 2176.0732\n",
      "Epoch 2390/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2602.0283 - val_loss: 488.3168\n",
      "Epoch 2391/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1077.9828 - val_loss: 398.7740\n",
      "Epoch 2392/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1409.7264 - val_loss: 1997.6996\n",
      "Epoch 2393/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1541.0753 - val_loss: 2261.8879\n",
      "Epoch 2394/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2751.0906 - val_loss: 406.0058\n",
      "Epoch 2395/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1205.4988 - val_loss: 618.4724\n",
      "Epoch 2396/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 584.6262 - val_loss: 285.6536\n",
      "Epoch 2397/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 207.0898 - val_loss: 185.6686\n",
      "Epoch 2398/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 250.6322 - val_loss: 217.9467\n",
      "Epoch 2399/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 867.4844 - val_loss: 936.1579\n",
      "Epoch 2400/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1685.2423 - val_loss: 3573.8977\n",
      "Epoch 2401/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3205.9092 - val_loss: 206.8011\n",
      "Epoch 2402/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 890.3417 - val_loss: 98.6462\n",
      "Epoch 2403/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 516.6927 - val_loss: 297.6466\n",
      "Epoch 2404/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1896.4465 - val_loss: 1818.3783\n",
      "Epoch 2405/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1350.4904 - val_loss: 1264.7988\n",
      "Epoch 2406/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 1088.1530 - val_loss: 1650.5723\n",
      "Epoch 2407/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2439.2156 - val_loss: 531.5562\n",
      "Epoch 2408/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1223.4696 - val_loss: 557.1175\n",
      "Epoch 2409/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1215.2034 - val_loss: 1372.1331\n",
      "Epoch 2410/4000\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 1042.2985 - val_loss: 2064.0056\n",
      "Epoch 2411/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2276.1287 - val_loss: 198.4792\n",
      "Epoch 2412/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1684.7961 - val_loss: 996.5538\n",
      "Epoch 2413/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1373.6572 - val_loss: 1868.2699\n",
      "Epoch 2414/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1570.4336 - val_loss: 2180.4023\n",
      "Epoch 2415/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2750.0474 - val_loss: 531.6529\n",
      "Epoch 2416/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 702.7361 - val_loss: 531.5943\n",
      "Epoch 2417/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1279.9027 - val_loss: 231.1404\n",
      "Epoch 2418/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1659.4279 - val_loss: 1096.9972\n",
      "Epoch 2419/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 877.8513 - val_loss: 733.9604\n",
      "Epoch 2420/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 940.5509 - val_loss: 1280.3120\n",
      "Epoch 2421/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1282.6284 - val_loss: 2396.0957\n",
      "Epoch 2422/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2589.6008 - val_loss: 482.3156\n",
      "Epoch 2423/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1267.4907 - val_loss: 1752.4359\n",
      "Epoch 2424/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1285.9702 - val_loss: 1010.1495\n",
      "Epoch 2425/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 728.3271 - val_loss: 691.5484\n",
      "Epoch 2426/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 516.4723 - val_loss: 224.4964\n",
      "Epoch 2427/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 284.1828 - val_loss: 205.2853\n",
      "Epoch 2428/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 203.8565 - val_loss: 124.5323\n",
      "Epoch 2429/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 116.5097 - val_loss: 101.1157\n",
      "Epoch 2430/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 90.6761 - val_loss: 71.8824\n",
      "Epoch 2431/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 68.7674 - val_loss: 62.2472\n",
      "Epoch 2432/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 65.6919 - val_loss: 69.4391\n",
      "Epoch 2433/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 84.4123 - val_loss: 279.0576\n",
      "Epoch 2434/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 860.3983 - val_loss: 372.3503\n",
      "Epoch 2435/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1379.5181 - val_loss: 250.1761\n",
      "Epoch 2436/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2018.2972 - val_loss: 1982.8038\n",
      "Epoch 2437/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1923.7180 - val_loss: 3292.4189\n",
      "Epoch 2438/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3919.8040 - val_loss: 1387.5793\n",
      "Epoch 2439/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 451.4994 - val_loss: 743.5503\n",
      "Epoch 2440/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2437.7185 - val_loss: 1844.8884\n",
      "Epoch 2441/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 942.4952 - val_loss: 882.0560\n",
      "Epoch 2442/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1011.8997 - val_loss: 1001.3681\n",
      "Epoch 2443/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 992.6275 - val_loss: 490.5328\n",
      "Epoch 2444/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 569.0593 - val_loss: 640.6097\n",
      "Epoch 2445/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 359.2985 - val_loss: 145.8444\n",
      "Epoch 2446/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 193.6168 - val_loss: 244.6957\n",
      "Epoch 2447/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 243.6904 - val_loss: 164.7368\n",
      "Epoch 2448/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 769.6905 - val_loss: 852.2814\n",
      "Epoch 2449/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1087.1893 - val_loss: 1391.4459\n",
      "Epoch 2450/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1333.0907 - val_loss: 2451.6978\n",
      "Epoch 2451/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2259.5391 - val_loss: 689.1174\n",
      "Epoch 2452/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2221.9937 - val_loss: 2163.4634\n",
      "Epoch 2453/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1268.2863 - val_loss: 426.4435\n",
      "Epoch 2454/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 911.8019 - val_loss: 1904.5709\n",
      "Epoch 2455/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1367.6853 - val_loss: 534.4340\n",
      "Epoch 2456/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1039.1976 - val_loss: 978.1237\n",
      "Epoch 2457/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1708.6755 - val_loss: 259.1600\n",
      "Epoch 2458/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 368.5082 - val_loss: 232.3501\n",
      "Epoch 2459/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 237.5305 - val_loss: 257.7852\n",
      "Epoch 2460/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 328.4749 - val_loss: 244.2152\n",
      "Epoch 2461/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 295.0057 - val_loss: 167.3534\n",
      "Epoch 2462/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 163.3511 - val_loss: 77.5978\n",
      "Epoch 2463/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 98.0241 - val_loss: 73.1986\n",
      "Epoch 2464/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 66.1016 - val_loss: 59.1676\n",
      "Epoch 2465/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 67.4114 - val_loss: 66.4820\n",
      "Epoch 2466/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 39ms/step - loss: 77.6517 - val_loss: 119.9419\n",
      "Epoch 2467/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 194.6087 - val_loss: 68.0286\n",
      "Epoch 2468/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 54.0744 - val_loss: 55.7512\n",
      "Epoch 2469/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 78.0027 - val_loss: 154.9343\n",
      "Epoch 2470/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 303.1326 - val_loss: 497.2565\n",
      "Epoch 2471/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 817.8760 - val_loss: 217.8038\n",
      "Epoch 2472/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 663.9691 - val_loss: 1479.3506\n",
      "Epoch 2473/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1206.2889 - val_loss: 1914.0079\n",
      "Epoch 2474/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2895.5857 - val_loss: 919.5762\n",
      "Epoch 2475/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1066.6206 - val_loss: 816.0493\n",
      "Epoch 2476/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1467.1210 - val_loss: 2303.3716\n",
      "Epoch 2477/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1560.2817 - val_loss: 383.9427\n",
      "Epoch 2478/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 856.8058 - val_loss: 1516.7148\n",
      "Epoch 2479/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1578.3081 - val_loss: 717.1283\n",
      "Epoch 2480/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1146.3267 - val_loss: 235.6302\n",
      "Epoch 2481/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 293.5714 - val_loss: 215.9493\n",
      "Epoch 2482/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 534.1884 - val_loss: 1582.1923\n",
      "Epoch 2483/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1612.8125 - val_loss: 271.5174\n",
      "Epoch 2484/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1850.7010 - val_loss: 844.6445\n",
      "Epoch 2485/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 800.0098 - val_loss: 164.9136\n",
      "Epoch 2486/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1459.3777 - val_loss: 1595.8523\n",
      "Epoch 2487/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 801.6366 - val_loss: 220.6474\n",
      "Epoch 2488/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 414.8640 - val_loss: 387.4195\n",
      "Epoch 2489/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 458.8763 - val_loss: 253.7840\n",
      "Epoch 2490/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 274.0435 - val_loss: 147.1686\n",
      "Epoch 2491/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 139.6362 - val_loss: 126.3795\n",
      "Epoch 2492/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 679.6891 - val_loss: 930.5035\n",
      "Epoch 2493/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1719.7007 - val_loss: 4131.4873\n",
      "Epoch 2494/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 4410.5171 - val_loss: 1311.4760\n",
      "Epoch 2495/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1516.0411 - val_loss: 1606.7904\n",
      "Epoch 2496/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1116.1957 - val_loss: 1734.9495\n",
      "Epoch 2497/4000\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 1538.3561 - val_loss: 4139.8750\n",
      "Epoch 2498/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3384.2590 - val_loss: 2833.0093\n",
      "Epoch 2499/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1964.0181 - val_loss: 1536.8190\n",
      "Epoch 2500/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1497.6467 - val_loss: 2187.6104\n",
      "Epoch 2501/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1429.6132 - val_loss: 692.0672\n",
      "Epoch 2502/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1555.5011 - val_loss: 2073.7627\n",
      "Epoch 2503/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1648.3041 - val_loss: 2634.4788\n",
      "Epoch 2504/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 4158.3970 - val_loss: 2275.4185\n",
      "Epoch 2505/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1498.0878 - val_loss: 911.0258\n",
      "Epoch 2506/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 856.2656 - val_loss: 1392.3251\n",
      "Epoch 2507/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1077.2167 - val_loss: 879.8138\n",
      "Epoch 2508/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1026.7238 - val_loss: 1047.4912\n",
      "Epoch 2509/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2166.4014 - val_loss: 602.8207\n",
      "Epoch 2510/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 845.3154 - val_loss: 223.4644\n",
      "Epoch 2511/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 282.9184 - val_loss: 209.8096\n",
      "Epoch 2512/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 549.5840 - val_loss: 204.0905\n",
      "Epoch 2513/4000\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 307.1133 - val_loss: 820.2513\n",
      "Epoch 2514/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 988.8112 - val_loss: 1570.6162\n",
      "Epoch 2515/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2300.8860 - val_loss: 405.0058\n",
      "Epoch 2516/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 402.3593 - val_loss: 288.9863\n",
      "Epoch 2517/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 422.3941 - val_loss: 314.1896\n",
      "Epoch 2518/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 425.2587 - val_loss: 260.9662\n",
      "Epoch 2519/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1924.4535 - val_loss: 2216.6638\n",
      "Epoch 2520/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1637.5022 - val_loss: 1368.6879\n",
      "Epoch 2521/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1506.4069 - val_loss: 108.5098\n",
      "Epoch 2522/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 531.1667 - val_loss: 897.1105\n",
      "Epoch 2523/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1842.8234 - val_loss: 373.5033\n",
      "Epoch 2524/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1232.2900 - val_loss: 997.0925\n",
      "Epoch 2525/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1568.6259 - val_loss: 1952.2401\n",
      "Epoch 2526/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1408.0852 - val_loss: 864.6569\n",
      "Epoch 2527/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 994.1838 - val_loss: 133.1348\n",
      "Epoch 2528/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 430.7850 - val_loss: 1107.7474\n",
      "Epoch 2529/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 981.2932 - val_loss: 1299.3452\n",
      "Epoch 2530/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1064.4785 - val_loss: 423.0074\n",
      "Epoch 2531/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 788.8372 - val_loss: 2439.7173\n",
      "Epoch 2532/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 964.9429 - val_loss: 916.7841\n",
      "Epoch 2533/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 796.3681 - val_loss: 1596.3041\n",
      "Epoch 2534/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1426.5032 - val_loss: 677.1039\n",
      "Epoch 2535/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 351.2502 - val_loss: 250.2084\n",
      "Epoch 2536/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 302.0923 - val_loss: 231.4378\n",
      "Epoch 2537/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 209.8653 - val_loss: 232.3241\n",
      "Epoch 2538/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 696.6877 - val_loss: 2720.3379\n",
      "Epoch 2539/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1741.8774 - val_loss: 675.5621\n",
      "Epoch 2540/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 699.5110 - val_loss: 197.0619\n",
      "Epoch 2541/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1474.8630 - val_loss: 1643.5765\n",
      "Epoch 2542/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 1379.5087 - val_loss: 2857.1174\n",
      "Epoch 2543/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3142.6184 - val_loss: 543.1239\n",
      "Epoch 2544/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 894.2048 - val_loss: 352.7596\n",
      "Epoch 2545/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1413.2389 - val_loss: 2056.5193\n",
      "Epoch 2546/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1388.8807 - val_loss: 808.0047\n",
      "Epoch 2547/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1035.4270 - val_loss: 1114.2849\n",
      "Epoch 2548/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2439.4937 - val_loss: 1016.7058\n",
      "Epoch 2549/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1257.8623 - val_loss: 1207.4928\n",
      "Epoch 2550/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1008.0418 - val_loss: 916.9940\n",
      "Epoch 2551/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 931.2078 - val_loss: 1157.5405\n",
      "Epoch 2552/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1039.3287 - val_loss: 1716.8173\n",
      "Epoch 2553/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1793.0537 - val_loss: 248.9391\n",
      "Epoch 2554/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 214.5436 - val_loss: 238.8649\n",
      "Epoch 2555/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 321.4497 - val_loss: 208.9208\n",
      "Epoch 2556/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 224.4053 - val_loss: 112.2072\n",
      "Epoch 2557/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 98.9636 - val_loss: 67.3158\n",
      "Epoch 2558/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 69.3383 - val_loss: 65.9344\n",
      "Epoch 2559/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 69.2261 - val_loss: 57.8670\n",
      "Epoch 2560/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 58.0435 - val_loss: 62.3104\n",
      "Epoch 2561/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 60.1617 - val_loss: 77.0852\n",
      "Epoch 2562/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 61.5341 - val_loss: 62.1546\n",
      "Epoch 2563/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 62.0031 - val_loss: 77.4840\n",
      "Epoch 2564/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 79.1498 - val_loss: 59.9190\n",
      "Epoch 2565/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 55.7771 - val_loss: 57.7093\n",
      "Epoch 2566/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 111.5853 - val_loss: 272.4301\n",
      "Epoch 2567/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 275.3833 - val_loss: 274.0279\n",
      "Epoch 2568/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1930.8848 - val_loss: 3696.4155\n",
      "Epoch 2569/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2871.6023 - val_loss: 229.7571\n",
      "Epoch 2570/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 565.8245 - val_loss: 919.7409\n",
      "Epoch 2571/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 922.8509 - val_loss: 472.7655\n",
      "Epoch 2572/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1955.2649 - val_loss: 791.4492\n",
      "Epoch 2573/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1677.3369 - val_loss: 1528.6382\n",
      "Epoch 2574/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1407.4141 - val_loss: 2793.6208\n",
      "Epoch 2575/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2793.1338 - val_loss: 2972.1680\n",
      "Epoch 2576/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2245.9526 - val_loss: 958.9203\n",
      "Epoch 2577/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1247.1371 - val_loss: 805.2990\n",
      "Epoch 2578/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1522.2606 - val_loss: 2368.2622\n",
      "Epoch 2579/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1590.0359 - val_loss: 141.3360\n",
      "Epoch 2580/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 281.4078 - val_loss: 285.2834\n",
      "Epoch 2581/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 264.4497 - val_loss: 615.9501\n",
      "Epoch 2582/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1602.1526 - val_loss: 829.3085\n",
      "Epoch 2583/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 490.4913 - val_loss: 189.3815\n",
      "Epoch 2584/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2471.6367 - val_loss: 2742.6597\n",
      "Epoch 2585/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1818.9233 - val_loss: 1256.3293\n",
      "Epoch 2586/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1176.4324 - val_loss: 848.3450\n",
      "Epoch 2587/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1718.9282 - val_loss: 205.1828\n",
      "Epoch 2588/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 647.9246 - val_loss: 601.0186\n",
      "Epoch 2589/4000\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 2336.5918 - val_loss: 1864.2418\n",
      "Epoch 2590/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 941.7792 - val_loss: 1289.6229\n",
      "Epoch 2591/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1559.6594 - val_loss: 3530.7839\n",
      "Epoch 2592/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1221.7968 - val_loss: 159.9941\n",
      "Epoch 2593/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1399.1100 - val_loss: 732.5425\n",
      "Epoch 2594/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 506.4553 - val_loss: 258.4744\n",
      "Epoch 2595/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2047.9237 - val_loss: 2074.3376\n",
      "Epoch 2596/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1245.3807 - val_loss: 980.5966\n",
      "Epoch 2597/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 682.5722 - val_loss: 311.9681\n",
      "Epoch 2598/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 712.5164 - val_loss: 868.8406\n",
      "Epoch 2599/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1536.7214 - val_loss: 2720.7024\n",
      "Epoch 2600/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2211.6516 - val_loss: 4377.5000\n",
      "Epoch 2601/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1622.5421 - val_loss: 742.9455\n",
      "Epoch 2602/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1060.3103 - val_loss: 1171.0280\n",
      "Epoch 2603/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 763.4279 - val_loss: 526.7397\n",
      "Epoch 2604/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1570.4219 - val_loss: 3030.1465\n",
      "Epoch 2605/4000\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 2351.9448 - val_loss: 3768.4924\n",
      "Epoch 2606/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1974.7539 - val_loss: 1116.6224\n",
      "Epoch 2607/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 790.5534 - val_loss: 369.1634\n",
      "Epoch 2608/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 327.9835 - val_loss: 234.1168\n",
      "Epoch 2609/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 163.5443 - val_loss: 134.9324\n",
      "Epoch 2610/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 124.4771 - val_loss: 134.9618\n",
      "Epoch 2611/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 96.9736 - val_loss: 69.8752\n",
      "Epoch 2612/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 76.6492 - val_loss: 96.0359\n",
      "Epoch 2613/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 106.2240 - val_loss: 154.4801\n",
      "Epoch 2614/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 94.6110 - val_loss: 65.6023\n",
      "Epoch 2615/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 65.3084 - val_loss: 64.7410\n",
      "Epoch 2616/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 44ms/step - loss: 58.8559 - val_loss: 59.9669\n",
      "Epoch 2617/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 62.8213 - val_loss: 66.5838\n",
      "Epoch 2618/4000\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 58.1506 - val_loss: 59.9011\n",
      "Epoch 2619/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 152.6922 - val_loss: 122.2849\n",
      "Epoch 2620/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1441.8383 - val_loss: 1563.3710\n",
      "Epoch 2621/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 916.8972 - val_loss: 796.0894\n",
      "Epoch 2622/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1013.6120 - val_loss: 1362.3942\n",
      "Epoch 2623/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 879.2274 - val_loss: 380.6006\n",
      "Epoch 2624/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 774.6576 - val_loss: 1823.7523\n",
      "Epoch 2625/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1336.9768 - val_loss: 392.1250\n",
      "Epoch 2626/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 961.0840 - val_loss: 1456.0709\n",
      "Epoch 2627/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1489.0211 - val_loss: 1372.9884\n",
      "Epoch 2628/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1242.6763 - val_loss: 1053.7817\n",
      "Epoch 2629/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1565.2893 - val_loss: 2751.2930\n",
      "Epoch 2630/4000\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 2162.8147 - val_loss: 162.0680\n",
      "Epoch 2631/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2258.0361 - val_loss: 2209.3750\n",
      "Epoch 2632/4000\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 1400.6846 - val_loss: 1532.9476\n",
      "Epoch 2633/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1195.7070 - val_loss: 396.5192\n",
      "Epoch 2634/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 772.1792 - val_loss: 659.5713\n",
      "Epoch 2635/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1071.0348 - val_loss: 2485.4521\n",
      "Epoch 2636/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 1015.4366 - val_loss: 144.5337\n",
      "Epoch 2637/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 390.3586 - val_loss: 210.9308\n",
      "Epoch 2638/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 112.3250 - val_loss: 95.8173\n",
      "Epoch 2639/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 144.9649 - val_loss: 79.0931\n",
      "Epoch 2640/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1242.6438 - val_loss: 1028.9492\n",
      "Epoch 2641/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 419.2625 - val_loss: 227.2886\n",
      "Epoch 2642/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 360.7532 - val_loss: 294.2494\n",
      "Epoch 2643/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 327.7589 - val_loss: 193.3644\n",
      "Epoch 2644/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 179.5788 - val_loss: 95.1834\n",
      "Epoch 2645/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 94.7788 - val_loss: 110.2019\n",
      "Epoch 2646/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 79.0479 - val_loss: 66.8579\n",
      "Epoch 2647/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 88.7886 - val_loss: 65.5860\n",
      "Epoch 2648/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 65.4336 - val_loss: 80.2682\n",
      "Epoch 2649/4000\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 67.2401 - val_loss: 57.7142\n",
      "Epoch 2650/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 63.2983 - val_loss: 65.7938\n",
      "Epoch 2651/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 57.8928 - val_loss: 57.6617\n",
      "Epoch 2652/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 58.9583 - val_loss: 58.8698\n",
      "Epoch 2653/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 65.3447 - val_loss: 84.0422\n",
      "Epoch 2654/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 75.7904 - val_loss: 87.3198\n",
      "Epoch 2655/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 732.1876 - val_loss: 1245.4094\n",
      "Epoch 2656/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1027.0679 - val_loss: 1414.2900\n",
      "Epoch 2657/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1097.0634 - val_loss: 1514.8055\n",
      "Epoch 2658/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1389.2074 - val_loss: 2458.2876\n",
      "Epoch 2659/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 4261.6187 - val_loss: 2201.0339\n",
      "Epoch 2660/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2412.4028 - val_loss: 4336.2598\n",
      "Epoch 2661/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 5324.8960 - val_loss: 2413.5198\n",
      "Epoch 2662/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2254.4351 - val_loss: 3704.9175\n",
      "Epoch 2663/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3757.4824 - val_loss: 649.3446\n",
      "Epoch 2664/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1724.1550 - val_loss: 1460.7174\n",
      "Epoch 2665/4000\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 1393.6133 - val_loss: 1761.2224\n",
      "Epoch 2666/4000\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 1214.2075 - val_loss: 538.3564\n",
      "Epoch 2667/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 473.0760 - val_loss: 252.6653\n",
      "Epoch 2668/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 270.2668 - val_loss: 130.9005\n",
      "Epoch 2669/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 367.6792 - val_loss: 374.6382\n",
      "Epoch 2670/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 292.7660 - val_loss: 188.3749\n",
      "Epoch 2671/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 233.4545 - val_loss: 236.8576\n",
      "Epoch 2672/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 656.3726 - val_loss: 931.1910\n",
      "Epoch 2673/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 412.8285 - val_loss: 152.7720\n",
      "Epoch 2674/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 407.3907 - val_loss: 879.8596\n",
      "Epoch 2675/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3921.5898 - val_loss: 3004.9233\n",
      "Epoch 2676/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2291.9260 - val_loss: 2248.8037\n",
      "Epoch 2677/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3095.2480 - val_loss: 870.1226\n",
      "Epoch 2678/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1892.1725 - val_loss: 2149.9146\n",
      "Epoch 2679/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1295.2607 - val_loss: 399.7675\n",
      "Epoch 2680/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 509.6769 - val_loss: 978.2465\n",
      "Epoch 2681/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1180.7881 - val_loss: 2648.6772\n",
      "Epoch 2682/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3523.4041 - val_loss: 990.4439\n",
      "Epoch 2683/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1275.6404 - val_loss: 781.4514\n",
      "Epoch 2684/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1234.3901 - val_loss: 1559.6022\n",
      "Epoch 2685/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1567.0271 - val_loss: 2803.7854\n",
      "Epoch 2686/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3094.4036 - val_loss: 412.7501\n",
      "Epoch 2687/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1043.3833 - val_loss: 534.0721\n",
      "Epoch 2688/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 715.2184 - val_loss: 657.7621\n",
      "Epoch 2689/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1277.0962 - val_loss: 1983.7245\n",
      "Epoch 2690/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1236.7125 - val_loss: 197.9042\n",
      "Epoch 2691/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 339.8510 - val_loss: 296.5255\n",
      "Epoch 2692/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 350.9187 - val_loss: 217.8090\n",
      "Epoch 2693/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 244.6826 - val_loss: 127.4169\n",
      "Epoch 2694/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 134.1781 - val_loss: 93.2016\n",
      "Epoch 2695/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 108.0429 - val_loss: 83.3180\n",
      "Epoch 2696/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 309.1226 - val_loss: 886.7123\n",
      "Epoch 2697/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1106.7448 - val_loss: 2190.7080\n",
      "Epoch 2698/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2059.5437 - val_loss: 162.5683\n",
      "Epoch 2699/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 804.9161 - val_loss: 3623.6030\n",
      "Epoch 2700/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2276.8188 - val_loss: 1301.6826\n",
      "Epoch 2701/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1534.3652 - val_loss: 2935.1526\n",
      "Epoch 2702/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2424.5920 - val_loss: 4329.0283\n",
      "Epoch 2703/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2568.1372 - val_loss: 1652.0054\n",
      "Epoch 2704/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1014.1177 - val_loss: 536.1105\n",
      "Epoch 2705/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1205.6692 - val_loss: 2933.2563\n",
      "Epoch 2706/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2689.6196 - val_loss: 341.1866\n",
      "Epoch 2707/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 459.6776 - val_loss: 297.5270\n",
      "Epoch 2708/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2167.2402 - val_loss: 2569.2354\n",
      "Epoch 2709/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1406.6288 - val_loss: 482.9100\n",
      "Epoch 2710/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 721.7476 - val_loss: 1592.6298\n",
      "Epoch 2711/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1092.1417 - val_loss: 283.3212\n",
      "Epoch 2712/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 580.2062 - val_loss: 1660.6184\n",
      "Epoch 2713/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2136.9148 - val_loss: 222.7004\n",
      "Epoch 2714/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1083.0729 - val_loss: 208.8241\n",
      "Epoch 2715/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1896.4165 - val_loss: 2359.3960\n",
      "Epoch 2716/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1504.0562 - val_loss: 1142.1356\n",
      "Epoch 2717/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1076.8268 - val_loss: 1026.3087\n",
      "Epoch 2718/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1829.0615 - val_loss: 255.7845\n",
      "Epoch 2719/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 273.1903 - val_loss: 125.6987\n",
      "Epoch 2720/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 136.9531 - val_loss: 111.0026\n",
      "Epoch 2721/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 99.0346 - val_loss: 78.3427\n",
      "Epoch 2722/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 74.7629 - val_loss: 73.5373\n",
      "Epoch 2723/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 90.5109 - val_loss: 69.1684\n",
      "Epoch 2724/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 84.3045 - val_loss: 65.1952\n",
      "Epoch 2725/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 58.6378 - val_loss: 63.8820\n",
      "Epoch 2726/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 66.9814 - val_loss: 66.9030\n",
      "Epoch 2727/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 57.7013 - val_loss: 61.3257\n",
      "Epoch 2728/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 62.2734 - val_loss: 78.9749\n",
      "Epoch 2729/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 60.6333 - val_loss: 64.6779\n",
      "Epoch 2730/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 68.1894 - val_loss: 119.6224\n",
      "Epoch 2731/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 530.6868 - val_loss: 1048.6823\n",
      "Epoch 2732/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 881.2139 - val_loss: 1047.6390\n",
      "Epoch 2733/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 750.8356 - val_loss: 704.3631\n",
      "Epoch 2734/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 879.5156 - val_loss: 1160.8158\n",
      "Epoch 2735/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 607.5712 - val_loss: 145.2648\n",
      "Epoch 2736/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 266.7120 - val_loss: 209.4974\n",
      "Epoch 2737/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 250.6232 - val_loss: 146.2153\n",
      "Epoch 2738/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 143.2148 - val_loss: 72.5601\n",
      "Epoch 2739/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 83.6350 - val_loss: 116.1949\n",
      "Epoch 2740/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 88.9961 - val_loss: 57.7588\n",
      "Epoch 2741/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 62.5153 - val_loss: 66.6367\n",
      "Epoch 2742/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 59.9657 - val_loss: 80.4318\n",
      "Epoch 2743/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 56.5119 - val_loss: 58.2377\n",
      "Epoch 2744/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 54.7054 - val_loss: 60.7434\n",
      "Epoch 2745/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 60.7151 - val_loss: 61.7336\n",
      "Epoch 2746/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 73.8041 - val_loss: 108.1729\n",
      "Epoch 2747/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 113.5994 - val_loss: 66.7331\n",
      "Epoch 2748/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 68.0713 - val_loss: 57.4755\n",
      "Epoch 2749/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 56.9295 - val_loss: 64.8280\n",
      "Epoch 2750/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 62.3255 - val_loss: 61.9508\n",
      "Epoch 2751/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 57.5462 - val_loss: 60.5561\n",
      "Epoch 2752/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 55.7837 - val_loss: 55.1843\n",
      "Epoch 2753/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 54.8891 - val_loss: 67.5947\n",
      "Epoch 2754/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 54.4787 - val_loss: 57.2426\n",
      "Epoch 2755/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 55.9664 - val_loss: 56.8846\n",
      "Epoch 2756/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 55.0329 - val_loss: 54.6142\n",
      "Epoch 2757/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 61.7647 - val_loss: 96.3699\n",
      "Epoch 2758/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1323.6404 - val_loss: 2717.5176\n",
      "Epoch 2759/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1698.9923 - val_loss: 94.5111\n",
      "Epoch 2760/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 278.5099 - val_loss: 269.0595\n",
      "Epoch 2761/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1159.9192 - val_loss: 2273.1377\n",
      "Epoch 2762/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1699.3251 - val_loss: 1033.3427\n",
      "Epoch 2763/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1233.8419 - val_loss: 815.4245\n",
      "Epoch 2764/4000\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 1499.5798 - val_loss: 149.9202\n",
      "Epoch 2765/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 201.6930 - val_loss: 235.3266\n",
      "Epoch 2766/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 308.0356 - val_loss: 290.8338\n",
      "Epoch 2767/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 42ms/step - loss: 1077.6929 - val_loss: 2536.2578\n",
      "Epoch 2768/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2186.4124 - val_loss: 1610.3699\n",
      "Epoch 2769/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 3971.7456 - val_loss: 2354.1108\n",
      "Epoch 2770/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1502.7980 - val_loss: 828.6887\n",
      "Epoch 2771/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1144.2941 - val_loss: 2327.1748\n",
      "Epoch 2772/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1934.9873 - val_loss: 1111.5522\n",
      "Epoch 2773/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2597.9712 - val_loss: 1059.8790\n",
      "Epoch 2774/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1713.5228 - val_loss: 1598.3788\n",
      "Epoch 2775/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1029.7925 - val_loss: 732.3274\n",
      "Epoch 2776/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1184.5951 - val_loss: 2524.0933\n",
      "Epoch 2777/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2072.9851 - val_loss: 175.7005\n",
      "Epoch 2778/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 326.6215 - val_loss: 250.5217\n",
      "Epoch 2779/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 367.1494 - val_loss: 217.8753\n",
      "Epoch 2780/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 295.5540 - val_loss: 327.7565\n",
      "Epoch 2781/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1062.8845 - val_loss: 2120.4614\n",
      "Epoch 2782/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1228.5161 - val_loss: 212.3943\n",
      "Epoch 2783/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 267.0759 - val_loss: 122.3210\n",
      "Epoch 2784/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 160.2900 - val_loss: 82.6750\n",
      "Epoch 2785/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 136.2886 - val_loss: 98.8493\n",
      "Epoch 2786/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 322.4591 - val_loss: 853.1160\n",
      "Epoch 2787/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 828.7490 - val_loss: 1423.1400\n",
      "Epoch 2788/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1267.8197 - val_loss: 1215.7361\n",
      "Epoch 2789/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1574.3821 - val_loss: 303.3465\n",
      "Epoch 2790/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1812.2516 - val_loss: 675.3517\n",
      "Epoch 2791/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 447.2067 - val_loss: 253.0002\n",
      "Epoch 2792/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 404.1167 - val_loss: 307.6257\n",
      "Epoch 2793/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 360.1466 - val_loss: 207.7741\n",
      "Epoch 2794/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 224.4207 - val_loss: 94.9944\n",
      "Epoch 2795/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 93.5673 - val_loss: 72.3364\n",
      "Epoch 2796/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 70.9503 - val_loss: 59.2561\n",
      "Epoch 2797/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 58.5780 - val_loss: 55.2541\n",
      "Epoch 2798/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 72.2883 - val_loss: 88.4401\n",
      "Epoch 2799/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 192.6410 - val_loss: 290.5823\n",
      "Epoch 2800/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 900.1574 - val_loss: 1957.6344\n",
      "Epoch 2801/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1650.8925 - val_loss: 2782.8779\n",
      "Epoch 2802/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 5338.7324 - val_loss: 3215.5845\n",
      "Epoch 2803/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2847.8818 - val_loss: 4868.8057\n",
      "Epoch 2804/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 7332.0713 - val_loss: 4761.2622\n",
      "Epoch 2805/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 3121.3459 - val_loss: 2419.6448\n",
      "Epoch 2806/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 5950.6543 - val_loss: 5171.4893\n",
      "Epoch 2807/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3568.4749 - val_loss: 981.5796\n",
      "Epoch 2808/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1342.3995 - val_loss: 2074.9473\n",
      "Epoch 2809/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1001.2834 - val_loss: 684.5247\n",
      "Epoch 2810/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1277.8182 - val_loss: 374.9313\n",
      "Epoch 2811/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 1471.0581 - val_loss: 1422.5171\n",
      "Epoch 2812/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1281.1676 - val_loss: 1022.0392\n",
      "Epoch 2813/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1467.1281 - val_loss: 1910.1633\n",
      "Epoch 2814/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1719.1698 - val_loss: 2070.8970\n",
      "Epoch 2815/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2205.1404 - val_loss: 363.3650\n",
      "Epoch 2816/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2614.9563 - val_loss: 2918.8052\n",
      "Epoch 2817/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1631.4978 - val_loss: 329.1834\n",
      "Epoch 2818/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 611.4400 - val_loss: 1176.1737\n",
      "Epoch 2819/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1037.7339 - val_loss: 935.0944\n",
      "Epoch 2820/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1014.2875 - val_loss: 1007.0719\n",
      "Epoch 2821/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1960.9340 - val_loss: 496.0906\n",
      "Epoch 2822/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 483.9790 - val_loss: 318.8050\n",
      "Epoch 2823/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 530.7003 - val_loss: 452.3720\n",
      "Epoch 2824/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2156.6365 - val_loss: 3540.9966\n",
      "Epoch 2825/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2879.7854 - val_loss: 140.9531\n",
      "Epoch 2826/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 898.8237 - val_loss: 472.1045\n",
      "Epoch 2827/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 209.5497 - val_loss: 153.5410\n",
      "Epoch 2828/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 167.9793 - val_loss: 102.4369\n",
      "Epoch 2829/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 135.8306 - val_loss: 249.5071\n",
      "Epoch 2830/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 348.7688 - val_loss: 478.4459\n",
      "Epoch 2831/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 817.9582 - val_loss: 533.2218\n",
      "Epoch 2832/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2868.7063 - val_loss: 2047.3036\n",
      "Epoch 2833/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1451.8013 - val_loss: 1127.4296\n",
      "Epoch 2834/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1128.9557 - val_loss: 2160.6670\n",
      "Epoch 2835/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2504.4250 - val_loss: 346.5746\n",
      "Epoch 2836/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1186.5897 - val_loss: 1011.0735\n",
      "Epoch 2837/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 901.3464 - val_loss: 743.6873\n",
      "Epoch 2838/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1254.0994 - val_loss: 1820.9652\n",
      "Epoch 2839/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1244.0989 - val_loss: 1587.9916\n",
      "Epoch 2840/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1604.1710 - val_loss: 1491.8226\n",
      "Epoch 2841/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1911.7621 - val_loss: 1078.5228\n",
      "Epoch 2842/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1428.8688 - val_loss: 1685.4449\n",
      "Epoch 2843/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1126.6686 - val_loss: 677.4691\n",
      "Epoch 2844/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 568.9747 - val_loss: 677.7315\n",
      "Epoch 2845/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1008.9044 - val_loss: 2882.2119\n",
      "Epoch 2846/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 4051.3025 - val_loss: 1717.6924\n",
      "Epoch 2847/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 787.1042 - val_loss: 307.2871\n",
      "Epoch 2848/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 209.3232 - val_loss: 150.2362\n",
      "Epoch 2849/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 119.1739 - val_loss: 73.5207\n",
      "Epoch 2850/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 72.0038 - val_loss: 62.6671\n",
      "Epoch 2851/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 62.5473 - val_loss: 70.6070\n",
      "Epoch 2852/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 62.2204 - val_loss: 79.6553\n",
      "Epoch 2853/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 59.8914 - val_loss: 62.0469\n",
      "Epoch 2854/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 68.9163 - val_loss: 75.3288\n",
      "Epoch 2855/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 316.1204 - val_loss: 739.3859\n",
      "Epoch 2856/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 732.7211 - val_loss: 921.4318\n",
      "Epoch 2857/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1019.5475 - val_loss: 1702.8324\n",
      "Epoch 2858/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1421.3964 - val_loss: 1498.4786\n",
      "Epoch 2859/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 2127.7686 - val_loss: 134.6451\n",
      "Epoch 2860/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 483.8849 - val_loss: 117.3159\n",
      "Epoch 2861/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 287.5148 - val_loss: 275.1863\n",
      "Epoch 2862/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 661.7454 - val_loss: 1548.6593\n",
      "Epoch 2863/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1163.6821 - val_loss: 980.1600\n",
      "Epoch 2864/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1145.1506 - val_loss: 592.5752\n",
      "Epoch 2865/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 982.5719 - val_loss: 197.9907\n",
      "Epoch 2866/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 447.6610 - val_loss: 508.9224\n",
      "Epoch 2867/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2419.0762 - val_loss: 1411.7856\n",
      "Epoch 2868/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 639.7200 - val_loss: 209.8777\n",
      "Epoch 2869/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 360.4687 - val_loss: 268.3671\n",
      "Epoch 2870/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 337.7649 - val_loss: 187.0719\n",
      "Epoch 2871/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 212.4067 - val_loss: 103.8039\n",
      "Epoch 2872/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 109.2914 - val_loss: 72.8324\n",
      "Epoch 2873/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 76.7933 - val_loss: 82.4703\n",
      "Epoch 2874/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 108.4428 - val_loss: 56.5044\n",
      "Epoch 2875/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 260.1799 - val_loss: 939.1501\n",
      "Epoch 2876/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1659.8627 - val_loss: 318.2590\n",
      "Epoch 2877/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 822.1647 - val_loss: 591.0893\n",
      "Epoch 2878/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 677.4960 - val_loss: 168.9987\n",
      "Epoch 2879/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 318.5982 - val_loss: 143.8575\n",
      "Epoch 2880/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 140.0708 - val_loss: 112.7948\n",
      "Epoch 2881/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 116.6443 - val_loss: 102.1216\n",
      "Epoch 2882/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 73.0572 - val_loss: 59.4251\n",
      "Epoch 2883/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 62.6505 - val_loss: 60.8726\n",
      "Epoch 2884/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 59.3828 - val_loss: 54.2035\n",
      "Epoch 2885/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 58.8478 - val_loss: 60.1196\n",
      "Epoch 2886/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 53.6202 - val_loss: 55.5687\n",
      "Epoch 2887/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 57.0017 - val_loss: 54.4456\n",
      "Epoch 2888/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 184.2458 - val_loss: 367.2099\n",
      "Epoch 2889/4000\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 1024.3325 - val_loss: 1338.3864\n",
      "Epoch 2890/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1599.1766 - val_loss: 3427.5774\n",
      "Epoch 2891/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 3900.6414 - val_loss: 1065.1346\n",
      "Epoch 2892/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 779.8300 - val_loss: 1578.8590\n",
      "Epoch 2893/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1446.8877 - val_loss: 372.2027\n",
      "Epoch 2894/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1031.2893 - val_loss: 518.5798\n",
      "Epoch 2895/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1623.8514 - val_loss: 2589.9485\n",
      "Epoch 2896/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1876.1477 - val_loss: 877.7600\n",
      "Epoch 2897/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2256.0278 - val_loss: 650.2946\n",
      "Epoch 2898/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 865.7712 - val_loss: 218.8858\n",
      "Epoch 2899/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 573.5185 - val_loss: 700.3978\n",
      "Epoch 2900/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3430.3013 - val_loss: 2764.9148\n",
      "Epoch 2901/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1394.5615 - val_loss: 297.3094\n",
      "Epoch 2902/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 510.4064 - val_loss: 555.5085\n",
      "Epoch 2903/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 441.0041 - val_loss: 255.9482\n",
      "Epoch 2904/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 597.3591 - val_loss: 1473.1456\n",
      "Epoch 2905/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1360.5491 - val_loss: 140.2946\n",
      "Epoch 2906/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 605.4230 - val_loss: 80.1628\n",
      "Epoch 2907/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 169.5504 - val_loss: 161.5986\n",
      "Epoch 2908/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 237.8919 - val_loss: 133.4537\n",
      "Epoch 2909/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 158.9958 - val_loss: 75.6605\n",
      "Epoch 2910/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 107.2183 - val_loss: 74.6390\n",
      "Epoch 2911/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 105.1028 - val_loss: 96.5428\n",
      "Epoch 2912/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 92.2387 - val_loss: 114.2423\n",
      "Epoch 2913/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 523.5236 - val_loss: 1946.5518\n",
      "Epoch 2914/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2002.7072 - val_loss: 180.8276\n",
      "Epoch 2915/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 491.4412 - val_loss: 804.9775\n",
      "Epoch 2916/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1409.1344 - val_loss: 350.2623\n",
      "Epoch 2917/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1386.7675 - val_loss: 165.8263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2918/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1065.6083 - val_loss: 398.0258\n",
      "Epoch 2919/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 683.1791 - val_loss: 296.5062\n",
      "Epoch 2920/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 299.5486 - val_loss: 379.7095\n",
      "Epoch 2921/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 439.4949 - val_loss: 261.5923\n",
      "Epoch 2922/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1036.1608 - val_loss: 1232.3435\n",
      "Epoch 2923/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2822.1233 - val_loss: 2657.8367\n",
      "Epoch 2924/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1727.3083 - val_loss: 1920.5492\n",
      "Epoch 2925/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2040.1489 - val_loss: 3833.9016\n",
      "Epoch 2926/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1796.8844 - val_loss: 740.7796\n",
      "Epoch 2927/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 941.0269 - val_loss: 627.7451\n",
      "Epoch 2928/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 865.5557 - val_loss: 1096.3572\n",
      "Epoch 2929/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 985.9850 - val_loss: 2291.7039\n",
      "Epoch 2930/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2210.5381 - val_loss: 1232.4208\n",
      "Epoch 2931/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2089.5002 - val_loss: 1897.4393\n",
      "Epoch 2932/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1845.5804 - val_loss: 1991.4607\n",
      "Epoch 2933/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1652.3898 - val_loss: 1116.5173\n",
      "Epoch 2934/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1273.8239 - val_loss: 485.6154\n",
      "Epoch 2935/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 775.8502 - val_loss: 1862.5609\n",
      "Epoch 2936/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2822.5918 - val_loss: 906.0673\n",
      "Epoch 2937/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2034.4539 - val_loss: 2988.6865\n",
      "Epoch 2938/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2223.0300 - val_loss: 182.0716\n",
      "Epoch 2939/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 782.4948 - val_loss: 2009.6754\n",
      "Epoch 2940/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2365.5120 - val_loss: 1787.2081\n",
      "Epoch 2941/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1457.2931 - val_loss: 2402.5051\n",
      "Epoch 2942/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2583.7468 - val_loss: 268.2625\n",
      "Epoch 2943/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1542.4550 - val_loss: 1095.8696\n",
      "Epoch 2944/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1233.4877 - val_loss: 2303.3457\n",
      "Epoch 2945/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1792.4440 - val_loss: 440.2632\n",
      "Epoch 2946/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 542.1647 - val_loss: 438.2870\n",
      "Epoch 2947/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 307.5468 - val_loss: 134.0766\n",
      "Epoch 2948/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 228.6787 - val_loss: 403.4499\n",
      "Epoch 2949/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 898.1223 - val_loss: 2061.1775\n",
      "Epoch 2950/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1645.7020 - val_loss: 357.8851\n",
      "Epoch 2951/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2172.9109 - val_loss: 1175.4659\n",
      "Epoch 2952/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1343.6335 - val_loss: 867.2763\n",
      "Epoch 2953/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1543.8790 - val_loss: 2103.1243\n",
      "Epoch 2954/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1476.2792 - val_loss: 693.8301\n",
      "Epoch 2955/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 771.8685 - val_loss: 537.0205\n",
      "Epoch 2956/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 941.5502 - val_loss: 929.6550\n",
      "Epoch 2957/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2318.7939 - val_loss: 1989.7892\n",
      "Epoch 2958/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1091.2017 - val_loss: 821.5084\n",
      "Epoch 2959/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 963.2192 - val_loss: 2544.8367\n",
      "Epoch 2960/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3592.6948 - val_loss: 1483.8306\n",
      "Epoch 2961/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1079.5587 - val_loss: 778.7964\n",
      "Epoch 2962/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 621.5314 - val_loss: 756.0078\n",
      "Epoch 2963/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 710.1039 - val_loss: 1371.7498\n",
      "Epoch 2964/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1185.0852 - val_loss: 608.7199\n",
      "Epoch 2965/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1290.5658 - val_loss: 167.9392\n",
      "Epoch 2966/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1746.6782 - val_loss: 1400.1372\n",
      "Epoch 2967/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1166.0175 - val_loss: 1139.6841\n",
      "Epoch 2968/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 707.8202 - val_loss: 254.9417\n",
      "Epoch 2969/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 230.7643 - val_loss: 153.1823\n",
      "Epoch 2970/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 138.1924 - val_loss: 171.3044\n",
      "Epoch 2971/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 90.7244 - val_loss: 67.2794\n",
      "Epoch 2972/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 68.1701 - val_loss: 67.2976\n",
      "Epoch 2973/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 79.0298 - val_loss: 67.4167\n",
      "Epoch 2974/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 67.1127 - val_loss: 93.9369\n",
      "Epoch 2975/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 73.2439 - val_loss: 71.2829\n",
      "Epoch 2976/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 65.6382 - val_loss: 71.7545\n",
      "Epoch 2977/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 71.6987 - val_loss: 172.5640\n",
      "Epoch 2978/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 338.2802 - val_loss: 1210.2036\n",
      "Epoch 2979/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1136.0610 - val_loss: 816.4535\n",
      "Epoch 2980/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 1367.8781 - val_loss: 149.8448\n",
      "Epoch 2981/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2123.0295 - val_loss: 1860.3270\n",
      "Epoch 2982/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1528.7660 - val_loss: 2213.2229\n",
      "Epoch 2983/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2056.2183 - val_loss: 340.5391\n",
      "Epoch 2984/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 926.0292 - val_loss: 303.8812\n",
      "Epoch 2985/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1691.6102 - val_loss: 1593.1923\n",
      "Epoch 2986/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1080.7095 - val_loss: 1550.2965\n",
      "Epoch 2987/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1270.9832 - val_loss: 288.0544\n",
      "Epoch 2988/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 565.6714 - val_loss: 140.7959\n",
      "Epoch 2989/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 163.2510 - val_loss: 95.2197\n",
      "Epoch 2990/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 90.0956 - val_loss: 82.1195\n",
      "Epoch 2991/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 77.2775 - val_loss: 72.8123\n",
      "Epoch 2992/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 70.2762 - val_loss: 65.8170\n",
      "Epoch 2993/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 64.3000 - val_loss: 74.1788\n",
      "Epoch 2994/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 65.7277 - val_loss: 73.9072\n",
      "Epoch 2995/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 69.9094 - val_loss: 64.9866\n",
      "Epoch 2996/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 64.0168 - val_loss: 64.6623\n",
      "Epoch 2997/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 64.5380 - val_loss: 62.3069\n",
      "Epoch 2998/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 64.3437 - val_loss: 63.9049\n",
      "Epoch 2999/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 72.1932 - val_loss: 63.3373\n",
      "Epoch 3000/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 62.0440 - val_loss: 79.0454\n",
      "Epoch 3001/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 74.7498 - val_loss: 67.6693\n",
      "Epoch 3002/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 66.1643 - val_loss: 62.5970\n",
      "Epoch 3003/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 64.1844 - val_loss: 61.9162\n",
      "Epoch 3004/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 58.6280 - val_loss: 58.8854\n",
      "Epoch 3005/4000\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 75.3202 - val_loss: 64.2571\n",
      "Epoch 3006/4000\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 80.1562 - val_loss: 75.0261\n",
      "Epoch 3007/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 76.0820 - val_loss: 404.1701\n",
      "Epoch 3008/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 2182.9246 - val_loss: 1434.7570\n",
      "Epoch 3009/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1115.8988 - val_loss: 1486.3967\n",
      "Epoch 3010/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 835.0499 - val_loss: 199.9704\n",
      "Epoch 3011/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 608.1012 - val_loss: 130.6840\n",
      "Epoch 3012/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1114.6791 - val_loss: 467.3663\n",
      "Epoch 3013/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1974.6780 - val_loss: 3121.6199\n",
      "Epoch 3014/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 2217.5752 - val_loss: 843.7432\n",
      "Epoch 3015/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1582.1428 - val_loss: 234.8377\n",
      "Epoch 3016/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 896.5685 - val_loss: 151.3530\n",
      "Epoch 3017/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 268.2551 - val_loss: 110.1987\n",
      "Epoch 3018/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 151.1383 - val_loss: 110.9037\n",
      "Epoch 3019/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 99.5955 - val_loss: 174.2864\n",
      "Epoch 3020/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 338.3493 - val_loss: 1245.0018\n",
      "Epoch 3021/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1372.9526 - val_loss: 136.6297\n",
      "Epoch 3022/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 141.1733 - val_loss: 119.5395\n",
      "Epoch 3023/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 160.3108 - val_loss: 110.5041\n",
      "Epoch 3024/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 110.1632 - val_loss: 63.0214\n",
      "Epoch 3025/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 74.6068 - val_loss: 73.2010\n",
      "Epoch 3026/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 63.8422 - val_loss: 55.2953\n",
      "Epoch 3027/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 62.4372 - val_loss: 56.5645\n",
      "Epoch 3028/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 62.2227 - val_loss: 60.4840\n",
      "Epoch 3029/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 62.4545 - val_loss: 61.4104\n",
      "Epoch 3030/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 71.3689 - val_loss: 54.6798\n",
      "Epoch 3031/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 233.0966 - val_loss: 265.2361\n",
      "Epoch 3032/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1534.5408 - val_loss: 2445.5291\n",
      "Epoch 3033/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1756.1434 - val_loss: 1945.0649\n",
      "Epoch 3034/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3176.7910 - val_loss: 1031.7114\n",
      "Epoch 3035/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1982.6821 - val_loss: 2036.9202\n",
      "Epoch 3036/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1512.7532 - val_loss: 1300.1547\n",
      "Epoch 3037/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1246.0111 - val_loss: 1346.6984\n",
      "Epoch 3038/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3097.0430 - val_loss: 1641.0693\n",
      "Epoch 3039/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1514.2100 - val_loss: 2040.6930\n",
      "Epoch 3040/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1724.1233 - val_loss: 617.6705\n",
      "Epoch 3041/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1242.8535 - val_loss: 2608.8809\n",
      "Epoch 3042/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 594.7455 - val_loss: 838.3873\n",
      "Epoch 3043/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2119.7002 - val_loss: 1459.1002\n",
      "Epoch 3044/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 673.6650 - val_loss: 210.5507\n",
      "Epoch 3045/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 368.6948 - val_loss: 332.1267\n",
      "Epoch 3046/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 408.5036 - val_loss: 200.3266\n",
      "Epoch 3047/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 335.6833 - val_loss: 788.7037\n",
      "Epoch 3048/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1088.9269 - val_loss: 4004.4731\n",
      "Epoch 3049/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 993.7256 - val_loss: 150.4053\n",
      "Epoch 3050/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 859.5878 - val_loss: 237.1760\n",
      "Epoch 3051/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1364.3785 - val_loss: 1099.8141\n",
      "Epoch 3052/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 927.3314 - val_loss: 1011.7926\n",
      "Epoch 3053/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 518.1114 - val_loss: 134.8663\n",
      "Epoch 3054/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 237.4190 - val_loss: 172.4380\n",
      "Epoch 3055/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 224.4538 - val_loss: 129.8324\n",
      "Epoch 3056/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 126.6557 - val_loss: 64.2490\n",
      "Epoch 3057/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 72.5180 - val_loss: 81.9729\n",
      "Epoch 3058/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 73.6224 - val_loss: 60.3417\n",
      "Epoch 3059/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 63.5620 - val_loss: 57.9444\n",
      "Epoch 3060/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 62.6281 - val_loss: 70.8658\n",
      "Epoch 3061/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 103.0154 - val_loss: 61.2624\n",
      "Epoch 3062/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 75.6295 - val_loss: 69.1810\n",
      "Epoch 3063/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 84.9274 - val_loss: 91.8009\n",
      "Epoch 3064/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 71.2977 - val_loss: 86.1995\n",
      "Epoch 3065/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 74.3410 - val_loss: 56.9930\n",
      "Epoch 3066/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 64.9214 - val_loss: 65.8953\n",
      "Epoch 3067/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 67.9187 - val_loss: 58.9575\n",
      "Epoch 3068/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 63.7757 - val_loss: 96.7637\n",
      "Epoch 3069/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 40ms/step - loss: 66.4583 - val_loss: 56.7366\n",
      "Epoch 3070/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 62.9614 - val_loss: 60.8153\n",
      "Epoch 3071/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 64.0997 - val_loss: 60.1425\n",
      "Epoch 3072/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 63.9725 - val_loss: 56.7794\n",
      "Epoch 3073/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 64.2072 - val_loss: 59.6005\n",
      "Epoch 3074/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 64.6751 - val_loss: 69.4224\n",
      "Epoch 3075/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 76.0208 - val_loss: 90.3410\n",
      "Epoch 3076/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 73.0252 - val_loss: 95.3080\n",
      "Epoch 3077/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 82.2583 - val_loss: 59.0374\n",
      "Epoch 3078/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 98.7829 - val_loss: 305.9043\n",
      "Epoch 3079/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 924.4355 - val_loss: 3029.1387\n",
      "Epoch 3080/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2940.9438 - val_loss: 1585.2820\n",
      "Epoch 3081/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 489.0237 - val_loss: 340.5264\n",
      "Epoch 3082/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 549.1351 - val_loss: 505.4771\n",
      "Epoch 3083/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 552.0510 - val_loss: 287.8023\n",
      "Epoch 3084/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 337.8714 - val_loss: 151.0311\n",
      "Epoch 3085/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 164.8983 - val_loss: 90.0571\n",
      "Epoch 3086/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 107.2224 - val_loss: 83.1224\n",
      "Epoch 3087/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 83.9104 - val_loss: 61.6672\n",
      "Epoch 3088/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 77.7919 - val_loss: 57.1155\n",
      "Epoch 3089/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 73.1058 - val_loss: 64.1881\n",
      "Epoch 3090/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 81.8338 - val_loss: 137.8205\n",
      "Epoch 3091/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 84.3566 - val_loss: 73.3990\n",
      "Epoch 3092/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 78.9368 - val_loss: 62.1811\n",
      "Epoch 3093/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 153.6194 - val_loss: 790.6946\n",
      "Epoch 3094/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1088.8629 - val_loss: 1447.3455\n",
      "Epoch 3095/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3155.8494 - val_loss: 1149.2921\n",
      "Epoch 3096/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1449.9165 - val_loss: 1062.5939\n",
      "Epoch 3097/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1498.2499 - val_loss: 2224.4482\n",
      "Epoch 3098/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1598.9614 - val_loss: 1475.7922\n",
      "Epoch 3099/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1969.8688 - val_loss: 3716.9919\n",
      "Epoch 3100/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1215.5148 - val_loss: 1137.8658\n",
      "Epoch 3101/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1812.9514 - val_loss: 585.5737\n",
      "Epoch 3102/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1499.6932 - val_loss: 1384.6614\n",
      "Epoch 3103/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 701.8788 - val_loss: 241.3161\n",
      "Epoch 3104/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 226.4841 - val_loss: 263.7758\n",
      "Epoch 3105/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 136.9694 - val_loss: 125.9698\n",
      "Epoch 3106/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 113.4329 - val_loss: 84.1370\n",
      "Epoch 3107/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 84.9407 - val_loss: 66.0458\n",
      "Epoch 3108/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 112.8306 - val_loss: 152.1919\n",
      "Epoch 3109/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 150.7998 - val_loss: 141.1503\n",
      "Epoch 3110/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 445.9531 - val_loss: 1300.2607\n",
      "Epoch 3111/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1569.1364 - val_loss: 631.6768\n",
      "Epoch 3112/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1135.0095 - val_loss: 1218.2650\n",
      "Epoch 3113/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1218.9839 - val_loss: 1183.3893\n",
      "Epoch 3114/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1144.3802 - val_loss: 1473.0228\n",
      "Epoch 3115/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 1061.3397 - val_loss: 1419.1765\n",
      "Epoch 3116/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1173.2117 - val_loss: 118.1998\n",
      "Epoch 3117/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 288.0614 - val_loss: 289.1031\n",
      "Epoch 3118/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 351.6993 - val_loss: 216.1385\n",
      "Epoch 3119/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 247.1615 - val_loss: 125.9632\n",
      "Epoch 3120/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 118.0217 - val_loss: 65.6413\n",
      "Epoch 3121/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 69.0094 - val_loss: 88.7172\n",
      "Epoch 3122/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 477.3992 - val_loss: 846.2874\n",
      "Epoch 3123/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1214.4924 - val_loss: 1919.9142\n",
      "Epoch 3124/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1597.8386 - val_loss: 2247.0095\n",
      "Epoch 3125/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2117.1670 - val_loss: 329.2085\n",
      "Epoch 3126/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2068.3635 - val_loss: 884.4799\n",
      "Epoch 3127/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 957.3386 - val_loss: 675.2167\n",
      "Epoch 3128/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1417.3730 - val_loss: 2183.7952\n",
      "Epoch 3129/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1486.1714 - val_loss: 1464.1573\n",
      "Epoch 3130/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1380.4186 - val_loss: 281.1653\n",
      "Epoch 3131/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 768.9903 - val_loss: 2111.8792\n",
      "Epoch 3132/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2245.2051 - val_loss: 578.4083\n",
      "Epoch 3133/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2931.9448 - val_loss: 3199.9663\n",
      "Epoch 3134/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1908.8959 - val_loss: 866.2449\n",
      "Epoch 3135/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1015.4422 - val_loss: 1674.8820\n",
      "Epoch 3136/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1760.4386 - val_loss: 186.7670\n",
      "Epoch 3137/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 994.9200 - val_loss: 227.7145\n",
      "Epoch 3138/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2508.1013 - val_loss: 2930.7686\n",
      "Epoch 3139/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1782.3196 - val_loss: 1253.6265\n",
      "Epoch 3140/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 1715.4833 - val_loss: 2597.5308\n",
      "Epoch 3141/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1007.4674 - val_loss: 2522.4668\n",
      "Epoch 3142/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2254.1838 - val_loss: 1475.9935\n",
      "Epoch 3143/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1434.5831 - val_loss: 1712.4312\n",
      "Epoch 3144/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1155.2245 - val_loss: 361.9398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3145/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 401.5963 - val_loss: 210.2654\n",
      "Epoch 3146/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 190.8686 - val_loss: 113.9320\n",
      "Epoch 3147/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 111.0055 - val_loss: 133.2250\n",
      "Epoch 3148/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 286.3698 - val_loss: 101.1993\n",
      "Epoch 3149/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 162.3236 - val_loss: 127.4891\n",
      "Epoch 3150/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 154.3958 - val_loss: 91.9623\n",
      "Epoch 3151/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 92.8795 - val_loss: 63.9344\n",
      "Epoch 3152/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 74.4552 - val_loss: 102.3795\n",
      "Epoch 3153/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 789.2887 - val_loss: 1875.4283\n",
      "Epoch 3154/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1395.9982 - val_loss: 1064.2126\n",
      "Epoch 3155/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1321.3248 - val_loss: 332.2399\n",
      "Epoch 3156/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1466.0994 - val_loss: 181.7299\n",
      "Epoch 3157/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 175.1128 - val_loss: 92.7521\n",
      "Epoch 3158/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 119.3529 - val_loss: 119.9542\n",
      "Epoch 3159/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 165.1861 - val_loss: 200.2254\n",
      "Epoch 3160/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 387.5481 - val_loss: 1000.1651\n",
      "Epoch 3161/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2056.4910 - val_loss: 300.3109\n",
      "Epoch 3162/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1254.5808 - val_loss: 338.7442\n",
      "Epoch 3163/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 718.5846 - val_loss: 115.5210\n",
      "Epoch 3164/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1514.6648 - val_loss: 1353.2075\n",
      "Epoch 3165/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 997.6899 - val_loss: 1062.0787\n",
      "Epoch 3166/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1294.1160 - val_loss: 1578.4275\n",
      "Epoch 3167/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1225.9001 - val_loss: 1133.6758\n",
      "Epoch 3168/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 776.8055 - val_loss: 224.5996\n",
      "Epoch 3169/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 212.6948 - val_loss: 104.1776\n",
      "Epoch 3170/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 111.3732 - val_loss: 89.0837\n",
      "Epoch 3171/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 86.6002 - val_loss: 66.5110\n",
      "Epoch 3172/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 77.4464 - val_loss: 82.0609\n",
      "Epoch 3173/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 85.3388 - val_loss: 69.6309\n",
      "Epoch 3174/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 64.8911 - val_loss: 65.7762\n",
      "Epoch 3175/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 89.0731 - val_loss: 124.8839\n",
      "Epoch 3176/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 83.4060 - val_loss: 67.8334\n",
      "Epoch 3177/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 69.0221 - val_loss: 64.7559\n",
      "Epoch 3178/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 65.4247 - val_loss: 60.5585\n",
      "Epoch 3179/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 83.1971 - val_loss: 107.1152\n",
      "Epoch 3180/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 89.6066 - val_loss: 77.4397\n",
      "Epoch 3181/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 64.5376 - val_loss: 62.8405\n",
      "Epoch 3182/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 80.6190 - val_loss: 69.3713\n",
      "Epoch 3183/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 226.5132 - val_loss: 359.3367\n",
      "Epoch 3184/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1856.9519 - val_loss: 3995.2856\n",
      "Epoch 3185/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3322.8770 - val_loss: 1394.5444\n",
      "Epoch 3186/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3087.4460 - val_loss: 2863.0171\n",
      "Epoch 3187/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1901.7545 - val_loss: 1042.5797\n",
      "Epoch 3188/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1106.9193 - val_loss: 947.3356\n",
      "Epoch 3189/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1087.7596 - val_loss: 290.1411\n",
      "Epoch 3190/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 560.7476 - val_loss: 1541.8545\n",
      "Epoch 3191/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2065.2795 - val_loss: 494.9864\n",
      "Epoch 3192/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1075.2605 - val_loss: 563.6964\n",
      "Epoch 3193/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1605.5953 - val_loss: 1886.8048\n",
      "Epoch 3194/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1108.6852 - val_loss: 836.0932\n",
      "Epoch 3195/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1222.6841 - val_loss: 2790.5161\n",
      "Epoch 3196/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3063.8420 - val_loss: 475.9800\n",
      "Epoch 3197/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2313.6504 - val_loss: 2432.8032\n",
      "Epoch 3198/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1730.2335 - val_loss: 1972.5974\n",
      "Epoch 3199/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2972.6206 - val_loss: 912.6525\n",
      "Epoch 3200/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 729.5590 - val_loss: 343.5312\n",
      "Epoch 3201/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1003.9372 - val_loss: 1297.4326\n",
      "Epoch 3202/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1399.4408 - val_loss: 2748.1611\n",
      "Epoch 3203/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2957.7002 - val_loss: 285.4631\n",
      "Epoch 3204/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 950.8464 - val_loss: 353.9348\n",
      "Epoch 3205/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 385.5633 - val_loss: 260.4214\n",
      "Epoch 3206/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 229.2146 - val_loss: 130.9546\n",
      "Epoch 3207/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 147.3795 - val_loss: 94.4022\n",
      "Epoch 3208/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 80.2834 - val_loss: 75.6313\n",
      "Epoch 3209/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 72.1398 - val_loss: 67.9447\n",
      "Epoch 3210/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 66.8478 - val_loss: 67.4701\n",
      "Epoch 3211/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 110.9924 - val_loss: 68.2415\n",
      "Epoch 3212/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 90.3217 - val_loss: 73.0283\n",
      "Epoch 3213/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 115.2329 - val_loss: 72.8555\n",
      "Epoch 3214/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 847.6281 - val_loss: 505.8835\n",
      "Epoch 3215/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2083.2180 - val_loss: 3144.3479\n",
      "Epoch 3216/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2264.6985 - val_loss: 509.9244\n",
      "Epoch 3217/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 744.1846 - val_loss: 768.1799\n",
      "Epoch 3218/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1323.1595 - val_loss: 260.8317\n",
      "Epoch 3219/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1928.1326 - val_loss: 1433.3030\n",
      "Epoch 3220/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1497.3318 - val_loss: 2395.3684\n",
      "Epoch 3221/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2127.7744 - val_loss: 287.3179\n",
      "Epoch 3222/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 867.1838 - val_loss: 656.9480\n",
      "Epoch 3223/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1301.9653 - val_loss: 400.7523\n",
      "Epoch 3224/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 950.5529 - val_loss: 710.8706\n",
      "Epoch 3225/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1817.1066 - val_loss: 3434.8005\n",
      "Epoch 3226/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2946.4453 - val_loss: 334.8964\n",
      "Epoch 3227/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1651.0858 - val_loss: 962.3196\n",
      "Epoch 3228/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1685.1382 - val_loss: 2664.6531\n",
      "Epoch 3229/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2092.4292 - val_loss: 244.0672\n",
      "Epoch 3230/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1316.9995 - val_loss: 388.9841\n",
      "Epoch 3231/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1076.9308 - val_loss: 617.9178\n",
      "Epoch 3232/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1357.7377 - val_loss: 1899.6147\n",
      "Epoch 3233/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1202.8669 - val_loss: 816.2990\n",
      "Epoch 3234/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1034.4644 - val_loss: 155.2129\n",
      "Epoch 3235/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 334.1923 - val_loss: 192.8801\n",
      "Epoch 3236/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 275.8327 - val_loss: 191.5333\n",
      "Epoch 3237/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 396.2660 - val_loss: 189.9489\n",
      "Epoch 3238/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2185.4788 - val_loss: 2583.2788\n",
      "Epoch 3239/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1499.0880 - val_loss: 140.4088\n",
      "Epoch 3240/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 304.8484 - val_loss: 287.4836\n",
      "Epoch 3241/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 407.0426 - val_loss: 254.4553\n",
      "Epoch 3242/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 328.2246 - val_loss: 175.6725\n",
      "Epoch 3243/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 204.8960 - val_loss: 126.0757\n",
      "Epoch 3244/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 109.2078 - val_loss: 123.1165\n",
      "Epoch 3245/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 131.5654 - val_loss: 164.3521\n",
      "Epoch 3246/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 123.2037 - val_loss: 61.7647\n",
      "Epoch 3247/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 77.9960 - val_loss: 61.0674\n",
      "Epoch 3248/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 73.3422 - val_loss: 69.4824\n",
      "Epoch 3249/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 75.9579 - val_loss: 105.3433\n",
      "Epoch 3250/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 76.6227 - val_loss: 72.9269\n",
      "Epoch 3251/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 71.5108 - val_loss: 60.3777\n",
      "Epoch 3252/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 95.5493 - val_loss: 110.0549\n",
      "Epoch 3253/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 82.7208 - val_loss: 71.6220\n",
      "Epoch 3254/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 66.9154 - val_loss: 55.1126\n",
      "Epoch 3255/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 63.2679 - val_loss: 58.6626\n",
      "Epoch 3256/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 65.5061 - val_loss: 54.8862\n",
      "Epoch 3257/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 97.9532 - val_loss: 61.1670\n",
      "Epoch 3258/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 118.0122 - val_loss: 174.1079\n",
      "Epoch 3259/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 209.6575 - val_loss: 102.7560\n",
      "Epoch 3260/4000\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 231.3667 - val_loss: 1012.6636\n",
      "Epoch 3261/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2096.2917 - val_loss: 1384.9658\n",
      "Epoch 3262/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 573.9857 - val_loss: 155.5030\n",
      "Epoch 3263/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2079.4619 - val_loss: 2608.6577\n",
      "Epoch 3264/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1720.5869 - val_loss: 887.9799\n",
      "Epoch 3265/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 814.1671 - val_loss: 839.0634\n",
      "Epoch 3266/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 933.4399 - val_loss: 579.9671\n",
      "Epoch 3267/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 941.0643 - val_loss: 139.4989\n",
      "Epoch 3268/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 182.6746 - val_loss: 117.6040\n",
      "Epoch 3269/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 118.9919 - val_loss: 69.2809\n",
      "Epoch 3270/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 78.1579 - val_loss: 76.5900\n",
      "Epoch 3271/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 76.1304 - val_loss: 65.1039\n",
      "Epoch 3272/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 68.9953 - val_loss: 55.9915\n",
      "Epoch 3273/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 67.8645 - val_loss: 79.8292\n",
      "Epoch 3274/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 66.3963 - val_loss: 55.1752\n",
      "Epoch 3275/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 63.1993 - val_loss: 53.7626\n",
      "Epoch 3276/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 77.9921 - val_loss: 66.5984\n",
      "Epoch 3277/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 108.7641 - val_loss: 77.9770\n",
      "Epoch 3278/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 271.1909 - val_loss: 883.4000\n",
      "Epoch 3279/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 678.7986 - val_loss: 918.0752\n",
      "Epoch 3280/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1007.1503 - val_loss: 2035.4865\n",
      "Epoch 3281/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2284.5007 - val_loss: 171.2505\n",
      "Epoch 3282/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2842.8811 - val_loss: 2927.9185\n",
      "Epoch 3283/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1699.1625 - val_loss: 1525.9420\n",
      "Epoch 3284/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1948.0402 - val_loss: 144.3950\n",
      "Epoch 3285/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 917.5989 - val_loss: 278.8573\n",
      "Epoch 3286/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 373.4299 - val_loss: 380.0982\n",
      "Epoch 3287/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 332.3069 - val_loss: 215.1829\n",
      "Epoch 3288/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 240.6895 - val_loss: 137.9517\n",
      "Epoch 3289/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 130.3120 - val_loss: 173.9873\n",
      "Epoch 3290/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 664.7087 - val_loss: 1697.0092\n",
      "Epoch 3291/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1099.9746 - val_loss: 739.9252\n",
      "Epoch 3292/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1187.3384 - val_loss: 2893.5125\n",
      "Epoch 3293/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 2766.6677 - val_loss: 2031.0647\n",
      "Epoch 3294/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1414.6442 - val_loss: 1309.6458\n",
      "Epoch 3295/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 976.3605 - val_loss: 162.1566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3296/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 324.3830 - val_loss: 255.3023\n",
      "Epoch 3297/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 364.3836 - val_loss: 229.9866\n",
      "Epoch 3298/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 286.0014 - val_loss: 149.6563\n",
      "Epoch 3299/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 155.9289 - val_loss: 83.4080\n",
      "Epoch 3300/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 87.2581 - val_loss: 84.8218\n",
      "Epoch 3301/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 76.6497 - val_loss: 83.7190\n",
      "Epoch 3302/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 73.5590 - val_loss: 66.6550\n",
      "Epoch 3303/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 67.7373 - val_loss: 100.0776\n",
      "Epoch 3304/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 109.5110 - val_loss: 71.3492\n",
      "Epoch 3305/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 68.8868 - val_loss: 67.7898\n",
      "Epoch 3306/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 66.9426 - val_loss: 69.2926\n",
      "Epoch 3307/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 64.6432 - val_loss: 67.0141\n",
      "Epoch 3308/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 63.1900 - val_loss: 65.8673\n",
      "Epoch 3309/4000\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 67.8793 - val_loss: 81.6639\n",
      "Epoch 3310/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 75.4542 - val_loss: 91.9272\n",
      "Epoch 3311/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 189.2508 - val_loss: 75.6433\n",
      "Epoch 3312/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1499.6293 - val_loss: 1174.0009\n",
      "Epoch 3313/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1175.1899 - val_loss: 1527.0632\n",
      "Epoch 3314/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1425.6699 - val_loss: 1840.7020\n",
      "Epoch 3315/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1673.8916 - val_loss: 902.7010\n",
      "Epoch 3316/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1760.2832 - val_loss: 346.6915\n",
      "Epoch 3317/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 3639.2739 - val_loss: 6154.9390\n",
      "Epoch 3318/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 5868.2207 - val_loss: 1754.4647\n",
      "Epoch 3319/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 753.3981 - val_loss: 203.4933\n",
      "Epoch 3320/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 175.3110 - val_loss: 97.5588\n",
      "Epoch 3321/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 109.2789 - val_loss: 132.6079\n",
      "Epoch 3322/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 264.2452 - val_loss: 121.8938\n",
      "Epoch 3323/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2039.3464 - val_loss: 2503.2725\n",
      "Epoch 3324/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1551.5126 - val_loss: 1258.1030\n",
      "Epoch 3325/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1105.4124 - val_loss: 475.6007\n",
      "Epoch 3326/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 698.3409 - val_loss: 369.4569\n",
      "Epoch 3327/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 489.9516 - val_loss: 99.0723\n",
      "Epoch 3328/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 179.5745 - val_loss: 150.0812\n",
      "Epoch 3329/4000\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 213.9395 - val_loss: 139.7766\n",
      "Epoch 3330/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 140.7474 - val_loss: 72.9287\n",
      "Epoch 3331/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 88.4251 - val_loss: 86.4801\n",
      "Epoch 3332/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 89.2692 - val_loss: 79.1651\n",
      "Epoch 3333/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 75.5918 - val_loss: 72.7795\n",
      "Epoch 3334/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 73.5403 - val_loss: 165.9081\n",
      "Epoch 3335/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 144.0143 - val_loss: 226.5172\n",
      "Epoch 3336/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 180.8738 - val_loss: 92.2439\n",
      "Epoch 3337/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 99.1853 - val_loss: 79.4275\n",
      "Epoch 3338/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 90.9788 - val_loss: 70.4709\n",
      "Epoch 3339/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 79.5129 - val_loss: 98.1083\n",
      "Epoch 3340/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 95.3907 - val_loss: 172.7123\n",
      "Epoch 3341/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 237.8757 - val_loss: 695.7921\n",
      "Epoch 3342/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 963.3739 - val_loss: 1826.9900\n",
      "Epoch 3343/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2799.6418 - val_loss: 576.2864\n",
      "Epoch 3344/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 915.4100 - val_loss: 240.5334\n",
      "Epoch 3345/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1583.5398 - val_loss: 1482.3373\n",
      "Epoch 3346/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 786.9127 - val_loss: 336.3686\n",
      "Epoch 3347/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1286.8646 - val_loss: 1445.8857\n",
      "Epoch 3348/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1460.6320 - val_loss: 1658.2056\n",
      "Epoch 3349/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1345.8060 - val_loss: 1109.8250\n",
      "Epoch 3350/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1339.7650 - val_loss: 3746.1235\n",
      "Epoch 3351/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3189.5710 - val_loss: 2851.5493\n",
      "Epoch 3352/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1951.2092 - val_loss: 2359.2664\n",
      "Epoch 3353/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 4017.5872 - val_loss: 1988.1857\n",
      "Epoch 3354/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1438.7488 - val_loss: 1467.8730\n",
      "Epoch 3355/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 935.8002 - val_loss: 804.1487\n",
      "Epoch 3356/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 899.3237 - val_loss: 778.5469\n",
      "Epoch 3357/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1480.2667 - val_loss: 268.9701\n",
      "Epoch 3358/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 410.9899 - val_loss: 261.2723\n",
      "Epoch 3359/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 337.4327 - val_loss: 214.3105\n",
      "Epoch 3360/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 235.0022 - val_loss: 137.0808\n",
      "Epoch 3361/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 144.0884 - val_loss: 100.4468\n",
      "Epoch 3362/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 103.4879 - val_loss: 102.7637\n",
      "Epoch 3363/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 86.2258 - val_loss: 80.2464\n",
      "Epoch 3364/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 85.0031 - val_loss: 90.0808\n",
      "Epoch 3365/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 73.2130 - val_loss: 81.2734\n",
      "Epoch 3366/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 71.4771 - val_loss: 80.3758\n",
      "Epoch 3367/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 76.9955 - val_loss: 75.5942\n",
      "Epoch 3368/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 66.5302 - val_loss: 73.7062\n",
      "Epoch 3369/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 74.9062 - val_loss: 76.7087\n",
      "Epoch 3370/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 71.2047 - val_loss: 76.0531\n",
      "Epoch 3371/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 71.1295 - val_loss: 68.1691\n",
      "Epoch 3372/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 42ms/step - loss: 92.7513 - val_loss: 112.7237\n",
      "Epoch 3373/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 121.4732 - val_loss: 89.6895\n",
      "Epoch 3374/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 155.1483 - val_loss: 463.0377\n",
      "Epoch 3375/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 981.8226 - val_loss: 2807.4756\n",
      "Epoch 3376/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2937.3518 - val_loss: 340.9737\n",
      "Epoch 3377/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1572.8405 - val_loss: 1069.4325\n",
      "Epoch 3378/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1002.4529 - val_loss: 743.0895\n",
      "Epoch 3379/4000\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 775.4028 - val_loss: 880.8435\n",
      "Epoch 3380/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1397.4034 - val_loss: 2823.4473\n",
      "Epoch 3381/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2355.6648 - val_loss: 2122.3960\n",
      "Epoch 3382/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1274.3779 - val_loss: 381.3640\n",
      "Epoch 3383/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1096.6699 - val_loss: 861.8093\n",
      "Epoch 3384/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1056.4408 - val_loss: 1380.4073\n",
      "Epoch 3385/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1219.1641 - val_loss: 2635.8289\n",
      "Epoch 3386/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3574.9128 - val_loss: 1126.6633\n",
      "Epoch 3387/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1095.7190 - val_loss: 636.1553\n",
      "Epoch 3388/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1628.6619 - val_loss: 2861.9382\n",
      "Epoch 3389/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2209.8325 - val_loss: 680.5663\n",
      "Epoch 3390/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 613.7354 - val_loss: 677.0998\n",
      "Epoch 3391/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2967.1074 - val_loss: 1980.6326\n",
      "Epoch 3392/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1287.4479 - val_loss: 821.8974\n",
      "Epoch 3393/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1049.1726 - val_loss: 2265.7224\n",
      "Epoch 3394/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2171.9832 - val_loss: 1751.4775\n",
      "Epoch 3395/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 457.0401 - val_loss: 341.0265\n",
      "Epoch 3396/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 529.7523 - val_loss: 423.8380\n",
      "Epoch 3397/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 672.2757 - val_loss: 275.3223\n",
      "Epoch 3398/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1189.4354 - val_loss: 287.4594\n",
      "Epoch 3399/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1626.8379 - val_loss: 1810.0393\n",
      "Epoch 3400/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 980.3143 - val_loss: 926.5332\n",
      "Epoch 3401/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 762.1904 - val_loss: 1026.3761\n",
      "Epoch 3402/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1134.3967 - val_loss: 409.7346\n",
      "Epoch 3403/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2309.7117 - val_loss: 1309.1019\n",
      "Epoch 3404/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1151.7324 - val_loss: 1100.0945\n",
      "Epoch 3405/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1018.3663 - val_loss: 1707.0681\n",
      "Epoch 3406/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1249.6611 - val_loss: 143.8348\n",
      "Epoch 3407/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 244.3240 - val_loss: 253.4998\n",
      "Epoch 3408/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 317.7981 - val_loss: 207.7556\n",
      "Epoch 3409/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 233.1191 - val_loss: 132.3551\n",
      "Epoch 3410/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 125.2215 - val_loss: 102.9805\n",
      "Epoch 3411/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 87.2660 - val_loss: 94.0713\n",
      "Epoch 3412/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 75.1927 - val_loss: 82.2842\n",
      "Epoch 3413/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 77.7372 - val_loss: 80.3491\n",
      "Epoch 3414/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 90.6601 - val_loss: 154.9090\n",
      "Epoch 3415/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 109.5582 - val_loss: 75.5374\n",
      "Epoch 3416/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 74.7132 - val_loss: 72.1065\n",
      "Epoch 3417/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 66.5804 - val_loss: 74.5894\n",
      "Epoch 3418/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 70.9744 - val_loss: 92.5884\n",
      "Epoch 3419/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 72.4452 - val_loss: 72.4960\n",
      "Epoch 3420/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 64.5913 - val_loss: 72.3849\n",
      "Epoch 3421/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 65.5882 - val_loss: 70.8208\n",
      "Epoch 3422/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 73.8587 - val_loss: 88.4273\n",
      "Epoch 3423/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 103.6111 - val_loss: 216.3032\n",
      "Epoch 3424/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 212.8678 - val_loss: 113.7449\n",
      "Epoch 3425/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 97.9883 - val_loss: 73.6474\n",
      "Epoch 3426/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 232.1014 - val_loss: 320.0509\n",
      "Epoch 3427/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 799.4083 - val_loss: 641.1425\n",
      "Epoch 3428/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1385.0935 - val_loss: 1972.9459\n",
      "Epoch 3429/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1489.9612 - val_loss: 1939.1627\n",
      "Epoch 3430/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2292.2744 - val_loss: 129.5798\n",
      "Epoch 3431/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2133.9119 - val_loss: 1952.8384\n",
      "Epoch 3432/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1344.5709 - val_loss: 1111.9036\n",
      "Epoch 3433/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 905.1442 - val_loss: 890.8876\n",
      "Epoch 3434/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1277.0648 - val_loss: 415.6887\n",
      "Epoch 3435/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2607.6721 - val_loss: 1751.3865\n",
      "Epoch 3436/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1411.4968 - val_loss: 1508.0837\n",
      "Epoch 3437/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1028.3076 - val_loss: 920.4419\n",
      "Epoch 3438/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 958.9996 - val_loss: 154.9993\n",
      "Epoch 3439/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 310.8986 - val_loss: 350.4376\n",
      "Epoch 3440/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 884.9300 - val_loss: 2243.6716\n",
      "Epoch 3441/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1984.0450 - val_loss: 3140.4551\n",
      "Epoch 3442/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1526.3381 - val_loss: 556.9130\n",
      "Epoch 3443/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1692.6780 - val_loss: 2006.4054\n",
      "Epoch 3444/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1330.9875 - val_loss: 936.0454\n",
      "Epoch 3445/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 857.2913 - val_loss: 148.5807\n",
      "Epoch 3446/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 273.1079 - val_loss: 235.6813\n",
      "Epoch 3447/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 287.6866 - val_loss: 171.8603\n",
      "Epoch 3448/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 169.8576 - val_loss: 97.8840\n",
      "Epoch 3449/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 104.5635 - val_loss: 91.6859\n",
      "Epoch 3450/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 104.9988 - val_loss: 88.8381\n",
      "Epoch 3451/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 82.0486 - val_loss: 77.3562\n",
      "Epoch 3452/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 99.6171 - val_loss: 74.5980\n",
      "Epoch 3453/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 84.1723 - val_loss: 81.2273\n",
      "Epoch 3454/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 70.2479 - val_loss: 83.6960\n",
      "Epoch 3455/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 77.6452 - val_loss: 72.0157\n",
      "Epoch 3456/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 70.2270 - val_loss: 74.6183\n",
      "Epoch 3457/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 71.3161 - val_loss: 77.6478\n",
      "Epoch 3458/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 82.2958 - val_loss: 77.7751\n",
      "Epoch 3459/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 69.5189 - val_loss: 78.6685\n",
      "Epoch 3460/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 83.5281 - val_loss: 73.2792\n",
      "Epoch 3461/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 296.6363 - val_loss: 454.1885\n",
      "Epoch 3462/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1998.7438 - val_loss: 937.8639\n",
      "Epoch 3463/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 367.5463 - val_loss: 154.5686\n",
      "Epoch 3464/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 127.5612 - val_loss: 97.8075\n",
      "Epoch 3465/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 96.4878 - val_loss: 105.9292\n",
      "Epoch 3466/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 86.7232 - val_loss: 115.1957\n",
      "Epoch 3467/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 88.7467 - val_loss: 97.8361\n",
      "Epoch 3468/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 69.6956 - val_loss: 71.2603\n",
      "Epoch 3469/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 66.4959 - val_loss: 75.2832\n",
      "Epoch 3470/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 69.8120 - val_loss: 98.0447\n",
      "Epoch 3471/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 102.3105 - val_loss: 151.0088\n",
      "Epoch 3472/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1565.4790 - val_loss: 2552.7610\n",
      "Epoch 3473/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1492.7520 - val_loss: 89.6248\n",
      "Epoch 3474/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 267.3963 - val_loss: 246.1546\n",
      "Epoch 3475/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 334.9924 - val_loss: 208.4803\n",
      "Epoch 3476/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 246.0233 - val_loss: 146.9575\n",
      "Epoch 3477/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 191.2938 - val_loss: 149.2672\n",
      "Epoch 3478/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 201.4284 - val_loss: 122.7531\n",
      "Epoch 3479/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 242.0900 - val_loss: 442.7776\n",
      "Epoch 3480/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 508.1837 - val_loss: 661.0439\n",
      "Epoch 3481/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1187.5148 - val_loss: 2502.3625\n",
      "Epoch 3482/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1971.1207 - val_loss: 832.7321\n",
      "Epoch 3483/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1331.2249 - val_loss: 133.9868\n",
      "Epoch 3484/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2701.5471 - val_loss: 2502.5625\n",
      "Epoch 3485/4000\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 1991.8596 - val_loss: 2748.9375\n",
      "Epoch 3486/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 3613.0071 - val_loss: 1083.9249\n",
      "Epoch 3487/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 970.3935 - val_loss: 512.7581\n",
      "Epoch 3488/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 263.7858 - val_loss: 123.0971\n",
      "Epoch 3489/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 190.4187 - val_loss: 105.1642\n",
      "Epoch 3490/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 109.4979 - val_loss: 98.8853\n",
      "Epoch 3491/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 83.3852 - val_loss: 86.3790\n",
      "Epoch 3492/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 70.8082 - val_loss: 82.1021\n",
      "Epoch 3493/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 70.4479 - val_loss: 74.4963\n",
      "Epoch 3494/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 69.3770 - val_loss: 78.6645\n",
      "Epoch 3495/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 71.3378 - val_loss: 73.4871\n",
      "Epoch 3496/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 69.3384 - val_loss: 101.9139\n",
      "Epoch 3497/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 78.1191 - val_loss: 71.4408\n",
      "Epoch 3498/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 71.7605 - val_loss: 71.4100\n",
      "Epoch 3499/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 68.0715 - val_loss: 72.0270\n",
      "Epoch 3500/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 65.7039 - val_loss: 72.8598\n",
      "Epoch 3501/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 70.3579 - val_loss: 83.6718\n",
      "Epoch 3502/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 72.8120 - val_loss: 86.9076\n",
      "Epoch 3503/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 80.7894 - val_loss: 76.9132\n",
      "Epoch 3504/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 82.1799 - val_loss: 78.0308\n",
      "Epoch 3505/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 71.5854 - val_loss: 70.2250\n",
      "Epoch 3506/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 78.6674 - val_loss: 78.5332\n",
      "Epoch 3507/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 65.6120 - val_loss: 70.0618\n",
      "Epoch 3508/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 69.9244 - val_loss: 91.7683\n",
      "Epoch 3509/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 441.4250 - val_loss: 794.7987\n",
      "Epoch 3510/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 295.5179 - val_loss: 221.8377\n",
      "Epoch 3511/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 427.9634 - val_loss: 1727.4368\n",
      "Epoch 3512/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2309.9041 - val_loss: 490.5028\n",
      "Epoch 3513/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 271.6846 - val_loss: 224.4722\n",
      "Epoch 3514/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 345.6288 - val_loss: 216.8409\n",
      "Epoch 3515/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 258.2750 - val_loss: 173.4065\n",
      "Epoch 3516/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 170.6177 - val_loss: 116.6711\n",
      "Epoch 3517/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 113.8101 - val_loss: 112.1669\n",
      "Epoch 3518/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 88.5209 - val_loss: 75.4692\n",
      "Epoch 3519/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 69.6261 - val_loss: 73.2250\n",
      "Epoch 3520/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 68.7014 - val_loss: 75.6149\n",
      "Epoch 3521/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 77.7887 - val_loss: 74.9669\n",
      "Epoch 3522/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 392.6723 - val_loss: 1122.4758\n",
      "Epoch 3523/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 40ms/step - loss: 1506.4117 - val_loss: 3352.4529\n",
      "Epoch 3524/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 3553.1338 - val_loss: 439.8730\n",
      "Epoch 3525/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 909.2621 - val_loss: 120.6851\n",
      "Epoch 3526/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2262.0105 - val_loss: 1790.1835\n",
      "Epoch 3527/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 708.7048 - val_loss: 94.5368\n",
      "Epoch 3528/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 149.5034 - val_loss: 103.5005\n",
      "Epoch 3529/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 114.9154 - val_loss: 77.2698\n",
      "Epoch 3530/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 77.6814 - val_loss: 92.8012\n",
      "Epoch 3531/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 80.5605 - val_loss: 79.3032\n",
      "Epoch 3532/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 148.6771 - val_loss: 150.5844\n",
      "Epoch 3533/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 127.7481 - val_loss: 74.3195\n",
      "Epoch 3534/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 77.0834 - val_loss: 95.1135\n",
      "Epoch 3535/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 76.9155 - val_loss: 70.0765\n",
      "Epoch 3536/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 87.7779 - val_loss: 85.3936\n",
      "Epoch 3537/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 114.7074 - val_loss: 136.2126\n",
      "Epoch 3538/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1566.2340 - val_loss: 3247.3301\n",
      "Epoch 3539/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2353.3569 - val_loss: 1132.5111\n",
      "Epoch 3540/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2202.8923 - val_loss: 292.3852\n",
      "Epoch 3541/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1647.8859 - val_loss: 759.6534\n",
      "Epoch 3542/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1391.2108 - val_loss: 1339.3452\n",
      "Epoch 3543/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1018.0929 - val_loss: 1102.1680\n",
      "Epoch 3544/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1175.7163 - val_loss: 2154.3838\n",
      "Epoch 3545/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1786.1897 - val_loss: 308.2716\n",
      "Epoch 3546/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 721.2060 - val_loss: 827.6136\n",
      "Epoch 3547/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1333.0261 - val_loss: 1285.2012\n",
      "Epoch 3548/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 675.6442 - val_loss: 1335.2305\n",
      "Epoch 3549/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3189.1208 - val_loss: 3038.7935\n",
      "Epoch 3550/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2181.9580 - val_loss: 2248.1008\n",
      "Epoch 3551/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2481.5442 - val_loss: 261.6645\n",
      "Epoch 3552/4000\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 1509.4103 - val_loss: 744.9969\n",
      "Epoch 3553/4000\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 1637.1283 - val_loss: 2857.9565\n",
      "Epoch 3554/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2259.0308 - val_loss: 221.6126\n",
      "Epoch 3555/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1428.6310 - val_loss: 296.7362\n",
      "Epoch 3556/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1165.6195 - val_loss: 386.5232\n",
      "Epoch 3557/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1760.3752 - val_loss: 1814.0316\n",
      "Epoch 3558/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1014.8344 - val_loss: 515.1651\n",
      "Epoch 3559/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 498.8493 - val_loss: 755.7603\n",
      "Epoch 3560/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 743.4539 - val_loss: 1795.9093\n",
      "Epoch 3561/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1881.5499 - val_loss: 675.7166\n",
      "Epoch 3562/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2306.0117 - val_loss: 2309.0657\n",
      "Epoch 3563/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1375.2025 - val_loss: 685.6181\n",
      "Epoch 3564/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 848.7485 - val_loss: 1350.2764\n",
      "Epoch 3565/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 932.9806 - val_loss: 292.2846\n",
      "Epoch 3566/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 477.8097 - val_loss: 946.8194\n",
      "Epoch 3567/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2054.7659 - val_loss: 545.3807\n",
      "Epoch 3568/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1370.2924 - val_loss: 1919.0878\n",
      "Epoch 3569/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1358.0568 - val_loss: 1240.9078\n",
      "Epoch 3570/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1404.9169 - val_loss: 460.0186\n",
      "Epoch 3571/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 3094.1687 - val_loss: 2500.2378\n",
      "Epoch 3572/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1807.3489 - val_loss: 1971.5665\n",
      "Epoch 3573/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2388.8372 - val_loss: 272.7104\n",
      "Epoch 3574/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 605.7672 - val_loss: 675.3571\n",
      "Epoch 3575/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2058.7856 - val_loss: 1625.3055\n",
      "Epoch 3576/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 832.1271 - val_loss: 595.7987\n",
      "Epoch 3577/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 347.3919 - val_loss: 175.5705\n",
      "Epoch 3578/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 171.7704 - val_loss: 131.5483\n",
      "Epoch 3579/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 151.5156 - val_loss: 100.6116\n",
      "Epoch 3580/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 103.6968 - val_loss: 97.4656\n",
      "Epoch 3581/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 94.7333 - val_loss: 93.4844\n",
      "Epoch 3582/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 79.3730 - val_loss: 80.6701\n",
      "Epoch 3583/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 76.5368 - val_loss: 82.3030\n",
      "Epoch 3584/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 72.0704 - val_loss: 81.4633\n",
      "Epoch 3585/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 72.5743 - val_loss: 77.3043\n",
      "Epoch 3586/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 82.7450 - val_loss: 87.6709\n",
      "Epoch 3587/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 138.5147 - val_loss: 378.1618\n",
      "Epoch 3588/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 635.6378 - val_loss: 2033.9412\n",
      "Epoch 3589/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2279.6077 - val_loss: 124.1633\n",
      "Epoch 3590/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1311.4551 - val_loss: 605.1055\n",
      "Epoch 3591/4000\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 999.4327 - val_loss: 881.9849\n",
      "Epoch 3592/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 699.2870 - val_loss: 796.1755\n",
      "Epoch 3593/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 921.0117 - val_loss: 1677.8340\n",
      "Epoch 3594/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1255.7217 - val_loss: 378.9235\n",
      "Epoch 3595/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 727.0135 - val_loss: 1193.3373\n",
      "Epoch 3596/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 2554.9998 - val_loss: 930.5272\n",
      "Epoch 3597/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1450.2223 - val_loss: 1276.2977\n",
      "Epoch 3598/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1393.8237 - val_loss: 2446.8848\n",
      "Epoch 3599/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2388.1516 - val_loss: 391.7959\n",
      "Epoch 3600/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2506.1963 - val_loss: 2629.4934\n",
      "Epoch 3601/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1557.9171 - val_loss: 849.1899\n",
      "Epoch 3602/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 813.2882 - val_loss: 1251.9150\n",
      "Epoch 3603/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1709.4514 - val_loss: 330.2032\n",
      "Epoch 3604/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2050.1018 - val_loss: 2980.3091\n",
      "Epoch 3605/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 2122.9238 - val_loss: 377.6788\n",
      "Epoch 3606/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 744.1889 - val_loss: 266.6183\n",
      "Epoch 3607/4000\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 900.3796 - val_loss: 223.8604\n",
      "Epoch 3608/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 1539.5737 - val_loss: 1136.9255\n",
      "Epoch 3609/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1496.4331 - val_loss: 2987.6404\n",
      "Epoch 3610/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2954.5085 - val_loss: 313.6269\n",
      "Epoch 3611/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 464.9495 - val_loss: 325.0121\n",
      "Epoch 3612/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1885.5740 - val_loss: 1747.2814\n",
      "Epoch 3613/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 983.4716 - val_loss: 912.3589\n",
      "Epoch 3614/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 587.4938 - val_loss: 239.5608\n",
      "Epoch 3615/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 177.4580 - val_loss: 137.4775\n",
      "Epoch 3616/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 118.3404 - val_loss: 102.3030\n",
      "Epoch 3617/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 97.7098 - val_loss: 97.7033\n",
      "Epoch 3618/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 84.1770 - val_loss: 84.6644\n",
      "Epoch 3619/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 86.7130 - val_loss: 82.3093\n",
      "Epoch 3620/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 81.2324 - val_loss: 79.9850\n",
      "Epoch 3621/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 73.2374 - val_loss: 85.3427\n",
      "Epoch 3622/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 81.0826 - val_loss: 84.1747\n",
      "Epoch 3623/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 77.6745 - val_loss: 81.2818\n",
      "Epoch 3624/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 77.7627 - val_loss: 76.3145\n",
      "Epoch 3625/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 69.8062 - val_loss: 74.9828\n",
      "Epoch 3626/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 68.6386 - val_loss: 86.2837\n",
      "Epoch 3627/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 74.5450 - val_loss: 78.5648\n",
      "Epoch 3628/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 66.0958 - val_loss: 79.3449\n",
      "Epoch 3629/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 79.1366 - val_loss: 72.7755\n",
      "Epoch 3630/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 83.4597 - val_loss: 80.6757\n",
      "Epoch 3631/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 67.9583 - val_loss: 71.4322\n",
      "Epoch 3632/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 69.5040 - val_loss: 77.7009\n",
      "Epoch 3633/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 80.7201 - val_loss: 86.2642\n",
      "Epoch 3634/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 114.1869 - val_loss: 91.7285\n",
      "Epoch 3635/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 85.1709 - val_loss: 92.9530\n",
      "Epoch 3636/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 95.4571 - val_loss: 108.5301\n",
      "Epoch 3637/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 99.0895 - val_loss: 113.0811\n",
      "Epoch 3638/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 138.8119 - val_loss: 222.0500\n",
      "Epoch 3639/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 151.1092 - val_loss: 76.4840\n",
      "Epoch 3640/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 74.4257 - val_loss: 72.1436\n",
      "Epoch 3641/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 83.3390 - val_loss: 70.8291\n",
      "Epoch 3642/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 66.1482 - val_loss: 63.8909\n",
      "Epoch 3643/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 72.6881 - val_loss: 65.6214\n",
      "Epoch 3644/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 67.3498 - val_loss: 65.9819\n",
      "Epoch 3645/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 71.2862 - val_loss: 67.0094\n",
      "Epoch 3646/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 63.2124 - val_loss: 77.5329\n",
      "Epoch 3647/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 68.8890 - val_loss: 64.4234\n",
      "Epoch 3648/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 62.4975 - val_loss: 69.1860\n",
      "Epoch 3649/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 66.4027 - val_loss: 63.4929\n",
      "Epoch 3650/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 84.1412 - val_loss: 80.9643\n",
      "Epoch 3651/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 99.1698 - val_loss: 146.2227\n",
      "Epoch 3652/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 108.7525 - val_loss: 111.5105\n",
      "Epoch 3653/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 99.4025 - val_loss: 72.6182\n",
      "Epoch 3654/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 76.7583 - val_loss: 69.2304\n",
      "Epoch 3655/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 168.7697 - val_loss: 944.6673\n",
      "Epoch 3656/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1733.4423 - val_loss: 632.4535\n",
      "Epoch 3657/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2634.4788 - val_loss: 2742.9163\n",
      "Epoch 3658/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1659.0646 - val_loss: 1204.6830\n",
      "Epoch 3659/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1228.0239 - val_loss: 1099.6897\n",
      "Epoch 3660/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1156.3539 - val_loss: 427.2281\n",
      "Epoch 3661/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2230.2549 - val_loss: 1027.1846\n",
      "Epoch 3662/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1121.7932 - val_loss: 871.5817\n",
      "Epoch 3663/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 511.9389 - val_loss: 567.9783\n",
      "Epoch 3664/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1515.4607 - val_loss: 3087.5908\n",
      "Epoch 3665/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2555.9224 - val_loss: 3028.6360\n",
      "Epoch 3666/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 3045.3535 - val_loss: 2530.8813\n",
      "Epoch 3667/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 1809.3917 - val_loss: 1980.6783\n",
      "Epoch 3668/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2134.2632 - val_loss: 236.0875\n",
      "Epoch 3669/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 830.5118 - val_loss: 174.7680\n",
      "Epoch 3670/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 252.2715 - val_loss: 184.1333\n",
      "Epoch 3671/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 198.5014 - val_loss: 150.4696\n",
      "Epoch 3672/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 112.9234 - val_loss: 94.4062\n",
      "Epoch 3673/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 90.6990 - val_loss: 89.3120\n",
      "Epoch 3674/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 40ms/step - loss: 75.2308 - val_loss: 98.3372\n",
      "Epoch 3675/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 75.2899 - val_loss: 78.8141\n",
      "Epoch 3676/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 70.5387 - val_loss: 72.9240\n",
      "Epoch 3677/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 72.5460 - val_loss: 82.0828\n",
      "Epoch 3678/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 84.4298 - val_loss: 92.4082\n",
      "Epoch 3679/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 79.1262 - val_loss: 84.3367\n",
      "Epoch 3680/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 72.8816 - val_loss: 83.7773\n",
      "Epoch 3681/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 80.6876 - val_loss: 75.2871\n",
      "Epoch 3682/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 90.1720 - val_loss: 73.7764\n",
      "Epoch 3683/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 71.0427 - val_loss: 77.7698\n",
      "Epoch 3684/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 69.7361 - val_loss: 74.2414\n",
      "Epoch 3685/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 66.1618 - val_loss: 69.8287\n",
      "Epoch 3686/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 65.0150 - val_loss: 73.3370\n",
      "Epoch 3687/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 66.9061 - val_loss: 73.4178\n",
      "Epoch 3688/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 79.3301 - val_loss: 68.7764\n",
      "Epoch 3689/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 77.1475 - val_loss: 102.6409\n",
      "Epoch 3690/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 82.3192 - val_loss: 70.7251\n",
      "Epoch 3691/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 72.5864 - val_loss: 68.6783\n",
      "Epoch 3692/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 68.1420 - val_loss: 81.9620\n",
      "Epoch 3693/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 66.1738 - val_loss: 73.0060\n",
      "Epoch 3694/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 62.3680 - val_loss: 68.5807\n",
      "Epoch 3695/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 63.8518 - val_loss: 72.7845\n",
      "Epoch 3696/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 69.7598 - val_loss: 83.6861\n",
      "Epoch 3697/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 73.8014 - val_loss: 71.6839\n",
      "Epoch 3698/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 74.0658 - val_loss: 142.6412\n",
      "Epoch 3699/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 77.7026 - val_loss: 69.2482\n",
      "Epoch 3700/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 74.9359 - val_loss: 95.4718\n",
      "Epoch 3701/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 100.0658 - val_loss: 141.8838\n",
      "Epoch 3702/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 78.2749 - val_loss: 72.8900\n",
      "Epoch 3703/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 80.1847 - val_loss: 169.3689\n",
      "Epoch 3704/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 146.1291 - val_loss: 95.9242\n",
      "Epoch 3705/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 126.2432 - val_loss: 246.7766\n",
      "Epoch 3706/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 147.3179 - val_loss: 94.0896\n",
      "Epoch 3707/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 69.3999 - val_loss: 75.4826\n",
      "Epoch 3708/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 67.4251 - val_loss: 72.1751\n",
      "Epoch 3709/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 66.3674 - val_loss: 86.4681\n",
      "Epoch 3710/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 80.1011 - val_loss: 82.1124\n",
      "Epoch 3711/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 71.3700 - val_loss: 89.6212\n",
      "Epoch 3712/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 405.1243 - val_loss: 1388.0835\n",
      "Epoch 3713/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1186.2756 - val_loss: 1374.0433\n",
      "Epoch 3714/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 1675.2046 - val_loss: 335.0923\n",
      "Epoch 3715/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1377.2220 - val_loss: 2634.9287\n",
      "Epoch 3716/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1741.6656 - val_loss: 582.4789\n",
      "Epoch 3717/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 294.9091 - val_loss: 127.3789\n",
      "Epoch 3718/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1051.5693 - val_loss: 3025.9817\n",
      "Epoch 3719/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2678.9280 - val_loss: 7037.5879\n",
      "Epoch 3720/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 1501.6045 - val_loss: 149.5581\n",
      "Epoch 3721/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1775.2719 - val_loss: 1366.5616\n",
      "Epoch 3722/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1173.7169 - val_loss: 1399.8414\n",
      "Epoch 3723/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1122.5938 - val_loss: 1312.0568\n",
      "Epoch 3724/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1256.6851 - val_loss: 2153.2593\n",
      "Epoch 3725/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1846.3569 - val_loss: 189.7329\n",
      "Epoch 3726/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 239.4846 - val_loss: 255.0952\n",
      "Epoch 3727/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 734.2443 - val_loss: 1994.5134\n",
      "Epoch 3728/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1838.4874 - val_loss: 298.1006\n",
      "Epoch 3729/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1490.6482 - val_loss: 402.5115\n",
      "Epoch 3730/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 2442.7083 - val_loss: 3189.7336\n",
      "Epoch 3731/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1995.6608 - val_loss: 956.4717\n",
      "Epoch 3732/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2055.8845 - val_loss: 365.1637\n",
      "Epoch 3733/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 610.7645 - val_loss: 430.1982\n",
      "Epoch 3734/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 304.7875 - val_loss: 255.2700\n",
      "Epoch 3735/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 193.8549 - val_loss: 174.6378\n",
      "Epoch 3736/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 117.2622 - val_loss: 124.4612\n",
      "Epoch 3737/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 106.3566 - val_loss: 116.9315\n",
      "Epoch 3738/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 98.6552 - val_loss: 102.2831\n",
      "Epoch 3739/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 77.2043 - val_loss: 83.5647\n",
      "Epoch 3740/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 66.4789 - val_loss: 77.2641\n",
      "Epoch 3741/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 104.0317 - val_loss: 151.2117\n",
      "Epoch 3742/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 87.0618 - val_loss: 77.8166\n",
      "Epoch 3743/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 71.0625 - val_loss: 76.5760\n",
      "Epoch 3744/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 73.8444 - val_loss: 81.7201\n",
      "Epoch 3745/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 79.2426 - val_loss: 134.6203\n",
      "Epoch 3746/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 87.9686 - val_loss: 83.3503\n",
      "Epoch 3747/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 70.0996 - val_loss: 76.1525\n",
      "Epoch 3748/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 69.6974 - val_loss: 79.3267\n",
      "Epoch 3749/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 104.9953 - val_loss: 130.3328\n",
      "Epoch 3750/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 120.6789 - val_loss: 148.3876\n",
      "Epoch 3751/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 119.0599 - val_loss: 105.9609\n",
      "Epoch 3752/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 87.2475 - val_loss: 90.2549\n",
      "Epoch 3753/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 135.4837 - val_loss: 82.1748\n",
      "Epoch 3754/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 104.3077 - val_loss: 98.8216\n",
      "Epoch 3755/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 78.8560 - val_loss: 87.3268\n",
      "Epoch 3756/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 72.8144 - val_loss: 89.1345\n",
      "Epoch 3757/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 83.9191 - val_loss: 80.7277\n",
      "Epoch 3758/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 67.1130 - val_loss: 75.9368\n",
      "Epoch 3759/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 66.9191 - val_loss: 71.2296\n",
      "Epoch 3760/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 63.2298 - val_loss: 73.0396\n",
      "Epoch 3761/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 72.6467 - val_loss: 82.3339\n",
      "Epoch 3762/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 67.9622 - val_loss: 86.8049\n",
      "Epoch 3763/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 69.7540 - val_loss: 82.7512\n",
      "Epoch 3764/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 65.1628 - val_loss: 71.0199\n",
      "Epoch 3765/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 73.1322 - val_loss: 71.3996\n",
      "Epoch 3766/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 65.2294 - val_loss: 69.9937\n",
      "Epoch 3767/4000\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 71.7862 - val_loss: 71.4253\n",
      "Epoch 3768/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 73.9719 - val_loss: 72.6701\n",
      "Epoch 3769/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 81.2798 - val_loss: 78.3995\n",
      "Epoch 3770/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 66.0171 - val_loss: 70.7965\n",
      "Epoch 3771/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 66.9932 - val_loss: 76.4100\n",
      "Epoch 3772/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 64.4821 - val_loss: 72.3194\n",
      "Epoch 3773/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 63.6589 - val_loss: 68.9628\n",
      "Epoch 3774/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 61.5029 - val_loss: 71.4045\n",
      "Epoch 3775/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 66.0106 - val_loss: 71.0353\n",
      "Epoch 3776/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 64.6400 - val_loss: 69.8996\n",
      "Epoch 3777/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 61.5277 - val_loss: 70.0191\n",
      "Epoch 3778/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 61.3567 - val_loss: 68.5889\n",
      "Epoch 3779/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 67.4073 - val_loss: 69.3150\n",
      "Epoch 3780/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 74.4566 - val_loss: 72.5046\n",
      "Epoch 3781/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 62.3141 - val_loss: 72.7999\n",
      "Epoch 3782/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 84.5016 - val_loss: 87.7707\n",
      "Epoch 3783/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 61.3991 - val_loss: 89.6634\n",
      "Epoch 3784/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 91.7817 - val_loss: 169.1175\n",
      "Epoch 3785/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 168.5871 - val_loss: 85.7617\n",
      "Epoch 3786/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 68.9409 - val_loss: 95.7040\n",
      "Epoch 3787/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 331.4323 - val_loss: 186.1125\n",
      "Epoch 3788/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 206.7872 - val_loss: 464.6093\n",
      "Epoch 3789/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1151.0791 - val_loss: 2798.1323\n",
      "Epoch 3790/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1813.1938 - val_loss: 177.8339\n",
      "Epoch 3791/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 405.9181 - val_loss: 593.9747\n",
      "Epoch 3792/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1477.2133 - val_loss: 1472.2559\n",
      "Epoch 3793/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1604.4579 - val_loss: 575.3214\n",
      "Epoch 3794/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1601.4167 - val_loss: 2018.8735\n",
      "Epoch 3795/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1567.6744 - val_loss: 1802.3438\n",
      "Epoch 3796/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 921.6920 - val_loss: 306.4365\n",
      "Epoch 3797/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1260.6056 - val_loss: 2020.3461\n",
      "Epoch 3798/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1918.9095 - val_loss: 2709.9744\n",
      "Epoch 3799/4000\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 2372.3367 - val_loss: 141.0726\n",
      "Epoch 3800/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1072.5967 - val_loss: 3954.4795\n",
      "Epoch 3801/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 5421.4795 - val_loss: 2359.0498\n",
      "Epoch 3802/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2776.7129 - val_loss: 3592.4050\n",
      "Epoch 3803/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2932.9346 - val_loss: 188.0865\n",
      "Epoch 3804/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 285.7361 - val_loss: 181.7061\n",
      "Epoch 3805/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 166.1713 - val_loss: 197.2287\n",
      "Epoch 3806/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 188.4897 - val_loss: 92.0766\n",
      "Epoch 3807/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 195.2083 - val_loss: 122.4198\n",
      "Epoch 3808/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 393.8766 - val_loss: 1185.7501\n",
      "Epoch 3809/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1379.1157 - val_loss: 3097.3032\n",
      "Epoch 3810/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 5764.3989 - val_loss: 3598.2388\n",
      "Epoch 3811/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2086.7585 - val_loss: 1038.3987\n",
      "Epoch 3812/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1058.0322 - val_loss: 2217.6892\n",
      "Epoch 3813/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2393.2505 - val_loss: 579.7341\n",
      "Epoch 3814/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 3368.2700 - val_loss: 3745.3711\n",
      "Epoch 3815/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2354.1472 - val_loss: 1170.0018\n",
      "Epoch 3816/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1437.1533 - val_loss: 3202.7983\n",
      "Epoch 3817/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 763.1613 - val_loss: 1294.0699\n",
      "Epoch 3818/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1997.5913 - val_loss: 1112.1685\n",
      "Epoch 3819/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1341.7561 - val_loss: 1301.7936\n",
      "Epoch 3820/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 849.2416 - val_loss: 789.0065\n",
      "Epoch 3821/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 913.4458 - val_loss: 1383.1238\n",
      "Epoch 3822/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 966.3401 - val_loss: 1086.7028\n",
      "Epoch 3823/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 821.6423 - val_loss: 172.9707\n",
      "Epoch 3824/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 158.4290 - val_loss: 120.4463\n",
      "Epoch 3825/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 121.6286 - val_loss: 141.9324\n",
      "Epoch 3826/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 41ms/step - loss: 106.4604 - val_loss: 91.0239\n",
      "Epoch 3827/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 85.0072 - val_loss: 111.5401\n",
      "Epoch 3828/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 89.1476 - val_loss: 89.1962\n",
      "Epoch 3829/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 77.2599 - val_loss: 77.7229\n",
      "Epoch 3830/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 68.0088 - val_loss: 75.3999\n",
      "Epoch 3831/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 76.0362 - val_loss: 69.4320\n",
      "Epoch 3832/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 77.2746 - val_loss: 87.7785\n",
      "Epoch 3833/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 270.6807 - val_loss: 598.2506\n",
      "Epoch 3834/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2112.6570 - val_loss: 5804.5903\n",
      "Epoch 3835/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 7027.4658 - val_loss: 3632.8127\n",
      "Epoch 3836/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1717.1161 - val_loss: 1730.6492\n",
      "Epoch 3837/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1821.1340 - val_loss: 236.7776\n",
      "Epoch 3838/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 176.0739 - val_loss: 219.8153\n",
      "Epoch 3839/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 347.6812 - val_loss: 223.5977\n",
      "Epoch 3840/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 438.2448 - val_loss: 229.7838\n",
      "Epoch 3841/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 453.0002 - val_loss: 439.4995\n",
      "Epoch 3842/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 860.8285 - val_loss: 1168.4320\n",
      "Epoch 3843/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2946.3452 - val_loss: 1473.9602\n",
      "Epoch 3844/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1664.2931 - val_loss: 2716.8867\n",
      "Epoch 3845/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2111.6379 - val_loss: 111.1099\n",
      "Epoch 3846/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 531.1696 - val_loss: 1976.4497\n",
      "Epoch 3847/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2085.6138 - val_loss: 1606.6416\n",
      "Epoch 3848/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1474.5201 - val_loss: 2263.5347\n",
      "Epoch 3849/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1872.6055 - val_loss: 422.8257\n",
      "Epoch 3850/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 865.2350 - val_loss: 1843.7155\n",
      "Epoch 3851/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 2678.9158 - val_loss: 494.7973\n",
      "Epoch 3852/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1266.8579 - val_loss: 655.8232\n",
      "Epoch 3853/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1012.1664 - val_loss: 1061.8936\n",
      "Epoch 3854/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 543.9803 - val_loss: 242.2058\n",
      "Epoch 3855/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 317.9547 - val_loss: 234.8313\n",
      "Epoch 3856/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 222.8142 - val_loss: 258.6922\n",
      "Epoch 3857/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 171.7067 - val_loss: 119.6147\n",
      "Epoch 3858/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 119.4514 - val_loss: 113.5989\n",
      "Epoch 3859/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 97.5758 - val_loss: 84.6533\n",
      "Epoch 3860/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 82.2351 - val_loss: 86.2563\n",
      "Epoch 3861/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 80.6743 - val_loss: 96.7738\n",
      "Epoch 3862/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 107.6165 - val_loss: 116.7003\n",
      "Epoch 3863/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 97.5996 - val_loss: 76.5895\n",
      "Epoch 3864/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 87.6688 - val_loss: 84.3940\n",
      "Epoch 3865/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 90.0931 - val_loss: 82.9663\n",
      "Epoch 3866/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 75.6270 - val_loss: 75.1534\n",
      "Epoch 3867/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 68.4298 - val_loss: 81.2904\n",
      "Epoch 3868/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 75.3436 - val_loss: 73.7956\n",
      "Epoch 3869/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 67.5891 - val_loss: 74.1276\n",
      "Epoch 3870/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 69.5122 - val_loss: 83.5518\n",
      "Epoch 3871/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 85.9537 - val_loss: 83.0232\n",
      "Epoch 3872/4000\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 84.5526 - val_loss: 102.7831\n",
      "Epoch 3873/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 102.6554 - val_loss: 113.7644\n",
      "Epoch 3874/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 420.5534 - val_loss: 1072.7659\n",
      "Epoch 3875/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 749.0236 - val_loss: 724.0093\n",
      "Epoch 3876/4000\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 441.1573 - val_loss: 177.8537\n",
      "Epoch 3877/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 811.7242 - val_loss: 846.4120\n",
      "Epoch 3878/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 1518.6898 - val_loss: 2835.8757\n",
      "Epoch 3879/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2298.9263 - val_loss: 225.3024\n",
      "Epoch 3880/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 961.4378 - val_loss: 142.5520\n",
      "Epoch 3881/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 1904.9534 - val_loss: 1637.5767\n",
      "Epoch 3882/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 844.5550 - val_loss: 298.6578\n",
      "Epoch 3883/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 950.9168 - val_loss: 849.7899\n",
      "Epoch 3884/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1523.0221 - val_loss: 2185.5051\n",
      "Epoch 3885/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1642.2725 - val_loss: 556.0362\n",
      "Epoch 3886/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 770.8973 - val_loss: 598.3333\n",
      "Epoch 3887/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1075.6996 - val_loss: 2445.3027\n",
      "Epoch 3888/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1947.3920 - val_loss: 1159.8369\n",
      "Epoch 3889/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 812.6395 - val_loss: 1262.6799\n",
      "Epoch 3890/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 871.3961 - val_loss: 788.1813\n",
      "Epoch 3891/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 565.3257 - val_loss: 144.3539\n",
      "Epoch 3892/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 144.0443 - val_loss: 106.7109\n",
      "Epoch 3893/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 87.4486 - val_loss: 86.0669\n",
      "Epoch 3894/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 83.8261 - val_loss: 88.8368\n",
      "Epoch 3895/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 87.8651 - val_loss: 96.1162\n",
      "Epoch 3896/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 90.1081 - val_loss: 78.7704\n",
      "Epoch 3897/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 71.3054 - val_loss: 82.8157\n",
      "Epoch 3898/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 79.5938 - val_loss: 107.2127\n",
      "Epoch 3899/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 77.5797 - val_loss: 81.0077\n",
      "Epoch 3900/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 79.2434 - val_loss: 85.6606\n",
      "Epoch 3901/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 75.8606 - val_loss: 75.8641\n",
      "Epoch 3902/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 71.1595 - val_loss: 73.9075\n",
      "Epoch 3903/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 89.7428 - val_loss: 78.5909\n",
      "Epoch 3904/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 74.3150 - val_loss: 98.5003\n",
      "Epoch 3905/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 73.5201 - val_loss: 89.8752\n",
      "Epoch 3906/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 80.3982 - val_loss: 99.2218\n",
      "Epoch 3907/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 81.1013 - val_loss: 72.9113\n",
      "Epoch 3908/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 76.3983 - val_loss: 76.0079\n",
      "Epoch 3909/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 69.2584 - val_loss: 74.2179\n",
      "Epoch 3910/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 70.9866 - val_loss: 75.6295\n",
      "Epoch 3911/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 71.2370 - val_loss: 71.5606\n",
      "Epoch 3912/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 69.3729 - val_loss: 80.5119\n",
      "Epoch 3913/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 83.2934 - val_loss: 108.3756\n",
      "Epoch 3914/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 79.9959 - val_loss: 75.1860\n",
      "Epoch 3915/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 86.8723 - val_loss: 80.9680\n",
      "Epoch 3916/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 192.8547 - val_loss: 371.8427\n",
      "Epoch 3917/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 957.4853 - val_loss: 1838.1932\n",
      "Epoch 3918/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1313.6404 - val_loss: 1514.7620\n",
      "Epoch 3919/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1452.9514 - val_loss: 620.2243\n",
      "Epoch 3920/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 997.5153 - val_loss: 164.7561\n",
      "Epoch 3921/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 507.7227 - val_loss: 1926.6956\n",
      "Epoch 3922/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3023.9519 - val_loss: 843.0106\n",
      "Epoch 3923/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 402.2928 - val_loss: 382.9628\n",
      "Epoch 3924/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 876.4556 - val_loss: 2107.1052\n",
      "Epoch 3925/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2343.1797 - val_loss: 1366.2699\n",
      "Epoch 3926/4000\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 996.3563 - val_loss: 636.7932\n",
      "Epoch 3927/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 1665.5233 - val_loss: 2926.6145\n",
      "Epoch 3928/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 2324.5186 - val_loss: 160.4456\n",
      "Epoch 3929/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 222.6878 - val_loss: 264.8973\n",
      "Epoch 3930/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 387.6267 - val_loss: 271.0667\n",
      "Epoch 3931/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 334.4523 - val_loss: 204.5696\n",
      "Epoch 3932/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 217.7651 - val_loss: 147.7704\n",
      "Epoch 3933/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 130.5172 - val_loss: 91.7241\n",
      "Epoch 3934/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 92.9269 - val_loss: 99.3753\n",
      "Epoch 3935/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 84.1668 - val_loss: 89.7959\n",
      "Epoch 3936/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 74.8049 - val_loss: 74.7941\n",
      "Epoch 3937/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 94.1326 - val_loss: 71.2207\n",
      "Epoch 3938/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 77.1760 - val_loss: 74.7751\n",
      "Epoch 3939/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 79.9595 - val_loss: 130.2837\n",
      "Epoch 3940/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 96.0723 - val_loss: 95.7278\n",
      "Epoch 3941/4000\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 80.6125 - val_loss: 71.4053\n",
      "Epoch 3942/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 74.4281 - val_loss: 68.7992\n",
      "Epoch 3943/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 69.5823 - val_loss: 79.9167\n",
      "Epoch 3944/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 76.3446 - val_loss: 92.1665\n",
      "Epoch 3945/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 80.3332 - val_loss: 143.2529\n",
      "Epoch 3946/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 141.1187 - val_loss: 152.7690\n",
      "Epoch 3947/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 107.1193 - val_loss: 98.3116\n",
      "Epoch 3948/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 71.9345 - val_loss: 68.3057\n",
      "Epoch 3949/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 68.6335 - val_loss: 67.0958\n",
      "Epoch 3950/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 71.2255 - val_loss: 68.2021\n",
      "Epoch 3951/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 77.0664 - val_loss: 65.7214\n",
      "Epoch 3952/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 72.2889 - val_loss: 66.0137\n",
      "Epoch 3953/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 90.7828 - val_loss: 70.8063\n",
      "Epoch 3954/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 69.0012 - val_loss: 76.8266\n",
      "Epoch 3955/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 246.7236 - val_loss: 82.0876\n",
      "Epoch 3956/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 104.9923 - val_loss: 76.1187\n",
      "Epoch 3957/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 77.4859 - val_loss: 86.9113\n",
      "Epoch 3958/4000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 78.8113 - val_loss: 68.2386\n",
      "Epoch 3959/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 89.2609 - val_loss: 76.6771\n",
      "Epoch 3960/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 78.6748 - val_loss: 65.8273\n",
      "Epoch 3961/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 65.8652 - val_loss: 64.2214\n",
      "Epoch 3962/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 68.8554 - val_loss: 62.5683\n",
      "Epoch 3963/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 126.2293 - val_loss: 151.2081\n",
      "Epoch 3964/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 1526.9121 - val_loss: 2347.8848\n",
      "Epoch 3965/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1616.9706 - val_loss: 2597.9221\n",
      "Epoch 3966/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2993.4773 - val_loss: 316.9868\n",
      "Epoch 3967/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2138.1562 - val_loss: 763.9741\n",
      "Epoch 3968/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2275.6685 - val_loss: 3740.3447\n",
      "Epoch 3969/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2555.6482 - val_loss: 235.0804\n",
      "Epoch 3970/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 593.0720 - val_loss: 819.9415\n",
      "Epoch 3971/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1469.5181 - val_loss: 422.3845\n",
      "Epoch 3972/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 434.2280 - val_loss: 1452.0410\n",
      "Epoch 3973/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2254.8313 - val_loss: 1689.0166\n",
      "Epoch 3974/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 731.5875 - val_loss: 188.1029\n",
      "Epoch 3975/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 262.7388 - val_loss: 305.6891\n",
      "Epoch 3976/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 477.7066 - val_loss: 1508.4092\n",
      "Epoch 3977/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1596.0774 - val_loss: 1094.5320\n",
      "Epoch 3978/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 40ms/step - loss: 2533.9036 - val_loss: 951.7307\n",
      "Epoch 3979/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 2048.0386 - val_loss: 2767.9666\n",
      "Epoch 3980/4000\n",
      "11/11 [==============================] - 1s 38ms/step - loss: 1898.1530 - val_loss: 1733.2584\n",
      "Epoch 3981/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2408.8376 - val_loss: 300.8470\n",
      "Epoch 3982/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 1235.4906 - val_loss: 974.7896\n",
      "Epoch 3983/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1458.7810 - val_loss: 3125.5203\n",
      "Epoch 3984/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2771.8804 - val_loss: 1474.5448\n",
      "Epoch 3985/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 997.4752 - val_loss: 380.0869\n",
      "Epoch 3986/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2072.4678 - val_loss: 2011.0682\n",
      "Epoch 3987/4000\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1424.5577 - val_loss: 1425.8618\n",
      "Epoch 3988/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 1387.4070 - val_loss: 1944.8279\n",
      "Epoch 3989/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 3185.7769 - val_loss: 3365.6174\n",
      "Epoch 3990/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2154.5498 - val_loss: 512.9597\n",
      "Epoch 3991/4000\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 765.6942 - val_loss: 292.8989\n",
      "Epoch 3992/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 410.7941 - val_loss: 187.8966\n",
      "Epoch 3993/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 200.6047 - val_loss: 149.0222\n",
      "Epoch 3994/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 138.0477 - val_loss: 110.1527\n",
      "Epoch 3995/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 102.6512 - val_loss: 97.4587\n",
      "Epoch 3996/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 91.0866 - val_loss: 89.5048\n",
      "Epoch 3997/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 77.5997 - val_loss: 79.5816\n",
      "Epoch 3998/4000\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 76.5210 - val_loss: 78.4272\n",
      "Epoch 3999/4000\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 79.6260 - val_loss: 79.1373\n",
      "Epoch 4000/4000\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 75.7258 - val_loss: 79.6709\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit(train_ds, \n",
    "                    epochs=4000, \n",
    "                    validation_data=val_ds,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5efe823",
   "metadata": {},
   "source": [
    "### training results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9fe1521c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k, hist in history.history.items():\n",
    "    plt.plot(hist[15:])\n",
    "    plt.title(k)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a0a2d100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597/597 [==============================] - 2s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "test_predict_res = model.predict(test_ds)\n",
    "# model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "34bcf939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.66797546e+02],\n",
       "       [-1.50347705e+03],\n",
       "       [-3.08711151e+02],\n",
       "       [-6.59434875e+02],\n",
       "       [ 9.49560840e+03],\n",
       "       [ 5.64296631e+03],\n",
       "       [ 1.17176182e+04],\n",
       "       [ 4.27723572e+02],\n",
       "       [-3.32856958e+03],\n",
       "       [-3.00245972e+03],\n",
       "       [-2.07801001e+03],\n",
       "       [-9.43347961e+02],\n",
       "       [-5.22696960e+02],\n",
       "       [-2.95577710e+03],\n",
       "       [-1.56130835e+03],\n",
       "       [ 5.43119336e+03],\n",
       "       [ 3.13067413e+02],\n",
       "       [-2.96751685e+03],\n",
       "       [-2.23275439e+03],\n",
       "       [ 7.23586670e+02],\n",
       "       [-8.59619751e+02],\n",
       "       [ 2.48014206e+02],\n",
       "       [ 1.30134219e+04],\n",
       "       [-3.25576074e+03],\n",
       "       [-3.12867310e+03],\n",
       "       [-1.62136035e+03],\n",
       "       [ 1.10480068e+04],\n",
       "       [-3.02770850e+03],\n",
       "       [ 9.07105938e+04],\n",
       "       [ 9.59811523e+03],\n",
       "       [ 2.39013770e+04],\n",
       "       [ 4.48011055e+04],\n",
       "       [-2.07072949e+03],\n",
       "       [-2.18536560e+02],\n",
       "       [-1.16559290e+03],\n",
       "       [-1.94543640e+03],\n",
       "       [ 9.90483765e+02],\n",
       "       [ 3.47539990e+03],\n",
       "       [-1.01504205e+03],\n",
       "       [-2.61677979e+03],\n",
       "       [-1.72845566e+02],\n",
       "       [-6.25528984e+01],\n",
       "       [ 2.20265796e+03],\n",
       "       [-8.17801025e+02],\n",
       "       [ 1.41456921e+03],\n",
       "       [ 1.19008271e+04],\n",
       "       [ 3.46155835e+03],\n",
       "       [-3.70450366e+03],\n",
       "       [-3.11857471e+03],\n",
       "       [ 3.08549463e+03],\n",
       "       [ 9.53627344e+03],\n",
       "       [-3.87365082e+02],\n",
       "       [ 8.10817578e+03],\n",
       "       [ 1.33999004e+04],\n",
       "       [ 2.61801709e+03],\n",
       "       [-5.98556824e+02],\n",
       "       [ 4.10694611e+02],\n",
       "       [-3.47775146e+02],\n",
       "       [-2.92534229e+03],\n",
       "       [-1.33832751e+03],\n",
       "       [ 1.13542310e+03],\n",
       "       [-8.52446899e+02],\n",
       "       [ 1.70597266e+03],\n",
       "       [-4.32529102e+03],\n",
       "       [-1.41964294e+03],\n",
       "       [ 6.21875635e+03],\n",
       "       [ 3.99653125e+03],\n",
       "       [ 2.36823218e+03],\n",
       "       [-1.18746094e+03],\n",
       "       [-3.71451294e+03],\n",
       "       [-2.72939600e+03],\n",
       "       [-1.20169653e+03],\n",
       "       [-1.00129376e+03],\n",
       "       [-2.90789111e+03],\n",
       "       [-7.66205627e+02],\n",
       "       [-1.30352258e+03],\n",
       "       [-3.44687378e+03],\n",
       "       [-1.75666833e+03],\n",
       "       [-2.97590015e+03],\n",
       "       [ 1.85484241e+03],\n",
       "       [-9.73417603e+02],\n",
       "       [ 7.04867188e+03],\n",
       "       [-2.74108374e+03],\n",
       "       [-7.21225220e+02],\n",
       "       [ 1.44149941e+04],\n",
       "       [ 4.29579883e+03],\n",
       "       [-1.12423755e+03],\n",
       "       [ 2.40868555e+04],\n",
       "       [-3.29987946e+02],\n",
       "       [ 3.99473242e+04],\n",
       "       [ 1.19322156e+03],\n",
       "       [ 9.78610059e+03],\n",
       "       [-1.87308862e+03],\n",
       "       [-3.04643311e+03],\n",
       "       [ 1.08490295e+03],\n",
       "       [ 2.45500059e+04],\n",
       "       [ 2.30468926e+04],\n",
       "       [ 7.18110498e+03],\n",
       "       [-4.18204150e+03],\n",
       "       [ 2.30521191e+03],\n",
       "       [ 1.92600146e+03],\n",
       "       [ 1.20116943e+03],\n",
       "       [-4.59189301e+02],\n",
       "       [ 3.91281323e+03],\n",
       "       [-3.51776953e+03],\n",
       "       [-2.47503589e+03],\n",
       "       [-3.21351636e+03],\n",
       "       [ 2.30687012e+04],\n",
       "       [ 6.11569580e+02],\n",
       "       [-4.18336945e+02],\n",
       "       [ 1.99196328e+04],\n",
       "       [ 1.39338232e+04],\n",
       "       [-1.37499683e+03],\n",
       "       [-1.75248425e+03],\n",
       "       [ 6.44634949e+02],\n",
       "       [-2.15749683e+03],\n",
       "       [-3.25609277e+03],\n",
       "       [ 1.76555847e+03],\n",
       "       [-2.93355640e+03],\n",
       "       [-4.93184601e+02],\n",
       "       [ 8.22631055e+03],\n",
       "       [-1.40264819e+03],\n",
       "       [ 2.20442334e+03],\n",
       "       [ 7.80452454e+02],\n",
       "       [ 7.22649365e+03],\n",
       "       [ 2.11515508e+04],\n",
       "       [-3.09747095e+03],\n",
       "       [-4.27406201e+03],\n",
       "       [ 5.75980949e+01],\n",
       "       [-6.47340332e+02],\n",
       "       [ 6.23277832e+03],\n",
       "       [-8.99606506e+02],\n",
       "       [-9.71019775e+02],\n",
       "       [-1.96272192e+03],\n",
       "       [-3.10674469e+02],\n",
       "       [ 1.66177661e+03],\n",
       "       [ 9.28956680e+01],\n",
       "       [ 5.44400098e+03],\n",
       "       [-2.01193250e+03],\n",
       "       [ 3.72064429e+03],\n",
       "       [-7.62564697e+02],\n",
       "       [-2.26188574e+03],\n",
       "       [-3.15298193e+03],\n",
       "       [ 6.71037158e+03],\n",
       "       [-1.54043713e+03],\n",
       "       [ 3.79269360e+03],\n",
       "       [-1.02109131e+03],\n",
       "       [-1.66397290e+03],\n",
       "       [ 1.65048181e+03],\n",
       "       [-8.12260925e+02],\n",
       "       [ 1.59111560e+03],\n",
       "       [ 1.49123369e+04],\n",
       "       [-3.54392847e+03],\n",
       "       [ 2.82632031e+03],\n",
       "       [ 4.65535010e+03],\n",
       "       [ 1.77318203e+04],\n",
       "       [-2.71611670e+03],\n",
       "       [ 3.42454614e+03],\n",
       "       [-4.18748193e+03],\n",
       "       [ 3.51190356e+03],\n",
       "       [-1.96788391e+03],\n",
       "       [-2.22121997e+03],\n",
       "       [-7.30223938e+02],\n",
       "       [ 2.62393594e+04],\n",
       "       [-1.41964246e+03],\n",
       "       [ 5.06016504e+03],\n",
       "       [ 5.20785391e+04],\n",
       "       [-3.25060181e+03],\n",
       "       [-3.81701538e+02],\n",
       "       [ 1.96740930e+03],\n",
       "       [ 1.83535425e+03],\n",
       "       [ 3.26892358e+03],\n",
       "       [ 2.75342949e+04],\n",
       "       [-4.47185498e+03],\n",
       "       [-2.79494800e+03],\n",
       "       [ 1.39301868e+03],\n",
       "       [-3.02573804e+03],\n",
       "       [-8.90893433e+02],\n",
       "       [ 1.09700967e+04],\n",
       "       [-2.48980859e+03],\n",
       "       [-9.97016830e+01],\n",
       "       [-2.78846289e+03],\n",
       "       [-1.39978882e+03],\n",
       "       [ 3.73175598e+02],\n",
       "       [-2.39216113e+03],\n",
       "       [-6.17250000e+02],\n",
       "       [ 4.54093811e+02],\n",
       "       [-9.89099121e+02],\n",
       "       [-4.26911182e+03],\n",
       "       [-2.42740869e+03],\n",
       "       [-5.17198059e+02],\n",
       "       [ 1.00236172e+04],\n",
       "       [ 1.23213730e+02],\n",
       "       [-2.61643408e+03],\n",
       "       [ 2.24497510e+03],\n",
       "       [ 2.33565161e+03],\n",
       "       [-3.01471216e+03],\n",
       "       [ 1.10698865e+03],\n",
       "       [ 1.45761162e+04],\n",
       "       [ 2.97266748e+03],\n",
       "       [-3.25060303e+03],\n",
       "       [ 3.50212891e+04],\n",
       "       [ 8.42707910e+03],\n",
       "       [-2.13485059e+03],\n",
       "       [-4.30839209e+03],\n",
       "       [-1.00060431e+03],\n",
       "       [ 7.40604199e+03],\n",
       "       [-3.37905688e+03],\n",
       "       [-8.46859131e+02],\n",
       "       [-1.45634570e+03],\n",
       "       [-3.46682617e+03],\n",
       "       [ 6.62422656e+03],\n",
       "       [-1.63335983e+02],\n",
       "       [-5.18308830e+01],\n",
       "       [ 6.85739502e+03],\n",
       "       [-4.27327686e+03],\n",
       "       [ 1.38267578e+04],\n",
       "       [ 1.95858086e+04],\n",
       "       [ 4.58636377e+03],\n",
       "       [-1.10158485e+02],\n",
       "       [ 1.93934102e+04],\n",
       "       [ 3.29318823e+03],\n",
       "       [-9.03333008e+02],\n",
       "       [ 1.40685352e+04],\n",
       "       [ 4.90660986e+03],\n",
       "       [-8.91849426e+02],\n",
       "       [ 1.23394961e+04],\n",
       "       [-3.00911157e+03],\n",
       "       [-8.74552856e+02],\n",
       "       [ 1.93504907e+03],\n",
       "       [-1.64788574e+03],\n",
       "       [ 2.88463501e+03],\n",
       "       [-2.96020654e+03],\n",
       "       [-3.00209465e+01],\n",
       "       [ 3.65469434e+03],\n",
       "       [-2.85295581e+03],\n",
       "       [ 1.00297571e+03],\n",
       "       [ 6.90471533e+03],\n",
       "       [ 4.05017798e+03],\n",
       "       [-9.77837952e+02],\n",
       "       [ 9.32576172e+03],\n",
       "       [-3.52026794e+02],\n",
       "       [-1.99159229e+03],\n",
       "       [-4.30816455e+03],\n",
       "       [ 4.36979199e+03],\n",
       "       [-1.38352136e+03],\n",
       "       [ 2.68203984e+04],\n",
       "       [ 6.91332959e+03],\n",
       "       [-2.59517365e+02],\n",
       "       [-1.80207245e+02],\n",
       "       [-6.30329895e+02],\n",
       "       [ 4.10694611e+02],\n",
       "       [-7.61870422e+02],\n",
       "       [ 1.11603638e+03],\n",
       "       [ 1.11225684e+04],\n",
       "       [-3.35013501e+03],\n",
       "       [-1.91828882e+03],\n",
       "       [ 7.89152783e+03],\n",
       "       [ 9.23003516e+03],\n",
       "       [-3.93117407e+03],\n",
       "       [ 1.75075742e+04],\n",
       "       [-1.46690283e+03],\n",
       "       [ 1.59645837e+03],\n",
       "       [ 1.02976465e+04],\n",
       "       [-2.24606323e+03],\n",
       "       [-6.07760864e+02],\n",
       "       [ 1.08994824e+04],\n",
       "       [ 2.19020801e+04],\n",
       "       [ 8.24165625e+03],\n",
       "       [ 2.31729346e+03],\n",
       "       [-4.68626709e+02],\n",
       "       [-2.92961035e+03],\n",
       "       [ 2.24162939e+03],\n",
       "       [ 1.75068640e+03],\n",
       "       [ 4.66980518e+03],\n",
       "       [ 3.56578516e+03],\n",
       "       [-7.37144470e+02],\n",
       "       [ 5.89356384e+02],\n",
       "       [ 3.71436011e+03],\n",
       "       [ 3.18761694e+03],\n",
       "       [-3.68315967e+03],\n",
       "       [-2.18636307e+02],\n",
       "       [-3.04984558e+02],\n",
       "       [ 9.36531738e+03],\n",
       "       [-3.61498193e+03],\n",
       "       [ 3.03213110e+03],\n",
       "       [ 9.54143945e+03],\n",
       "       [-1.20474500e+03],\n",
       "       [-2.16567535e+02],\n",
       "       [ 3.21515747e+02],\n",
       "       [ 5.05145557e+03],\n",
       "       [ 3.09732202e+03],\n",
       "       [-1.96193604e+03],\n",
       "       [ 1.59372246e+04],\n",
       "       [-8.33614807e+01],\n",
       "       [ 2.31048096e+03],\n",
       "       [-8.26129822e+02],\n",
       "       [ 8.82331299e+02],\n",
       "       [-2.83034717e+03],\n",
       "       [ 7.78124707e+03],\n",
       "       [-3.08670435e+03],\n",
       "       [-2.27855664e+03],\n",
       "       [ 4.20400488e+03],\n",
       "       [-4.12304688e+03],\n",
       "       [ 1.60431064e+04],\n",
       "       [-2.72942822e+03],\n",
       "       [-3.08201123e+03],\n",
       "       [ 2.54039395e+04],\n",
       "       [-8.57475037e+02],\n",
       "       [ 5.58663379e+03],\n",
       "       [ 8.74128125e+03],\n",
       "       [-4.37033966e+02],\n",
       "       [ 1.29667998e+04],\n",
       "       [-2.05757666e+03],\n",
       "       [ 1.24370254e+04],\n",
       "       [-4.55233124e+02],\n",
       "       [-3.16176855e+03],\n",
       "       [ 7.75947656e+03],\n",
       "       [-3.83932080e+03],\n",
       "       [-3.23090759e+02],\n",
       "       [ 2.63364590e+04],\n",
       "       [-9.84017761e+02],\n",
       "       [ 1.14401953e+04],\n",
       "       [-1.10630066e+03],\n",
       "       [ 1.34136006e+04],\n",
       "       [ 4.23088574e+03],\n",
       "       [ 8.18924023e+03],\n",
       "       [ 1.94190201e+02],\n",
       "       [-4.48370819e+02],\n",
       "       [ 1.13322441e+04],\n",
       "       [-5.36875244e+02],\n",
       "       [-1.25530066e+03],\n",
       "       [-2.64947241e+03],\n",
       "       [-3.09676880e+02],\n",
       "       [ 2.60138184e+03],\n",
       "       [-3.45146851e+02],\n",
       "       [ 6.39080566e+03],\n",
       "       [-8.19109558e+02],\n",
       "       [ 1.23893389e+04],\n",
       "       [ 1.86120557e+03],\n",
       "       [ 4.26292188e+03],\n",
       "       [ 6.45709375e+03],\n",
       "       [ 2.28361855e+04],\n",
       "       [ 2.96788940e+03],\n",
       "       [ 8.11448730e+03],\n",
       "       [ 1.47363018e+04],\n",
       "       [ 1.79412610e+03],\n",
       "       [ 6.07612158e+03],\n",
       "       [ 1.49827148e+03],\n",
       "       [-9.78739502e+02],\n",
       "       [ 2.20622715e+04],\n",
       "       [ 6.36184180e+03],\n",
       "       [ 1.54075378e+03],\n",
       "       [-2.21014380e+03],\n",
       "       [ 5.54608838e+03],\n",
       "       [-3.35573950e+03],\n",
       "       [ 4.60940137e+03],\n",
       "       [ 3.77377656e+04],\n",
       "       [-2.12703540e+03],\n",
       "       [-1.82461633e+03],\n",
       "       [ 4.73296211e+04],\n",
       "       [-1.77460034e+03],\n",
       "       [-3.77878540e+03],\n",
       "       [-6.83816833e+01],\n",
       "       [-3.92638403e+03],\n",
       "       [ 1.89012048e+03],\n",
       "       [ 4.20912842e+02],\n",
       "       [ 1.54810669e+03],\n",
       "       [-5.22776978e+02],\n",
       "       [-2.63107617e+03],\n",
       "       [ 9.77584381e+01],\n",
       "       [-3.17607129e+03],\n",
       "       [-1.47469971e+03],\n",
       "       [ 1.20415791e+04],\n",
       "       [ 9.66343117e+00],\n",
       "       [ 9.33072656e+03],\n",
       "       [-2.76319971e+03],\n",
       "       [-8.85774414e+02],\n",
       "       [-4.39402930e+03],\n",
       "       [ 1.84343418e+04],\n",
       "       [ 3.12613359e+04],\n",
       "       [ 1.78972571e+03],\n",
       "       [ 1.52760410e+04],\n",
       "       [-2.84388672e+03],\n",
       "       [-2.27758194e+02],\n",
       "       [ 6.11554639e+03],\n",
       "       [-2.92534668e+03],\n",
       "       [-1.26153992e+03],\n",
       "       [-3.48661621e+03],\n",
       "       [ 2.38245532e+03],\n",
       "       [ 1.87373848e+04],\n",
       "       [ 3.97605493e+03],\n",
       "       [ 5.16673193e+03],\n",
       "       [ 5.18115039e+03],\n",
       "       [ 1.81067200e+03],\n",
       "       [-4.62518262e+03],\n",
       "       [-1.32904785e+03],\n",
       "       [ 8.61092285e+03],\n",
       "       [-3.44670288e+03],\n",
       "       [-2.22406494e+03],\n",
       "       [-1.00526074e+03],\n",
       "       [-4.36125061e+02],\n",
       "       [-2.18257593e+03],\n",
       "       [-2.02470691e+03],\n",
       "       [ 7.36660986e+03],\n",
       "       [ 1.82385078e+04],\n",
       "       [ 2.33096895e+04],\n",
       "       [ 1.82623965e+04],\n",
       "       [-1.78541553e+03],\n",
       "       [-7.97460876e+02],\n",
       "       [-3.60544238e+03],\n",
       "       [ 1.54603916e+04],\n",
       "       [-4.90808203e+03],\n",
       "       [-3.83144287e+03],\n",
       "       [-1.71851135e+03],\n",
       "       [ 3.59034492e+04],\n",
       "       [-1.28789734e+03],\n",
       "       [-1.42371729e+03],\n",
       "       [-1.25797900e+03],\n",
       "       [-3.50808691e+03],\n",
       "       [-2.78557202e+03],\n",
       "       [-2.76310425e+03],\n",
       "       [-1.43155371e+03],\n",
       "       [ 3.23159375e+03],\n",
       "       [ 1.62550488e+04],\n",
       "       [-8.13055298e+02],\n",
       "       [-2.88734033e+03],\n",
       "       [-1.66567432e+03],\n",
       "       [ 1.55618496e+04],\n",
       "       [ 7.13161484e+04],\n",
       "       [-9.30388550e+02],\n",
       "       [ 5.54991162e+03],\n",
       "       [ 3.07841089e+03],\n",
       "       [-2.62497485e+03],\n",
       "       [-3.82617139e+03],\n",
       "       [-1.65211304e+02],\n",
       "       [ 1.76311250e+04],\n",
       "       [-1.25573450e+03],\n",
       "       [-1.50679077e+03],\n",
       "       [ 1.96141445e+04],\n",
       "       [-2.42601733e+03],\n",
       "       [ 3.28553633e+04],\n",
       "       [ 1.16193623e+04],\n",
       "       [-1.67079065e+03],\n",
       "       [-2.60753003e+03],\n",
       "       [-4.40609711e+02],\n",
       "       [-3.24336353e+03],\n",
       "       [ 7.07424365e+03],\n",
       "       [ 1.45502002e+03],\n",
       "       [-1.20967944e+03],\n",
       "       [-8.45992493e+02],\n",
       "       [-1.17115662e+03],\n",
       "       [ 3.63915430e+03],\n",
       "       [ 9.10694043e+03],\n",
       "       [ 4.84761211e+04],\n",
       "       [ 4.13644492e+04],\n",
       "       [-2.45939087e+03],\n",
       "       [ 1.19066736e+03],\n",
       "       [ 1.22676379e+03],\n",
       "       [ 1.85957703e+03],\n",
       "       [-2.07111572e+03],\n",
       "       [-1.05011707e+03],\n",
       "       [-3.74711816e+03],\n",
       "       [-1.36167200e+03],\n",
       "       [-6.96310913e+02],\n",
       "       [ 3.69080078e+03],\n",
       "       [-8.12050476e+02],\n",
       "       [-2.75565503e+03],\n",
       "       [ 1.14493701e+04],\n",
       "       [ 2.15128984e+04],\n",
       "       [-3.17262402e+03],\n",
       "       [-1.88233545e+03],\n",
       "       [-4.45135010e+02],\n",
       "       [ 1.66242871e+03],\n",
       "       [ 8.23688965e+03],\n",
       "       [ 2.90644116e+03],\n",
       "       [-1.55446375e+03],\n",
       "       [-4.63793457e+03],\n",
       "       [-1.34521912e+03],\n",
       "       [ 1.99116289e+04],\n",
       "       [ 3.34930591e+03],\n",
       "       [ 6.11129150e+03],\n",
       "       [ 3.28773389e+03],\n",
       "       [-3.14763379e+03],\n",
       "       [-3.19914990e+03],\n",
       "       [ 5.27939502e+03],\n",
       "       [ 2.07660078e+04],\n",
       "       [-1.60871716e+03],\n",
       "       [-2.90090820e+03],\n",
       "       [ 1.46627917e+03],\n",
       "       [-3.13177246e+03],\n",
       "       [ 8.86884961e+03],\n",
       "       [-4.56060449e+03],\n",
       "       [ 8.65787988e+03],\n",
       "       [ 4.51673828e+04],\n",
       "       [ 5.06413965e+03],\n",
       "       [-1.43472253e+03],\n",
       "       [-3.65488892e+03],\n",
       "       [-2.48046753e+03],\n",
       "       [-2.77752686e+03],\n",
       "       [-6.37524681e+01],\n",
       "       [-1.82892212e+03],\n",
       "       [ 1.62671838e+03],\n",
       "       [-1.04662891e+03],\n",
       "       [-2.22495020e+03],\n",
       "       [-3.05378711e+03],\n",
       "       [ 1.16547500e+04],\n",
       "       [-3.31302979e+03],\n",
       "       [ 1.99031482e+03],\n",
       "       [-3.28800415e+03],\n",
       "       [ 5.93870215e+03],\n",
       "       [-4.19501648e+02],\n",
       "       [-2.68732910e+03],\n",
       "       [-1.08967908e+03],\n",
       "       [ 2.61004272e+03],\n",
       "       [-1.57917200e+03],\n",
       "       [-1.50581177e+03],\n",
       "       [-3.46711639e+02],\n",
       "       [ 2.40185425e+03],\n",
       "       [-3.65500732e+03],\n",
       "       [-1.57811194e+03],\n",
       "       [-2.38035107e+03],\n",
       "       [-1.07517700e+03],\n",
       "       [ 3.23836060e+03],\n",
       "       [-4.70467621e+02],\n",
       "       [-3.98369434e+03],\n",
       "       [-1.56109741e+03],\n",
       "       [-2.20872217e+03],\n",
       "       [-5.87106079e+02],\n",
       "       [-3.66300879e+03],\n",
       "       [-2.42124908e+02],\n",
       "       [ 7.04375586e+03],\n",
       "       [-1.97113571e+02],\n",
       "       [ 4.40838043e+02],\n",
       "       [-2.10707373e+03],\n",
       "       [ 1.42912830e+03],\n",
       "       [-1.33294568e+03],\n",
       "       [-1.81434314e+03],\n",
       "       [-2.59364807e+02],\n",
       "       [-1.25246924e+03],\n",
       "       [-1.65837256e+03],\n",
       "       [-3.11897046e+03],\n",
       "       [ 2.06428003e+03],\n",
       "       [-7.79653931e+02],\n",
       "       [-1.79122449e+03],\n",
       "       [-1.63722961e+03],\n",
       "       [-1.08721460e+03],\n",
       "       [-3.18098145e+03],\n",
       "       [ 3.05770898e+03],\n",
       "       [-3.89788257e+03],\n",
       "       [-2.20774902e+03],\n",
       "       [ 2.87269336e+03],\n",
       "       [-1.02218573e+03],\n",
       "       [ 2.38588818e+03],\n",
       "       [-2.14144800e+03],\n",
       "       [ 2.52935107e+03],\n",
       "       [-1.34977649e+03],\n",
       "       [ 5.57611694e+02],\n",
       "       [-1.58428711e+03],\n",
       "       [-2.98071729e+03],\n",
       "       [-5.64573547e+02],\n",
       "       [ 3.67512109e+04],\n",
       "       [ 1.18330732e+04],\n",
       "       [-4.49133154e+03],\n",
       "       [ 9.10379492e+03],\n",
       "       [-3.23016504e+03],\n",
       "       [-2.30169727e+03],\n",
       "       [ 2.19020801e+04],\n",
       "       [-3.17078662e+03],\n",
       "       [-7.43145020e+02],\n",
       "       [-5.93668579e+02],\n",
       "       [-3.08123438e+03],\n",
       "       [-8.71479736e+02],\n",
       "       [-2.96725684e+03],\n",
       "       [-3.27269238e+03],\n",
       "       [ 3.90154126e+03],\n",
       "       [-2.78396069e+03],\n",
       "       [ 1.34136006e+04],\n",
       "       [ 5.07352197e+03],\n",
       "       [-3.26720923e+03],\n",
       "       [ 3.17354468e+03],\n",
       "       [-1.24500452e+03],\n",
       "       [ 6.25178467e+03],\n",
       "       [-3.29598730e+03],\n",
       "       [ 1.04710947e+04],\n",
       "       [ 1.96008184e+04],\n",
       "       [-1.81178101e+03],\n",
       "       [ 1.08490295e+03],\n",
       "       [-6.10437805e+02],\n",
       "       [-1.42721765e+03],\n",
       "       [ 1.19066736e+03],\n",
       "       [ 2.46064673e+03],\n",
       "       [ 1.06832441e+04],\n",
       "       [ 1.60262207e+04],\n",
       "       [ 8.59970410e+03],\n",
       "       [ 8.38157129e+03],\n",
       "       [-2.11242627e+03]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "31759c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_res(pred_res, thres=0.5, from_logits=False):\n",
    "    res = []\n",
    "    for y_pred in pred_res:\n",
    "        prob = y_pred if not from_logits else tf.nn.sigmoid(y_pred)\n",
    "#         print(y_pred, tf.nn.sigmoid(y_pred))\n",
    "        res.append( 1 if prob >= thres else 0)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f046d919",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_test_p_res = binarize_res(test_predict_res, thres=0.5, from_logits=False)\n",
    "# len(binary_test_p_res), binary_test_p_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d998dbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds_2 = tf.data.TFRecordDataset(filenames=[test_fp])\n",
    "test_ds_2 = test_ds_2.map(encode_fn)\n",
    "# label fetch model:\n",
    "preproc_input_2 = tf.keras.layers.Input(type_spec=preproc_input_spec)\n",
    "graph, labels = split_fn(preproc_input_2) # See section \"Splitting the label off ...\".\n",
    "label_fetch_model = tf.keras.Model(preproc_input_2,  labels, )\n",
    "# fetch\n",
    "test_labels = test_ds_2.map(label_fetch_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0e03fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([e[0] for e in test_labels.as_numpy_iterator()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8954ddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_pred, y_true):\n",
    "    l = len(y_pred)\n",
    "    assert len(y_true) == l, 'diff len cannot do'\n",
    "#     print(y_pred, y_true)\n",
    "    return np.mean(y_pred == y_true)\n",
    "\n",
    "def metrics(y_pred, y_true):\n",
    "    acc = compute_accuracy(y_pred, y_true)\n",
    "    tp,tn,fp,fn = 0,0,0,0\n",
    "    \n",
    "    l = len(y_pred)\n",
    "    for i in range(l):\n",
    "        p = y_pred[i]\n",
    "        t = y_true[i]\n",
    "        if p==t:\n",
    "            if p == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "        elif p == 1:\n",
    "            fp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "    return (acc, tp/l, tn/l, fp/l, fn/l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f3609917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9212730318257957,\n",
       " 0.4438860971524288,\n",
       " 0.47738693467336685,\n",
       " 0.01507537688442211,\n",
       " 0.06365159128978225)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics(binary_test_p_res, y_true, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7d251be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGiCAYAAAD9QiyHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHJUlEQVR4nO3de1xUdf4/8Nfch+Eu4KCIi2XeLxgE4eatBSldW/v2LVddQbboylrN7qaUSVYbXUlXbd1Ksq385tZu0v50TZoiN6VsVSqvZV4IlQFUGK4zh5nz+wOYHGZABmcYj76e+5iF85nzOeczb07y4lxloiiKICIiIpIgub8HQERERNRbDDJEREQkWQwyREREJFkMMkRERCRZDDJEREQkWQwyREREJFkMMkRERCRZDDJEREQkWQwyREREJFkMMkRERCRZHgeZ7du3Y9asWRg4cCBkMhk2bdp0wT4lJSW49tprodFoMHToUKxfv74XQyUiIiJy5nGQaWxsxPjx47FmzZoezX/s2DHMnDkT06ZNQ1lZGR566CHcdddd+OijjzweLBEREdH5ZBfz0EiZTIYPPvgAs2fP7nKexYsXY/Pmzdi3b5+j7de//jVqa2uxdevW3q6aiIiICEpfr6C0tBSpqalObenp6XjooYe67GOxWGCxWBzTdrsdZ8+eRUREBGQyma+GSkRERF4kiiLq6+sxcOBAyOW+OS3X50GmsrISer3eqU2v18NsNqO5uRkBAQEuffLz87F8+XJfD42IiIj6wI8//ohBgwb5ZNk+DzK9kZubC4PB4Jiuq6vD4MGDcezYMQQHB3ttPYIg4NNPP8W0adOgUqm8tlzqHuvuH6y7f7Du/sG6+0fnutfX12PIkCFe/d3dmc+DTHR0NEwmk1ObyWRCSEiI270xAKDRaKDRaFza+/Xrh5CQEK+NTRAE6HQ6REREcEPvQ6y7f7Du/sG6+wfr7h+d695Re1+eFuLz+8ikpKTAaDQ6tRUXFyMlJcXXqyYiIqLLnMdBpqGhAWVlZSgrKwPQdnl1WVkZysvLAbQdFsrIyHDMf++99+Lo0aN45JFHcOjQIbzyyiv4+9//jocfftg7n4CIiIiuWB4Hmf/+97+YMGECJkyYAAAwGAyYMGECli1bBgA4ffq0I9QAwJAhQ7B582YUFxdj/PjxeOmll/D6668jPT3dSx+BiIiIrlQenyMzdepUdHfrGXd37Z06dSr27t3r6aqIiIiIusVnLREREZFkMcgQERGRZDHIEBERkWQxyBAREZFkMcgQERGRZDHIEBERkWQxyBAREZFkMcgQERGRZDHIEBERkWQxyBAREZFkefyIAiIiIpK2ltYWnGo4hR/rf0RFQwUq6itwz7h7EKYN8/fQPMYgQ0REdJkRRRFnWs6gor7CKax0vKqaq1z6pMelI14b3/eDvUgMMkRERBJktVlxsuFkW1Cpr3CElR/rf8TJhpNobm3utn+gKhCxwbEYFDQIg4IHIVwb3kcj9y4GGSIiIj+x2W1oEBpgtphhtppRZ62D2Wp2TDu+uvm+XqjvdtkyyBAdGI1BwYMwKGhQW2hp/35Q8CCEacIgk8n66JP6DoMMERFJmmATcLrxtNOeiXJzOY43HMeHxg8hk186v6xFUUS9td4RSBqsDRAh9np5OqXONai0Tw8MGgi1Qu3F0V+aGGSIiOiSJooi6ix1P53n0VDxU2ipr0BlUyXsot1t36Omo3082t4JUAYgRB2CEE1I29eOV/t0qCbUpS1ME3bZ7FW5GAwyREQ+IooiTjWcQnlrOb6u/hpKJf/JvZAmockpsHSElQsdRtEqtM57I3QDcezgMUyInwCFQtFHo78wmUyGQFWgc0hRh0KlUPl7aJLF/6qIiLxAFEWcajyFA2cO4MCZA9hfsx8Hzh5AnaUOAPBq8at+HqH0RQVEuZzn0TEdoY1w2jMhCAK2/LAFN8XdBJWKIeFyxiBDROQhURRxuvH0T6HlzH4cOHMAtZZal3mVciWCEYxAXWDfD1SCNAqN056VjqAyMGggApQB/h4eXYIYZIiIuiGKIiobK50Cy4EzB3DOcs5lXqVMiWvCr8GoiFEYFTEKoyNHIy4wDh9/9DFmzJjBPQNEPsAgQ0RXLLtod7qCxGxpv/zVYm4LL2cP4OCZgzjbctalr0toiRiNa8KvcblKRBCEvvo4VzRRFNEs2GBubkVds4Az9c34vk6GveW1CAxQQ6NUQKuSO31VKWSX9ImyNrsIS6sNFsGOls5fBRssrXZYWn/6/qc2G1oEu6Nv52mXZbV/XZ+VhFEDQ/z9sT3GIENEl4U6Sx1ONZxCraW2y/tudIQUTy99VcqUGBo+tC209Gvb03JN+DXQKDQX7CuKIlrtgKXVDrvM5o2PelkTbCLqmgXUNQltX5sFmFsEmJt/mu78MjcLMDe3wmrrfOWSAqsP7OpyXXIZoFEqoFHJoW3/qlHKoVUpnL5qlAoovHQJtwjAel6waPtqh8VNCBFsvb8suzearK19uj5vuaKDjOIfWUg9+gWUxx730gLVQEAYoA0FtO1fA8I6fd/+Xsf3mlBAzmd3El2IYBdQ2Vjp9vLbioYK1Fu7v6qlOwHKAASrg50ub43QRmBEvxEYHTEaw/oNcwktdruI6noLqupbUFVvQZW5BVVmC6rqLTCZ29o63hdsSvz+y48vtgTUAwq5DKEBKoRolWhpaoRKq3PZc9HBLgLNgg3Ngg3Apb3nTKWQOe1N0ijlULeHrc57mtyFMa3KNahpOs0zJFKa53Fd0UEG9ZUItFYDVn8OQgZoQ1zDTw/+0uvZ4mVAkB4IjwPCfgaE/wwIGwyoeNIcXXrMVvNPz4bpdMv1ysZK2MTu92hEaCMQrg13ud/G+ffmcHc/DjmULrvoGy02VNW3YN8xC4xfn2gPK+3BxWxBTYMFrfa+/Yv5SqFWyBESoEJogLL9q+vr/PYQrQqhurbvA9UKyGSytquWtmzBjBmTnM5NEkURVpu9y0Mv7r62CDZ480fdtpfHzZ4fN6FEq5JDrZBDqeAfvF25ooOMbebL+LykGBMnTvTO/R1aW4CWOqC5FmipPe/7urbp879vqQOEJgBie1sdgPKLH0NPBUW3h5r2cHN+0AmJAeSXzn0XyL9EUURNc43zQ+caKtAoNHpl+TbRhqqmKlTUV8BsNXc7r1quRnRgDKK0AxCujkawMhoBsiiobFGQtUag2SpHS6sNLQ1tf4FXCTb8eP65A46vZ9DSWu2Y7m0gkcmAiEAN+gdr0D9EA32wFv1D2qajgrXQh2jQL0CB0u2fYvr06VCpruh/cntEKZdDq5L77NwVmUzWvtdCAYAnX18Oruz/qqJG4FzgUYgxCYA/riZotfwUYpwCzznA7qVjlfZWwHwaqD0BnDsOnDsBWOuBhsq2149fuvaRK4HQQZ324vysrU1+8XWStbYirPEHyE7uAXiDsD4ja21FaNPxtm0hKBLQhDgOa7a0tuBUw6n2W7v/iBN15fixvgInGypwuvEkLHZLn41TIwuFFlFQ2qOA1n5otYSjuSkMDQ2hqLcE4gzc/WXa0P66eOr2v5Z1agX6B2sdIaW/I6S0BZT+wVpEBqkv+JeyIAgIUALBWiWvWiLygV79FlmzZg1eeOEFVFZWYvz48Vi1ahWSkpLczisIAvLz8/Hmm2/i5MmTGD58OJ577jncdNNNFzXwS02LYEOz1dMT+WSALKztUFLAz3wwqjaBGiXUyvZ/bEWxLSidO+4cbmpPtH8tB+xCe/txn4xHCWAKAHznk8VTJ3YADXIZzHI5whQKbF3/LCpUSlQoVTihUqNCqcQZ5QX++hVlULYGQmYNg80aAYvQHzab946ni63BsAsRsFv7oV7s/tkwMhnaDiU4DjEonQ4xtJ0z0HmX/U8nc7o9d6D9q1ohh/wSei4PEV2Yx0Fm48aNMBgMWLt2LZKTk7FixQqkp6fj8OHD6N+/v8v8S5cuxdtvv43XXnsNI0aMwEcffYRbb70VO3fuxIQJE7zyIXypydrqOIGv49i4qb4F1Z1O6qtrvrRPFAtQKVyOL4cEDEFowLC2tn7t72nkiMRZ9LOeRkjLKQQ2VUBZV94WdMyn2oLQRRIhorm5GQEBAZDBe780RIiwi22HQuwiYBfF9lfbiZl2UYToaHd+X/TC5/IlEUCTDGhQyFAvbwsmDQoZGjq+l8tQr2j7vl7e3q5oa2+UA/Ye7KYPtNsRK7RiUGsrBgmtiG396fsBra0uO+FtbveM9I6s4/80XbS7m7+5/XWJUwK4RRSBMgakvqQEMBNKKL4PBwLCXS+0uNAFGZrgttRMlzyZ6OG/4MnJybjuuuuwevVqAIDdbkdsbCx+97vfYcmSJS7zDxw4EI899hgeeOABR9ttt92GgIAAvP322z1ap9lsRmhoKOrq6hAS4r1r3I+Y6rDpo89w1eh4nG1qdYSS88NKvUWal6N5k1opR2iACsFaJeRe+A9bFEU0NDQgKCjooo+Di6KIFsEOc7PQw5+VCJmiCTLVWcjVZyBXnYVMfRZyVdsL8kvv5y2DHVC0QCZz/1C8nlLK1FDZddAHxaK/JhoDNBGIUYZgsDIQgxUa9Bdt0NjqoRbMUFnrobDWQW7pfM5XHdB+y32iy5pM7hx4lF66AMObZPK2Q8Turoh1F9T6IJz9dJJ12w0gffX7+3we7ZGxWq3YvXs3cnNzHW1yuRypqakoLS1128disUCr1Tq1BQQE4PPPP+9yPRaLBRbLT8fkzea2EwAFQfDqzaUe2LAXh00K4MC33c4XoJKjf7AWUcHq9pP42k/u6/R9kEbpxf0L3mEXRTRabe33WmhFneN+DK3t92ZwbatrFlDf0nZTKbsIWFvtqG6/lNR7ZDA1e+dk0c4C1SICA+sRoKuDSnsOctUZ2BRnYJVVo9FeBUGUwJ/xXVDL1U5X2wSrfrpkuPPlw53b5XY5iouLkZaW1qNzNWztLxd2G2AxAza/Xu4nGYLQiu3bP8PkyVN4sm8fEoRWfF7yMSZdNxaq1kbHOYiyjvMSW+og6wjoTt/XQmazAqK97TB8s+sdnKVKlCnaQ04oxPav0IY5vrdPyGw7N/IidPyO7vzVlzz6r6qmpgY2mw16vd6pXa/X49ChQ277pKeno6CgAJMnT8bVV18No9GIf/7zn7DZuj6fJD8/H8uXL3dp37ZtG3Q6nSdD7laAIEd/rQwhahEhKiBUDZfvQ1WARgHIZJ3+0a5ve9Wh7fV9L9YviiIECGgRW9AsNju9unokvS+oAESo214IPW98AFrtgLX9JdjbGy8pIgRZE5pkZ9GAc6gTz6JOrEMzROejDp3KGSILQbg8HP3k/dBP0c/xvVrW/fkZ/iCHHFqZFgGyAKhk5wUQof3V5Nqnof1/p3DK5b3i4mKfjZW6oApDcenX/h7FlUcThW3fVLZPyAH0a3+1U7e/Ou0okNutUNmaoG5thMrWCJWtCbILXPrvDzLRBpW9GarWJqhsjVDbGqG0NUFta4SqtW3cba9GKMTWts/QfBZoPuv2j+4dZ8JxLnCoV8bW8e9MU5Obf6C8zOd/HqxcuRLZ2dkYMWIEZDIZrr76amRlZaGwsLDLPrm5uTAYDI5ps9mM2NhYTJ8+3au7ptLSBI/+Qu1Oo9CI042nYbaanW953j5dZ61zau/4XrBf2ufWSIIIl4ClVWgRExTjeMUGxTq+Hxg4EFql1u2iLmeC4L3tnXqOdfcP1v0ndgB2obn9ELG5fe9TbfueqDrHnqiU628Hggdc1Lo6173jiIoveRRkIiMjoVAoYDKZnNpNJhOio6Pd9omKisKmTZvQ0tKCM2fOYODAgViyZAmuuuqqLtej0Wig0bgej1SpVD7ZID1dbqPQiINnDjo9QO64+Xiv16+QKVwOB6gUl+9/eKJdhMlkgl6vh8wLV4gEqYIQGxzreEruoKBBiAyIvKSfoeJPvvrviLrHuvsH695OpQJ03e8I8Obdwzrq3he19yjIqNVqJCQkwGg0Yvbs2QDaTvY1Go3Iycnptq9Wq0VMTAwEQcA//vEP3HHHHb0edF9qEppw8OxB7K/ZjwNn20NL3XG3z2cJ1YQiVB3q9s6h53/f+X2dUndF/dJ1nAw2hU8DJiKii+PxoSWDwYDMzEwkJiYiKSkJK1asQGNjI7KysgAAGRkZiImJQX5+PgDgyy+/xMmTJxEfH4+TJ0/iiSeegN1uxyOPPOLdT+IFTUITDp095LSn5VjdMbehJTow2vHwuI6n3/bT9nOzVCIiIvIVj4PMnDlzUF1djWXLlqGyshLx8fHYunWr4wTg8vJyyM97CGJLSwuWLl2Ko0ePIigoCDNmzMBbb72FsLAwr32I3vq6+mvstOxE6c5SHDx3sMvQotfpMTrip8AyKmIUIgIi/DBiIiIiOl+vTvbNycnp8lBSSUmJ0/SUKVNw4MCB3qzG557a9RSONh8Fjv/U1l/X3xFaOr4ytBAREV2aruibGvx8wM+hblRj6sipGNt/LEZFjEJkQKS/h0VEREQ9dEUHmYevfRhbKrdgxliedEpERCRF3ntYChEREVEfY5AhIiIiyWKQISIiIslikCEiIiLJYpAhIiIiyWKQISIiIslikCEiIiLJYpAhIiIiyWKQISIiIslikCEiIiLJYpAhIiIiyWKQISIiIslikCEiIiLJYpAhIiIiyWKQISIiIslikCEiIiLJYpAhIiIiyWKQISIiIslikCEiIiLJYpAhIiIiyWKQISIiIslikCEiIiLJYpAhIiIiyWKQISIiIsnqVZBZs2YN4uLioNVqkZycjF27dnU7/4oVKzB8+HAEBAQgNjYWDz/8MFpaWno1YCIiIqIOHgeZjRs3wmAwIC8vD3v27MH48eORnp6Oqqoqt/Nv2LABS5YsQV5eHg4ePIh169Zh48aNePTRRy968ERERHRl8zjIFBQUIDs7G1lZWRg1ahTWrl0LnU6HwsJCt/Pv3LkTP//5zzFv3jzExcVh+vTpmDt37gX34hARERFdiNKTma1WK3bv3o3c3FxHm1wuR2pqKkpLS932mThxIt5++23s2rULSUlJOHr0KLZs2YIFCxZ0uR6LxQKLxeKYNpvNAABBECAIgidD7lbHsry5TLow1t0/WHf/YN39g3X3j85174v6exRkampqYLPZoNfrndr1ej0OHTrkts+8efNQU1ODG264AaIoorW1Fffee2+3h5by8/OxfPlyl/Zt27ZBp9N5MuQeKS4u9voy6cJYd/9g3f2DdfcP1t0/Oure1NTk83V5FGR6o6SkBM888wxeeeUVJCcn48iRI3jwwQfx1FNP4fHHH3fbJzc3FwaDwTFtNpsRGxuL6dOnIyQkxGtjEwQBxcXFSEtLg0ql8tpyqXusu3+w7v7BuvsH6+4fnevecUTFlzwKMpGRkVAoFDCZTE7tJpMJ0dHRbvs8/vjjWLBgAe666y4AwNixY9HY2Ii7774bjz32GORy19N0NBoNNBqNS7tKpfLJBumr5VL3WHf/YN39g3X3D9bdPzrq3he19+hkX7VajYSEBBiNRkeb3W6H0WhESkqK2z5NTU0uYUWhUAAARFH0dLxEREREDh4fWjIYDMjMzERiYiKSkpKwYsUKNDY2IisrCwCQkZGBmJgY5OfnAwBmzZqFgoICTJgwwXFo6fHHH8esWbMcgYaIiIioNzwOMnPmzEF1dTWWLVuGyspKxMfHY+vWrY4TgMvLy532wCxduhQymQxLly7FyZMnERUVhVmzZuFPf/qT9z4FERERXZF6dbJvTk4OcnJy3L5XUlLivAKlEnl5ecjLy+vNqoiIiIi6xGctERERkWQxyBAREZFkMcgQERGRZDHIEBERkWQxyBAREZFkMcgQERGRZDHIEBERkWQxyBAREZFkMcgQERGRZDHIEBERkWQxyBAREZFkMcgQERGRZDHIEBERkWQxyBAREZFkMcgQERGRZDHIEBERkWQxyBAREZFkMcgQERGRZDHIEBERkWQxyBAREZFkMcgQERGRZDHIEBERkWQxyBAREZFkMcgQERGRZDHIEBERkWQxyBAREZFk9SrIrFmzBnFxcdBqtUhOTsauXbu6nHfq1KmQyWQur5kzZ/Z60ERERERAL4LMxo0bYTAYkJeXhz179mD8+PFIT09HVVWV2/n/+c9/4vTp047Xvn37oFAocPvtt1/04ImIiOjK5nGQKSgoQHZ2NrKysjBq1CisXbsWOp0OhYWFbufv168foqOjHa/i4mLodDoGGSIiIrpoSk9mtlqt2L17N3Jzcx1tcrkcqampKC0t7dEy1q1bh1//+tcIDAzsch6LxQKLxeKYNpvNAABBECAIgidD7lbHsry5TLow1t0/WHf/YN39g3X3j85174v6exRkampqYLPZoNfrndr1ej0OHTp0wf67du3Cvn37sG7dum7ny8/Px/Lly13at23bBp1O58mQe6S4uNjry6QLY939g3X3D9bdP1h3/+ioe1NTk8/X5VGQuVjr1q3D2LFjkZSU1O18ubm5MBgMjmmz2YzY2FhMnz4dISEhXhuPIAgoLi5GWloaVCqV15ZL3WPd/YN19w/W3T9Yd//oXPeOIyq+5FGQiYyMhEKhgMlkcmo3mUyIjo7utm9jYyPeffddPPnkkxdcj0ajgUajcWlXqVQ+2SB9tVzqHuvuH6y7f7Du/sG6+0dH3fui9h6d7KtWq5GQkACj0ehos9vtMBqNSElJ6bbve++9B4vFgt/85je9GykRERFRJx4fWjIYDMjMzERiYiKSkpKwYsUKNDY2IisrCwCQkZGBmJgY5OfnO/Vbt24dZs+ejYiICO+MnIiIiK54HgeZOXPmoLq6GsuWLUNlZSXi4+OxdetWxwnA5eXlkMudd/QcPnwYn3/+ObZt2+adURMRERGhlyf75uTkICcnx+17JSUlLm3Dhw+HKIq9WRURERFRl/isJSIiIpIsBhkiIiKSLAYZIiIikiwGGSIiIpIsBhkiIiKSLAYZIiIikiwGGSIiIpIsBhkiIiKSLAYZIiIikiwGGSIiIpIsBhkiIiKSLAYZIiIikiwGGSIiIpIsBhkiIiKSLAYZIiIikiwGGSIiIpIsBhkiIiKSLAYZIiIikiwGGSIiIpIsBhkiIiKSLAYZIiIikiwGGSIiIpIsBhkiIiKSLAYZIiIikiwGGSIiIpIsBhkiIiKSrF4FmTVr1iAuLg5arRbJycnYtWtXt/PX1tbigQcewIABA6DRaDBs2DBs2bKlVwMmIiIi6qD0tMPGjRthMBiwdu1aJCcnY8WKFUhPT8fhw4fRv39/l/mtVivS0tLQv39/vP/++4iJicGJEycQFhbmjfETERHRFczjIFNQUIDs7GxkZWUBANauXYvNmzejsLAQS5YscZm/sLAQZ8+exc6dO6FSqQAAcXFxFzdqIiIiIngYZKxWK3bv3o3c3FxHm1wuR2pqKkpLS932+fDDD5GSkoIHHngARUVFiIqKwrx587B48WIoFAq3fSwWCywWi2PabDYDAARBgCAIngy5Wx3L8uYy6cJYd/9g3f2DdfcP1t0/Ote9L+rvUZCpqamBzWaDXq93atfr9Th06JDbPkePHsUnn3yC+fPnY8uWLThy5Ajuv/9+CIKAvLw8t33y8/OxfPlyl/Zt27ZBp9N5MuQeKS4u9voy6cJYd/9g3f2DdfcP1t0/Oure1NTk83V5fGjJU3a7Hf3798err74KhUKBhIQEnDx5Ei+88EKXQSY3NxcGg8ExbTabERsbi+nTpyMkJMRrYxMEAcXFxUhLS3Mc9iLfY939g3X3D9bdP1h3/+hc944jKr7kUZCJjIyEQqGAyWRyajeZTIiOjnbbZ8CAAVCpVE6HkUaOHInKykpYrVao1WqXPhqNBhqNxqVdpVL5ZIP01XKpe6y7f7Du/sG6+wfr7h8dde+L2nt0+bVarUZCQgKMRqOjzW63w2g0IiUlxW2fn//85zhy5Ajsdruj7bvvvsOAAQPchhgiIiKinvL4PjIGgwGvvfYa3nzzTRw8eBD33XcfGhsbHVcxZWRkOJ0MfN999+Hs2bN48MEH8d1332Hz5s145pln8MADD3jvUxAREdEVyeNzZObMmYPq6mosW7YMlZWViI+Px9atWx0nAJeXl0Mu/ykfxcbG4qOPPsLDDz+McePGISYmBg8++CAWL17svU9BREREV6Reneybk5ODnJwct++VlJS4tKWkpOCLL77ozaqIiIiIusRnLREREZFkMcgQERGRZDHIEBERkWQxyBAREZFkMcgQERGRZDHIEBERkWQxyBAREZFkMcgQERGRZDHIEBERkWQxyBAREZFkMcgQERGRZDHIEBERkWQxyBAREZFkMcgQERGRZDHIEBERkWQxyBAREZFkMcgQERGRZDHIEBERkWQxyBAREZFkMcgQERGRZDHIEBERkWQxyBAREZFkMcgQERGRZDHIEBERkWQxyBAREZFkMcgQERGRZPUqyKxZswZxcXHQarVITk7Grl27upx3/fr1kMlkTi+tVtvrARMRERF18DjIbNy4EQaDAXl5edizZw/Gjx+P9PR0VFVVddknJCQEp0+fdrxOnDhxUYMmIiIiAgClpx0KCgqQnZ2NrKwsAMDatWuxefNmFBYWYsmSJW77yGQyREdH93gdFosFFovFMW02mwEAgiBAEARPh9yljmV5c5l0Yay7f7Du/sG6+wfr7h+d694X9ZeJoij2dGar1QqdTof3338fs2fPdrRnZmaitrYWRUVFLn3Wr1+Pu+66CzExMbDb7bj22mvxzDPPYPTo0V2u54knnsDy5ctd2jds2ACdTtfT4RIREZEfNTU1Yd68eairq0NISIhP1uHRHpmamhrYbDbo9Xqndr1ej0OHDrntM3z4cBQWFmLcuHGoq6vDiy++iIkTJ2L//v0YNGiQ2z65ubkwGAyOabPZjNjYWEyfPt2rhRAEAcXFxUhLS4NKpfLacql7rLt/sO7+wbr7B+vuH53r3nFExZc8PrTkqZSUFKSkpDimJ06ciJEjR+Kvf/0rnnrqKbd9NBoNNBqNS7tKpfLJBumr5VL3WHf/YN39g3X3D9bdPzrq3he19+hk38jISCgUCphMJqd2k8nU43NgVCoVJkyYgCNHjniyaiIiIiIXHgUZtVqNhIQEGI1GR5vdbofRaHTa69Idm82Gb7/9FgMGDPBspERERESdeHxoyWAwIDMzE4mJiUhKSsKKFSvQ2NjouIopIyMDMTExyM/PBwA8+eSTuP766zF06FDU1tbihRdewIkTJ3DXXXd595MQERHRFcfjIDNnzhxUV1dj2bJlqKysRHx8PLZu3eo4Abi8vBxy+U87es6dO4fs7GxUVlYiPDwcCQkJ2LlzJ0aNGuW9T0FERERXpF6d7JuTk4OcnBy375WUlDhNv/zyy3j55Zd7sxoiIiKibvFZS0RERCRZDDJEREQkWQwyREREJFkMMkRERCRZDDJEREQkWQwyREREJFkMMkRERCRZDDJEREQkWQwyREREJFkMMkRERCRZDDJEREQkWQwyREREJFkMMkRERCRZDDJEREQkWQwyREREJFkMMkRERCRZDDJEREQkWQwyREREJFkMMkRERCRZDDJEREQkWQwyREREJFkMMkRERCRZDDJEREQkWQwyREREJFkMMkRERCRZDDJEREQkWb0KMmvWrEFcXBy0Wi2Sk5Oxa9euHvV79913IZPJMHv27N6sloiIiMiJx0Fm48aNMBgMyMvLw549ezB+/Hikp6ejqqqq237Hjx/HH/7wB0yaNKnXgyUiIiI6n9LTDgUFBcjOzkZWVhYAYO3atdi8eTMKCwuxZMkSt31sNhvmz5+P5cuX4z//+Q9qa2u7XYfFYoHFYnFMm81mAIAgCBAEwdMhd6ljWd5cJl0Y6+4frLt/sO7+wbr7R+e690X9ZaIoij2d2Wq1QqfT4f3333c6PJSZmYna2loUFRW57ZeXl4dvvvkGH3zwARYuXIja2lps2rSpy/U88cQTWL58uUv7hg0boNPpejpcIiIi8qOmpibMmzcPdXV1CAkJ8ck6PNojU1NTA5vNBr1e79Su1+tx6NAht30+//xzrFu3DmVlZT1eT25uLgwGg2PabDYjNjYW06dP92ohBEFAcXEx0tLSoFKpvLZc6h7r7h+su3+w7v7BuvtH57p3HFHxJY8PLXmivr4eCxYswGuvvYbIyMge99NoNNBoNC7tKpXKJxukr5ZL3WPd/YN19w/W3T9Yd//oqHtf1N6jIBMZGQmFQgGTyeTUbjKZEB0d7TL/Dz/8gOPHj2PWrFmONrvd3rZipRKHDx/G1Vdf3ZtxExEREXl21ZJarUZCQgKMRqOjzW63w2g0IiUlxWX+ESNG4Ntvv0VZWZnjdcstt2DatGkoKytDbGzsxX8CIiIiumJ5fGjJYDAgMzMTiYmJSEpKwooVK9DY2Oi4iikjIwMxMTHIz8+HVqvFmDFjnPqHhYUBgEs7ERERkac8DjJz5sxBdXU1li1bhsrKSsTHx2Pr1q2OE4DLy8shl/OGwUREROR7vTrZNycnBzk5OW7fKykp6bbv+vXre7NKIiIiIhfcdUJERESSxSBDREREksUgQ0RERJLFIENERESSxSBDREREksUgQ0RERJLFIENERESSxSBDREREksUgQ0RERJLFIENERESSxSBDREREksUgQ0RERJLFIENERESSxSBDREREksUgQ0RERJLFIENERESSxSBDREREksUgQ0RERJLFIENERESSxSBDREREksUgQ0RERJLFIENERESSxSBDREREksUgQ0RERJLFIENERESSxSBDREREktWrILNmzRrExcVBq9UiOTkZu3bt6nLef/7zn0hMTERYWBgCAwMRHx+Pt956q9cDJiIiIurgcZDZuHEjDAYD8vLysGfPHowfPx7p6emoqqpyO3+/fv3w2GOPobS0FN988w2ysrKQlZWFjz766KIHT0RERFc2pacdCgoKkJ2djaysLADA2rVrsXnzZhQWFmLJkiUu80+dOtVp+sEHH8Sbb76Jzz//HOnp6W7XYbFYYLFYHNNmsxkAIAgCBEHwdMhd6liWN5dJF8a6+wfr7h+su3+w7v7Rue59UX+ZKIpiT2e2Wq3Q6XR4//33MXv2bEd7ZmYmamtrUVRU1G1/URTxySef4JZbbsGmTZuQlpbmdr4nnngCy5cvd2nfsGEDdDpdT4dLREREftTU1IR58+ahrq4OISEhPlmHR3tkampqYLPZoNfrndr1ej0OHTrUZb+6ujrExMTAYrFAoVDglVde6TLEAEBubi4MBoNj2mw2IzY2FtOnT/dqIQRBQHFxMdLS0qBSqby2XOoe6+4frLt/sO7+wbr7R+e6dxxR8SWPDy31RnBwMMrKytDQ0ACj0QiDwYCrrrrK5bBTB41GA41G49KuUql8skH6arnUPdbdP1h3/2Dd/YN194+OuvdF7T0KMpGRkVAoFDCZTE7tJpMJ0dHRXfaTy+UYOnQoACA+Ph4HDx5Efn5+l0GGiIiIqCc8umpJrVYjISEBRqPR0Wa322E0GpGSktLj5djtdqeTeYmIiIh6w+NDSwaDAZmZmUhMTERSUhJWrFiBxsZGx1VMGRkZiImJQX5+PgAgPz8fiYmJuPrqq2GxWLBlyxa89dZb+Mtf/uLdT0JERERXHI+DzJw5c1BdXY1ly5ahsrIS8fHx2Lp1q+ME4PLycsjlP+3oaWxsxP3334+KigoEBARgxIgRePvttzFnzhzvfQoiIiK6IvXqZN+cnBzk5OS4fa+kpMRp+umnn8bTTz/dm9UQERERdYvPWiIiIiLJYpAhIiIiyWKQISIiIslikCEiIiLJYpAhIiIiyWKQISIiIslikCEiIiLJYpAhIiIiyWKQISIiIslikCEiIiLJYpAhIiIiyWKQISIiIslikCEiIiLJYpAhIiIiyWKQISIiIslikCEiIiLJYpAhIiIiyWKQISIiIslikCEiIiLJYpAhIiIiyWKQISIiIslikCEiIiLJYpAhIiIiyWKQISIiIslikCEiIiLJYpAhIiIiyepVkFmzZg3i4uKg1WqRnJyMXbt2dTnva6+9hkmTJiE8PBzh4eFITU3tdn4iIiKinvI4yGzcuBEGgwF5eXnYs2cPxo8fj/T0dFRVVbmdv6SkBHPnzsWnn36K0tJSxMbGYvr06Th58uRFD56IiIiubEpPOxQUFCA7OxtZWVkAgLVr12Lz5s0oLCzEkiVLXOZ/5513nKZff/11/OMf/4DRaERGRobbdVgsFlgsFse02WwGAAiCAEEQ3Pax2+0QBAGiKPb4s7S2tkKpVKKhoQFKpceloG7IZDIolUooFAqX9zp+hl39LMk3WHf/YN39g3X3j85174v6y0QPfvNbrVbodDq8//77mD17tqM9MzMTtbW1KCoquuAy6uvr0b9/f7z33nv45S9/6XaeJ554AsuXL3dp37BhA3Q6nUu7QqFAZGQkVCpVTz8K9QG73Y76+nrU19f7eyhEROQHTU1NmDdvHurq6hASEuKTdXi0G6KmpgY2mw16vd6pXa/X49ChQz1axuLFizFw4ECkpqZ2OU9ubi4MBoNj2mw2Ow5JdS6EKIo4efIkWltbMWDAAMjlPT9aJooiGhsbERgYCJlM1uN+dGGiKKKpqQnV1dUYNmyY0zYjCAKKi4uRlpbG8NmHWHf/YN39g3X3j8517zii4kt9ejzl2WefxbvvvouSkhJotdou59NoNNBoNC7tKpXKZYMUBAEtLS0YOHAggoKCPBpPx+GogIAAjwIQ9UxgYCDkcjmqqqowYMAAl8NM7n6e5Husu3+w7v7BuvtHR937ovYe/faOjIyEQqGAyWRyajeZTIiOju6274svvohnn30W27Ztw7hx4zwfaRdsNhsAQK1We22Z5D0dhwJ5nJqIiHzBoyCjVquRkJAAo9HoaLPb7TAajUhJSemy3/PPP4+nnnoKW7duRWJiYu9H2w0eGro08edCRES+5PGhJYPBgMzMTCQmJiIpKQkrVqxAY2Oj4yqmjIwMxMTEID8/HwDw3HPPYdmyZdiwYQPi4uJQWVkJAAgKCvL4UBARERHR+TwOMnPmzEF1dTWWLVuGyspKxMfHY+vWrY6TOcvLy53ON/nLX/4Cq9WK//3f/3VaTl5eHp544omLGz0RERFd0Xp1sm9OTg5ycnLcvldSUuI0ffz48d6sgoiIiOiCeKkOERERSRaDDBEREUnWZRdkRFFEk7W1x69mq82j+bt7efJ4hK1bt+KGG25AWFgYIiIi8Mtf/hI//PCD4/2JEydi8eLFTn2qq6uhUqmwfft2AMDp06cxc+ZMBAQEYMiQIY4TqlesWNHler/66iukpaUhMjISoaGhmDJlCvbs2eM0T21tLe655x7o9XpotVqMGTMG/+///T/H+zt27MDUqVOh0+kQHh6O9PR0nDt3rsefnYiIyFsuuwcMNQs2jFr2kV/WfeDJdOjUPStpY2MjDAYDxo0bh4aGBixbtgy33norysrKIJfLMX/+fDz//PN49tlnHZcwb9y4EQMHDsSkSZMAtF0hVlNTg5KSEqhUKhgMhi4f3tmhvr4emZmZWLVqFURRxEsvvYQZM2bg+++/R3BwMOx2O26++WbU19fj7bffxtVXX40DBw44bmZXVlaGX/ziF/jtb3+LlStXQqlU4tNPP3Xcz4eIiKgvXXZBRipuu+02p+nCwkJERUXhwIEDGDNmDO644w489NBD+Pzzzx3BZcOGDZg7dy5kMhkOHTqEjz/+GF999ZXj3jyvv/46rrnmmm7Xe+ONNzpNv/rqqwgLC8Nnn32GX/7yl/j444+xa9cuHDx4EMOGDQMAXHXVVY75n3/+eSQmJuKVV15xtI0ePbr3hSAiIroIl12QCVApcODJ9B7Na7fbUW+uR3BIsFceURCgcn3Sc1e+//57LFu2DF9++SVqampgt9sBtF2+PmbMGERFRWH69Ol45513MGnSJBw7dgylpaX461//CgA4fPgwlEolrr32Wscyhw4divDw8G7XazKZsHTpUpSUlKCqqgo2mw1NTU0oLy8H0LbHZdCgQY4Q01lZWRluv/32Hn9OIiIiX7rsgoxMJuvx4R273Y5WtQI6tbLPn7U0a9Ys/OxnP8Nrr72GgQMHwm63Y8yYMbBarY555s+fj0WLFmHVqlXYsGEDxo4di7Fjx17UejMzM3HmzBmsXLkSP/vZz6DRaJCSkuJYb0BAQLf9L/Q+ERFRX7rsTvaVgjNnzuDw4cNYunQpfvGLX2DkyJFuT5b91a9+hZaWFmzduhUbNmzA/PnzHe8NHz4cra2t2Lt3r6PtyJEjFzzpdseOHVi0aBFmzJiB0aNHQ6PRoKamxvH+uHHjUFFRge+++85t/3Hjxjk9ooKIiMifGGT8IDw8HBEREXj11Vdx5MgRfPLJJzAYDC7zBQYGYvbs2Xj88cdx8OBBzJ071/HeiBEjkJqairvvvhu7du3C3r17cffddyMgIKDb5xtdc801eOutt3Dw4EF8+eWXmD9/vtNelilTpmDy5Mm47bbbUFxcjGPHjuHf//43tm7dCgDIzc3FV199hfvvvx/ffPMNDh06hL/85S9OYYiIiKivMMj4gVwux7vvvovdu3djzJgxePjhh/HCCy+4nXf+/Pn4+uuvMWnSJAwePNjpvb/97W/Q6/WYPHkybr31VmRnZyM4OBharbbLda9btw7nzp3DtddeiwULFmDRokXo37+/0zz/+Mc/cN1112Hu3LkYNWoUHnnkEcdVScOGDcO2bdvw9ddfIykpCSkpKSgqKoJSedkdpSQiIgngbx8/SU1NxYEDB5za3N2H5uabb+7y/jQDBgzAli1bHNMVFRWoqqrC0KFDu1zvhAkT8NVXXzm1dX4OVr9+/VBYWNjlMqZMmYIdO3Z0+T4REVFfYZCRsE8++QQNDQ0YO3YsTp8+jUceeQRxcXGYPHmyv4dGRETUJxhkJEwQBDz66KM4evQogoODMXHiRLzzzjtQqVT+HhoREVGfYJCRsPT0dKSn9+yeOURERJcjnuxLREREksUgQ0RERJLFIENERESSxSBDREREksUgQ0RERJLFIENERESSxSBDREREksUg4ydTp07FQw891Ku+n332GWJjY707ICIiIglikJGgoqIizJo1y9/DICIi8rvLL8iIImBt7PlLaPJs/u5eXTzcsbOFCxfis88+w8qVKyGTySCTybB+/XrIZDJs3rwZ48aNg1arxfXXX499+/a59P/www9xyy23AGjbs5OTk4OcnByEhoYiMjISjz/+uNODJs+dO4eMjAyEh4dDp9Ph5ptvxvfff+94/8SJE5g1axbCw8MRGBiI0aNHOz2MkoiI6FJ1+T2iQGgCnhnYo1nlAMK8ue5HTwHqwAvOtnLlSnz33XcYM2YMnnzySQDA/v37AQB//OMfsXLlSkRHR+PRRx/FrFmz8N133zmen7R//35UVVXhxhtvdCzvzTffxJ133oldu3bhv//9L+6++24MHjwY2dnZANqC0/fff48PP/wQISEhWLx4MWbMmIEDBw5ApVLhgQcegNVqxfbt2xEYGIgDBw4gKCjIm5UhIiLyicsvyEhAaGgo1Go1dDodoqOjAQCHDh0CAOTl5SEtLQ1AW0AZNGgQPvjgA9xxxx0A2g4rpaenQ61WO5YXGxuLl19+GTKZDMOHD8e3336Ll19+GdnZ2Y4As2PHDkycOBEA8M477yA2NhabNm3C7bffjvLyctx2220YO3YsAOCqq67qs1oQERFdjF4FmTVr1uCFF15AZWUlxo8fj1WrViEpKcntvPv378eyZcuwe/dunDhxAi+//HKvT3LtEZWubc9ID9jtdpjr6xESHAy53AtH2VS6i15ESkqK4/t+/fph+PDhOHjwoKOtqKgIOTk5Tn2uv/56yGQyp2W89NJLsNlsOHjwIJRKJZKTkx3vR0REOC130aJFuO+++7Bt2zakpqbitttuw7hx4y76sxAREfmax7+9N27cCIPBgLy8POzZswfjx49Heno6qqqq3M7f1NSEq666Cs8++6xj74NPyWRth3d6+lLpPJu/u9d5YcIXTp8+jb1792LmzJleXe5dd92Fo0ePYsGCBfj222+RmJiIVatWeXUdREREvuDxHpmCggJkZ2cjKysLALB27Vps3rwZhYWFWLJkicv81113Ha677joAcPu+OxaLBRaLxTFtNpsBAIIgQBAEp3kFQYAoirDb7bDb7R59lo4TYjv69yWVSoXW1lbHeju+7ty5E4MGDQLQdpLud999h+HDh8Nut6OoqAgTJ05EWFiY03i//PJLp+nS0lJcc801jkNNra2tKC0tdRxaOnPmDA4fPowRI0Y4+sXExODuu+/G3XffjUcffRSvvfYaHnjggYv+nHa7HaIoQhAEKBQKAHD8DDv/LMm3WHf/YN39g3X3j85174v6exRkrFYrdu/ejdzcXEebXC5HamoqSktLvTao/Px8LF++3KV927Zt0OmcD98olUpER0ejoaEBVqu1V+urr6/vVb+LERMTg9LSUuzbtw+BgYFoaGgAACxfvhwBAQGIiorC008/jX79+uHGG2+E2WzGBx98gLS0NEewA4DW1laUl5fjd7/7HRYuXIivv/4aq1evxlNPPQWz2Qy9Xo8ZM2YgOzsbBQUFCAoKwvLlyzFgwABMmzYNZrMZubm5SE1NxdChQ1FbWwuj0YihQ4c6rae3rFYrmpubsX37drS2tjq9V1xcfNHLJ8+x7v7BuvsH6+4fHXVvamry+bo8CjI1NTWw2WzQ6/VO7Xq93nGyqjfk5ubCYDA4ps1mM2JjYzF9+nSEhIQ4zdvS0oIff/wRQUFB0Gq1Hq1HFEXU19cjODjY6RyTvrBkyRJkZWXh+uuvR3NzM9atWwcAeO655/Doo4/i+++/R3x8PP71r38hMjISjY2N2L59O1atWuVUA6VSiQULFsBmsyE1NRUKhQKLFi3CokWLHJ/pb3/7Gx566CHMnTsXVqsVkyZNwpYtWxAREQEAUCgUWLx4MSoqKhASEoL09HQUFBS41Lo3WlpaEBAQgMmTJzt+PoIgoLi4GGlpaY6rscj3WHf/YN39g3X3j85198YfxBdySV61pNFooNFoXNpVKpXLBmmz2SCTySCXyz0+YbfjsEpH/740YsQIp71YJSUlAIDJkye7vXdMcXExhgwZgmHDhrm8p1arsWLFCqxdu9btuiIiIvDWW291OZbVq1d7OPqek8vlkMlkbn927trI91h3/2Dd/YN194+OuvdF7T367R0ZGQmFQgGTyeTUbjKZ+uZE3itYUFAQnnvuOX8Pg4iI6JLiUZBRq9VISEiA0Wh0tNntdhiNRqfLhsn7pk+fzscSEBERdeLxoSWDwYDMzEwkJiYiKSkJK1asQGNjo+MqpoyMDMTExCA/Px9A28meBw4ccHx/8uRJlJWVISgoCEOHDvXiR5G2qVOnOj1WoKc6DkkRERFdiTwOMnPmzEF1dTWWLVuGyspKxMfHY+vWrY4TgMvLy53ONzl16hQmTJjgmH7xxRfx4osvYsqUKfwlTERERBelVyf7djyk0J3O4SQuLq5XexqIiIiILuTye/o1ERERXTEYZIiIiEiyGGSIiIhIshhkiIiISLIYZIiIiEiyGGT8ZOrUqXjooYd61ffNN9/EDTfc4N0BERERSRCDjAQVFRXhlltu8fcwiIiI/O6yCzKiKKJJaOrxq7m12aP5u3v19H45CxcuxGeffYaVK1dCJpNBJpNh/fr1kMlkMBqNSExMhE6nw8SJE3H48GGnvi0tLdi2bZsjyMTFxeGZZ57Bb3/7WwQHB2Pw4MF49dVXnfr8+OOPuOOOOxAWFoZ+/frhV7/6FY4fP+54v7W1FYsWLUJYWBgiIiKwePFiZGZmYvbs2Rf1syAiIvK1S/Lp1xejubUZyRuS/bLuL+d9CZ1Kd8H5Vq5cie+++w5jxozBk08+CQDYv38/AOCxxx7DSy+9hKioKNx777347W9/ix07djj6Go1GxMTEYMSIEY62l156CU899RQeffRRvP/++7jvvvswZcoUDB8+HIIgID09HSkpKfjPf/4DpVKJp59+GjfddBO++eYbqNVqPPfcc3jnnXfwxhtvYOTIkVi5ciU2bdqEadOmeblCRERE3nXZ7ZGRgtDQUKjVauh0OkRHRyM6OhoKhQIA8Kc//QlTpkzBqFGjsGTJEuzcuRMtLS2Ovu4OK82YMQP3338/hg4disWLFyMyMhKffvopAGDjxo2w2+14/fXXMXbsWIwcORJvvPEGysvLHXdhXrVqFXJzc3HrrbdixIgRWL16NcLCwvqkFkRERBfjstsjE6AMwJfzvuzRvHa7HfX19QgODnZ6PtTFrPtijRs3zvH9gAEDAABVVVUYPHgwRFHEv/71L/z973/vso9MJkN0dDSqqqoAAF9//TWOHDmC4OBgpz4tLS344YcfUFdXB5PJhKSkJMd7CoUCCQkJsNvtF/15iIiIfOmyCzIymaxHh3eAtiDTqmyFTqXzSpDxBpVK5fheJpMBgCNQ7Nq1C62trZg4cWKXfTr6dfRpaGhAQkIC3nnnHZd1RUVFeXXsREREfe3S+O19BVKr1bDZbB71KSoqwsyZMx2HoXri2muvxffff4/+/ftj6NChTq/Q0FCEhoZCr9fjq6++cvSx2WzYs2ePR2MjIiLyBwYZP4mLi8OXX36J48ePo6ampkeHcT788EOPL7ueP38+IiMj8atf/Qr/+c9/cOzYMZSUlGDRokWoqKgAAPzud79Dfn4+ioqKcPjwYTz44IM4d+6cY48QERHRpYpBxk/+8Ic/QKFQYNSoUYiKikJ5eXm38//www84cuQI0tPTPVqPTqfD9u3bMXjwYPzP//wPRo4ciTvvvBMtLS0ICQkBACxevBhz585FRkYGUlJSEBQUhPT0dGi12l5/PiIior5w2Z0jIxXDhg1DaWmpU9vChQudpuPj4x33pikoKMCNN96IwMBAp3nOvx9Mh7KyMqfp6OhovPnmm12ORalUYtWqVVi1ahWAtnNyRo4ciTvuuKOHn4aIiMg/GGQkYtCgQcjNzfXJsk+cOIFt27ZhypQpsFgsWL16NY4dO4Z58+b5ZH1ERETewiAjEb7cOyKXy7F+/Xr84Q9/gCiKGDNmDD7++GOMHDnSZ+skIiLyBgYZQmxsrNPdg4mIiKSCJ/sSERGRZF02QaanD2ykvsW7AxMRkS9J/tCSSqWCTCZDdXU1oqKiPLr3id1uh9VqRUtLyyVzZ9/LhSiKsFqtqK6uhlwuh1qt9veQiIjoMiT5IKNQKDBo0CBUVFS4vRS5O6Ioorm5GQEBAbz5m4/odDoMHjyYQZGIiHxC8kEGAIKCgnDNNddAEASP+gmCgO3bt2Py5Mkuzyuii6dQKKBUKhkSiYjIZy6LIAO0/dL05BlEHX1aW1uh1WoZZIiIiCSI+/uJiIhIsnoVZNasWYO4uDhotVokJydj165d3c7/3nvvYcSIEdBqtRg7diy2bNnSq8ESERERnc/jILNx40YYDAbk5eVhz549GD9+PNLT01FVVeV2/p07d2Lu3Lm48847sXfvXsyePRuzZ8/Gvn37LnrwREREdGXz+ByZgoICZGdnIysrCwCwdu1abN68GYWFhViyZInL/CtXrsRNN92EP/7xjwCAp556CsXFxVi9ejXWrl3rdh0WiwUWi8UxXVdXBwA4e/asxyf0dkcQBDQ1NeHMmTM8R6YPse7+wbr7B+vuH6y7f3Sue319PQDf3uvNoyBjtVqxe/dup4cXyuVypKamujzJuUNpaSkMBoNTW3p6OjZt2tTlevLz87F8+XKX9iFDhngyXCIiIroE1NfXIzQ01CfL9ijI1NTUwGazQa/XO7Xr9XocOnTIbZ/Kykq381dWVna5ntzcXKfwY7fbcfbsWURERHj1Ul6z2YzY2Fj8+OOPCAkJ8dpyqXusu3+w7v7BuvsH6+4fnesuiiLq6+sxcOBAn63zkrz8WqPRQKPROLWFhYX5bH0hISHc0P2AdfcP1t0/WHf/YN394/y6+2pPTAePTvaNjIyEQqGAyWRyajeZTIiOjnbbJzo62qP5iYiIiHrKoyCjVquRkJAAo9HoaLPb7TAajUhJSXHbJyUlxWl+ACguLu5yfiIiIqKe8vjQksFgQGZmJhITE5GUlIQVK1agsbHRcRVTRkYGYmJikJ+fDwB48MEHMWXKFLz00kuYOXMm3n33Xfz3v//Fq6++6t1P0gsajQZ5eXkuh7HIt1h3/2Dd/YN19w/W3T/8UXeZ2ItrolavXo0XXngBlZWViI+Px5///GckJycDAKZOnYq4uDisX7/eMf97772HpUuX4vjx47jmmmvw/PPPY8aMGV77EERERHRl6lWQISIiIroU8FlLREREJFkMMkRERCRZDDJEREQkWQwyREREJFlXXJCxWCyIj4+HTCZDWVmZo/348eOQyWQury+++MKp/3vvvYcRI0ZAq9Vi7Nix2LJlSx9/Amnqqu4A8M0332DSpEnQarWIjY3F888/79KfdffMLbfcgsGDB0Or1WLAgAFYsGABTp065Xif27tvXKjuALd3bzt+/DjuvPNODBkyBAEBAbj66quRl5cHq9XqNA+3d+/pSc2BPtzWxSvMokWLxJtvvlkEIO7du9fRfuzYMRGA+PHHH4unT592vKxWq2OeHTt2iAqFQnz++efFAwcOiEuXLhVVKpX47bff+uGTSEtXda+rqxP1er04f/58cd++feL//d//iQEBAeJf//pXxzysu+cKCgrE0tJS8fjx4+KOHTvElJQUMSUlxfE+t3ffuFDdub1737///W9x4cKF4kcffST+8MMPYlFRkdi/f3/x97//vWMebu/e1ZOa9+W2fkUFmS1btogjRowQ9+/f32WQOb+tszvuuEOcOXOmU1tycrJ4zz33+GjEl4fu6v7KK6+I4eHhosVicbQtXrxYHD58uGOadb94RUVFokwmc/zDze29b3SuO7f3vvH888+LQ4YMcUxze/e9zjXvy239ijm0ZDKZkJ2djbfeegs6na7L+W655Rb0798fN9xwAz788EOn90pLS5GamurUlp6ejtLSUp+M+XJwobqXlpZi8uTJUKvVjrb09HQcPnwY586dc8zDuvfe2bNn8c4772DixIlQqVRO73F79x13def23jfq6urQr18/l3Zu777TueZ9ua1fEUFGFEUsXLgQ9957LxITE93OExQUhJdeegnvvfceNm/ejBtuuAGzZ8922tgrKyuh1+ud+un1elRWVvp0/FLVk7p3VdOO97qbh3Xv3uLFixEYGIiIiAiUl5ejqKjI8R63d9/pru7c3n3vyJEjWLVqFe655x5HG7d333JX877c1iUdZJYsWeL2BK7zX4cOHcKqVatQX1+P3NzcLpcVGRkJg8GA5ORkXHfddXj22Wfxm9/8Bi+88EIffiJp8Gbdqed6WvcOf/zjH7F3715s27YNCoUCGRkZENtv5M3tvee8WXfqOU/rDgAnT57ETTfdhNtvvx3Z2dmOdm7vPePNmvcljx8aeSn5/e9/j4ULF3Y7z1VXXYVPPvkEpaWlLg+xSkxMxPz58/Hmm2+67ZucnIzi4mLHdHR0NEwmk9M8JpMJ0dHRvfsAEuXNundVUwCOurLubXpa9w6RkZGIjIzEsGHDMHLkSMTGxuKLL77o8snz3N7d82bdub33nKd1P3XqFKZNm4aJEyf26KHE3N5debPmfbmtSzrIREVFISoq6oLz/fnPf8bTTz/tmD516hTS09OxceNGx8Mu3SkrK8OAAQMc0ykpKTAajXjooYccbcXFxV3+YrhcebPuKSkpeOyxxyAIguM8guLiYgwfPhzh4eGOeVj3ntfdHbvdDqDtMviucHt3z5t15/bec57U/eTJk5g2bRoSEhLwxhtvQC6/8MEGbu+uvFnzPt3We3FysuS5O4N9/fr14oYNG8SDBw+KBw8eFP/0pz+JcrlcLCwsdMyzY8cOUalUii+++KJ48OBBMS8vj5fnecBd3Wtra0W9Xi8uWLBA3Ldvn/juu++KOp3O5RI91r3nvvjiC3HVqlXi3r17xePHj4tGo1GcOHGiePXVV4stLS2iKHJ794We1J3bu/dVVFSIQ4cOFX/xi1+IFRUVTpdXd+D27l09qXlfbusMMu3Wr18vjhw5UtTpdGJISIiYlJQkvvfeey59//73v4vDhg0T1Wq1OHr0aHHz5s19OHJp6+oSyK+//lq84YYbRI1GI8bExIjPPvusS1/Wvee++eYbcdq0aWK/fv1EjUYjxsXFiffee69YUVHhmIfbu/f1pO6iyO3d29544w0RgNtXB27v3tWTmoti323rMlHkWWhEREQkTZK+aomIiIiubAwyREREJFkMMkRERCRZDDJEREQkWQwyREREJFkMMkRERCRZDDJEREQkWQwyREREJFkMMkRERCRZDDJEREQkWQwyREREJFn/HzKyQ2hYR5NgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accs = []\n",
    "tp_rate = []\n",
    "fp_rate = []\n",
    "pos_rate = np.mean(y_true)\n",
    "threses = []\n",
    "\n",
    "arange = np.arange(-45000, -20000, 1000)\n",
    "for i in arange:\n",
    "    thres = i/100\n",
    "    binary_test_p_res = binarize_res(test_predict_res, thres=thres, from_logits=False)\n",
    "    a, tp, tn, fp, fn = metrics(binary_test_p_res, y_true)\n",
    "    accs.append(a)\n",
    "    tp_rate.append(tp/pos_rate)\n",
    "    fp_rate.append(tn/(1-pos_rate))\n",
    "    threses.append(thres)\n",
    "\n",
    "plt.plot(threses, accs, label='avg acc')\n",
    "plt.plot(threses, tp_rate, label='tp/pos')\n",
    "plt.plot(threses, fp_rate, label='tn/neg')\n",
    "\n",
    "plt.yticks(np.arange(0,1.1,0.1))\n",
    "# plt.xticks(np.arange(0,1.1,0.05))\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3fcaa323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9061976549413735,\n",
       " 0.46063651591289784,\n",
       " 0.4455611390284757,\n",
       " 0.04690117252931323,\n",
       " 0.04690117252931323)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_test_p_res = binarize_res(test_predict_res, thres=-350, from_logits=False)\n",
    "metrics(binary_test_p_res, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7a3e7a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9212730318257957,\n",
       " 0.45896147403685095,\n",
       " 0.4623115577889447,\n",
       " 0.03015075376884422,\n",
       " 0.048576214405360134)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_test_p_res = binarize_res(test_predict_res, thres=-250, from_logits=False)\n",
    "metrics(binary_test_p_res, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8291a1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "09e73f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary_test_p_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "59d5be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "agtensor = test_ds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0881504c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 205ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-244.86552]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(agtensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6560c038",
   "metadata": {},
   "source": [
    "## Exporting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10637e9",
   "metadata": {},
   "source": [
    "#### export the whole model: serilizable -> logits/probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "41e165a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=GraphTensorSpec({'context': ContextSpec({'features': {'hidden_state': TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)}, 'sizes': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, None), 'node_sets': {'source': NodeSetSpec({'features': {'hidden_state': TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)}, 'sizes': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, None), 'operate': NodeSetSpec({'features': {'hidden_state': TensorSpec(shape=(None, 9), dtype=tf.float32, name=None)}, 'sizes': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, None)}, 'edge_sets': {'src2op': EdgeSetSpec({'features': {}, 'sizes': TensorSpec(shape=(None,), dtype=tf.int32, name=None), 'adjacency': AdjacencySpec({'#index.0': TensorSpec(shape=(None,), dtype=tf.int32, name=None), '#index.1': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, {'#index.0': 'source', '#index.1': 'operate'})}, TensorShape([]), tf.int32, None), 'op2op': EdgeSetSpec({'features': {}, 'sizes': TensorSpec(shape=(None,), dtype=tf.int32, name=None), 'adjacency': AdjacencySpec({'#index.0': TensorSpec(shape=(None,), dtype=tf.int32, name=None), '#index.1': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, {'#index.0': 'operate', '#index.1': 'operate'})}, TensorShape([]), tf.int32, None)}}, TensorShape([]), tf.int32, None), description=\"created by layer 'model_9'\")\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, context_update_9_layer_call_fn, context_update_9_layer_call_and_return_conditional_losses, context_update_10_layer_call_fn, context_update_10_layer_call_and_return_conditional_losses while saving (showing 5 of 67). These functions will not be directly callable after loading.\n",
      "/home/flink/workspace/yimin/data_explore/lib/python3.8/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:521: UserWarning: Encoding a StructuredValue with type tensorflow_gnn.GraphTensorSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "/home/flink/workspace/yimin/data_explore/lib/python3.8/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:521: UserWarning: Encoding a StructuredValue with type tensorflow_gnn.ContextSpec.v2; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "/home/flink/workspace/yimin/data_explore/lib/python3.8/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:521: UserWarning: Encoding a StructuredValue with type tensorflow_gnn.NodeSetSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "/home/flink/workspace/yimin/data_explore/lib/python3.8/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:521: UserWarning: Encoding a StructuredValue with type tensorflow_gnn.EdgeSetSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "/home/flink/workspace/yimin/data_explore/lib/python3.8/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:521: UserWarning: Encoding a StructuredValue with type tensorflow_gnn.AdjacencySpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./tfgnn_model/exported_keras_model_1_24/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./tfgnn_model/exported_keras_model_1_24/assets\n"
     ]
    }
   ],
   "source": [
    "# Export the combined SavedModel for serving.\n",
    "model_save_path = \"./tfgnn_model/exported_keras_model_1_24\"\n",
    "# first for the pre-processing model\n",
    "serving_input = tf.keras.layers.Input(shape=[],  # The batch dim is implied.\n",
    "                                      dtype=tf.string, name=\"examples\")\n",
    "preproc_input = tfgnn.keras.layers.ParseExample(example_input_spec)(serving_input)\n",
    "serving_model_input, _ = preproc_model(preproc_input)  # Drop labels.\n",
    "print(serving_model_input)\n",
    "# second for the main inference model\n",
    "serving_logits = model(serving_model_input)\n",
    "serving_output = {\n",
    "    \"logits\": tf.keras.layers.Layer(name=\"logits\")(serving_logits),\n",
    "    \"probabilities\": tf.keras.layers.Layer(name=\"probabilities\")(tf.nn.sigmoid(serving_logits))\n",
    "    }\n",
    "# combine them, re-define a new model then exoprt\n",
    "exported_model = tf.keras.Model(serving_input, serving_output)\n",
    "exported_model.save(model_save_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6469d0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow_gnn.graph.graph_tensor.GraphTensor'>\n"
     ]
    }
   ],
   "source": [
    "tmp_sample = 'shit'\n",
    "for sample in train_ds.take(1):\n",
    "    print(type(sample[0]),)\n",
    "    tmp_sample = sample[0]\n",
    "#     print(model.pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a73369",
   "metadata": {},
   "source": [
    "#### export the half-preprocess model directly for graphTensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b8e5b8c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot convert the argument `type_value`: <class 'tensorflow.python.framework.ops.Tensor'> to a TensorFlow DType.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m serving_input \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# The batch dim is implied.\u001b[39;49;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;43;03m#                                       dtype=tfgnn.graph.graph_tensor.GraphTensor, name=\"gtensors\")\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexamples\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m preproc_input \u001b[38;5;241m=\u001b[39m tfgnn\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mParseExample(example_input_spec)(serving_input)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# preproc_input = tfgnn.keras.layers.ParseExample(example_input_spec)(preproc_input)\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/yimin/data_explore/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/workspace/yimin/data_explore/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py:762\u001b[0m, in \u001b[0;36mas_dtype\u001b[0;34m(type_value)\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(type_value, _dtypes\u001b[38;5;241m.\u001b[39mDType):\n\u001b[1;32m    760\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _INTERN_TABLE[type_value\u001b[38;5;241m.\u001b[39mas_datatype_enum]\n\u001b[0;32m--> 762\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert the argument `type_value`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_value\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    763\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto a TensorFlow DType.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert the argument `type_value`: <class 'tensorflow.python.framework.ops.Tensor'> to a TensorFlow DType."
     ]
    }
   ],
   "source": [
    "serving_input = tf.keras.layers.Input(shape=[],  # The batch dim is implied.\n",
    "#                                       dtype=tfgnn.graph.graph_tensor.GraphTensor, name=\"gtensors\")\n",
    "                                      dtype=tf.Tensor, name = 'examples')\n",
    "preproc_input = tfgnn.keras.layers.ParseExample(example_input_spec)(serving_input)\n",
    "# preproc_input = tfgnn.keras.layers.ParseExample(example_input_spec)(preproc_input)\n",
    "serving_model_input, _ = preproc_model(preproc_input)  # Drop labels.\n",
    "print(type(serving_model_input))\n",
    "# second for the main inference model\n",
    "serving_logits = model(serving_model_input)\n",
    "serving_output = {\n",
    "    \"logits\": tf.keras.layers.Layer(name=\"logits\")(serving_logits),\n",
    "    \"probabilities\": tf.keras.layers.Layer(name=\"probabilities\")(tf.nn.sigmoid(serving_logits))\n",
    "    }\n",
    "# combine them, re-define a new model then exoprt\n",
    "exported_model = tf.keras.Model(serving_input, serving_output)\n",
    "# exported_model.save(\"./tfgnn_model/exported_gtensor_keras_model_12_21\", include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76630df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tmp_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74708474",
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized_tmp_sample = tfgnn.write_example(tmp_sample).SerializeToString()\n",
    "# tmp_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80dfe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(serialized_tmp_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cdbd20c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serialized_tmp_sample == b'\\n\\x85T\\n\\xb6\\x01\\n\\x14edges/src2op.#source\\x12\\x9d\\x01\\x1a\\x9a\\x01\\n\\x97\\x01\\x00\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\t\\n\\n\\x0b\\x0c\\r\\r\\x0e\\x0f\\x10\\x11\\x12\\x12\\x13\\x14\\x14\\x15\\x15\\x16\\x17\\x18\\x19\\x1a\\x1a\\x1b\\x1c\\x1c\\x1d\\x1e\\x1f  !\"\"#$$%&\\'\\'()*+,-./01234567789:;<==>?@ABBCDDEFGHIJKLMNOPPQQRSTUVWXYZ[\\\\]^__`abbcdefgghijkklmnopqrstuvwxyz{||}}~\\x7f\\n\\xf7\\x01\\n\\x14edges/src2op.#target\\x12\\xde\\x01\\x1a\\xdb\\x01\\n\\xd8\\x01\\x00\\x03\\x04\\x05\\x08\\t\\n\\r\\x0f\\x12\\x14\\x15\\x17\\x1a\\x1d\\x1e\\x1f!\"%&\\'),-./124578:;<=>?@ABCDEHIKLOPQRSVWZ[\\\\]^_abefghijmpqrstuvwxyz{|}~\\x81\\x01\\x84\\x01\\x85\\x01\\x86\\x01\\x87\\x01\\x88\\x01\\x89\\x01\\x8a\\x01\\x8b\\x01\\x8c\\x01\\x8d\\x01\\x8f\\x01\\x90\\x01\\x91\\x01\\x94\\x01\\x95\\x01\\x96\\x01\\x99\\x01\\x9a\\x01\\x9d\\x01\\x9e\\x01\\x9f\\x01\\xa0\\x01\\xa1\\x01\\xa2\\x01\\xa3\\x01\\xa4\\x01\\xa5\\x01\\xa7\\x01\\xa8\\x01\\xa9\\x01\\xaa\\x01\\xab\\x01\\xac\\x01\\xad\\x01\\xae\\x01\\xaf\\x01\\xb0\\x01\\xb1\\x01\\xb4\\x01\\xb5\\x01\\xb7\\x01\\xb8\\x01\\xba\\x01\\xbb\\x01\\xbc\\x01\\xbd\\x01\\xbe\\x01\\xbf\\x01\\xc0\\x01\\xc3\\x01\\xc6\\x01\\xc7\\x01\\xca\\x01\\xcb\\x01\\xcc\\x01\\xcd\\x01\\xce\\x01\\xcf\\x01\\xd0\\x01\\xd1\\x01\\xd2\\x01\\xd3\\x01\\xd5\\x01\\xd6\\x01\\n\\x9c\\x01\\n\\x11edges/op2op.#size\\x12\\x86\\x01\\x1a\\x83\\x01\\n\\x80\\x01\\x02\\x00\\x00\\x02\\x00\\x00\\x02\\x01\\x02\\x01\\x02\\x02\\x02\\x01\\x01\\x00\\x02\\x00\\x02\\x02\\x01\\x02\\x00\\x01\\x00\\x01\\x02\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x01\\x02\\x02\\x00\\x02\\x01\\x00\\x00\\x02\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x02\\x00\\x00\\x01\\x00\\x02\\x02\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x01\\x00\\x01\\x00\\x02\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x01\\x02\\x00\\x00\\x02\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x01\\x02\\x00\\x01\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x02\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x02\\x00\\x00\\n\\xe1<\\n\\x1anodes/operate.hidden_state\\x12\\xc2<\\x12\\xbf<\\n\\xbc<\\xder\\x91?zh\\x0b\\xc1\\rfu\\xc1\\x85\\xf0\\xe8\\xc1 W8\\xc1[{!\\xc1e\\xe3,?\\xe2\\xf50?\\x00\\x00\\x00@\\xea\\xce\\x97@\\xc5\\xb8hA\\xe8B\\xfb\\xc1\\xacO/\\xc1\\xd7\\xda\\x8eA\\x06*\\x1a\\xc1\\x9e\\xb3w>\\x19\\'\\x9c>\\x00\\x00\\x00@&\\x08\\xafA3\\xbc\\xb2\\xc0\\xc6\\xf6\\x14A\\x9c5\\xccA\\xdey\\xceA\\xd1\\xab\\x80\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\xff\\xe8\\x03\\xc1^\\x1a\\xf8\\xc0\\xd4\\x0c\\x88@\\xef\\xc0U\\xc1\"\\xdb\\xb1\\xc1\\x82\\xac\\x95\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0@]\\xd3{A\\x8b\\xedE\\xc1\\xa1\\xacs@4kcA\\xb0\\xbf\\xfcA(\\x07o\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@A\\x9b\\xca\\x80\\xc0\\x1217\\xc0\\x18\\x97\\xbc\\xc1g\\xea-\\xc1\\x19\\xd9\\xa8\\xc1\\xfb\\xbc(\\xc1]\\xc2\\x0f?\\xb3\\xa5\\xd5>\\x00\\x00\\xc0@a\\xd8+A\\xa1\\xcf\\xdeA\\xe1\\xa8F\\xc2\\xe8-Z\\xc1\\x10>\\xa1A\\x01\\xb8\\x8e\\xc0\\x03\\xedb=\\xff\\xc0\\x939\\x00\\x00\\xc0@\\x9f\\x91.\\xc0G5\\xfe\\xc0\\xa0\\x08\\nBR\\xe5\\xefA\\x92q|@\\x82m\\x1c\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0@\\n\\xb8\\x95\\xc0.\\xc9\\x93\\xc0\\x1d\\xa4\\x10A\\x86\\xb8p\\xc0\\xfc\\xbe\\xd1\\xc1z\\x01g\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80@?\\x1c\\xb0@\\xf2V\\x82\\xc1n\\xcf\\xed\\xc14M\\xcf\\xc1\\xa3\\xd88\\xc1c\\x0e\\xad\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@A\\x9b\\xca\\x80\\xc0\\x1217\\xc0\\x18\\x97\\xbc\\xc1g\\xea-\\xc1\\x19\\xd9\\xa8\\xc1\\xfb\\xbc(\\xc1]\\xc2\\x0f?\\xb3\\xa5\\xd5>\\x00\\x00@@a\\xd8+A\\xa1\\xcf\\xdeA\\xe1\\xa8F\\xc2\\xe8-Z\\xc1\\x10>\\xa1A\\x01\\xb8\\x8e\\xc0\\x03\\xedb=\\xff\\xc0\\x939\\x00\\x00@@\\x9f\\x91.\\xc0G5\\xfe\\xc0\\xa0\\x08\\nBR\\xe5\\xefA\\x92q|@\\x82m\\x1c\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@@\\x1d8o\\xc1\\r\\xb5\\xb7\\xc0\\x87FX\\xc17o\\xf0\\xc1js\\xfd\\xc05\\xdf9\\xc1\\xaem\\xf5?\\xb0\\xe50?\\x00\\x00@AY8\\xe1A\\xe6\\x9f\\x14\\xc1\\xde\\xf1L\\xc0\\xe5\\x18\\xe6A*M\\xcaAt\\x19a\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@A\\x9b\\xca\\x80\\xc0\\x1217\\xc0\\x18\\x97\\xbc\\xc1g\\xea-\\xc1\\x19\\xd9\\xa8\\xc1\\xfb\\xbc(\\xc1]\\xc2\\x0f?\\xb3\\xa5\\xd5>\\x00\\x00\\x00@a\\xd8+A\\xa1\\xcf\\xdeA\\xe1\\xa8F\\xc2\\xe8-Z\\xc1\\x10>\\xa1A\\x01\\xb8\\x8e\\xc0\\x03\\xedb=\\xff\\xc0\\x939\\x00\\x00\\x00@\\x9f\\x91.\\xc0G5\\xfe\\xc0\\xa0\\x08\\nBR\\xe5\\xefA\\x92q|@\\x82m\\x1c\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\x1d8o\\xc1\\r\\xb5\\xb7\\xc0\\x87FX\\xc17o\\xf0\\xc1js\\xfd\\xc05\\xdf9\\xc1\\xaem\\xf5?\\xb0\\xe50?\\x00\\x00@@Y8\\xe1A\\xe6\\x9f\\x14\\xc1\\xde\\xf1L\\xc0\\xe5\\x18\\xe6A*M\\xcaAt\\x19a\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@@=~\\x0e?!\\xb1\\xea\\xc0R\\xe2\\xfc\\xc1#\\xa5`\\xc1p\\x80\\x89\\xc1\\xfe\\x9aW\\xc1\\x7f\\xc2E?$\\xb5@?\\x00\\x00\\x00@^\\xc4\\x1b\\xc2\\x13\\xf5\\xb4>:`\\xa7\\xc1\\x04\\xf5\\xb7\\xc1\\xc1\\xc9]\\xc0\\xf9Hf\\xc1\\x87\\x10\\x14>(P\\x0f>\\x00\\x00\\x00@\\xff\\xad\\x1e\\xc1\\xcas\\x80@\\xc2\\xc8\\xd5\\xc0\\x19\\xd1r\\xc0\\xe7\\x1f\\xbf\\xc1\\x165_\\xc0\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\xder\\x91?zh\\x0b\\xc1\\rfu\\xc1\\x85\\xf0\\xe8\\xc1 W8\\xc1[{!\\xc1e\\xe3,?\\xe2\\xf50?\\x00\\x00@A\\xea\\xce\\x97@\\xc5\\xb8hA\\xe8B\\xfb\\xc1\\xacO/\\xc1\\xd7\\xda\\x8eA\\x06*\\x1a\\xc1\\x9e\\xb3w>\\x19\\'\\x9c>\\x00\\x00@A&\\x08\\xafA3\\xbc\\xb2\\xc0\\xc6\\xf6\\x14A\\x9c5\\xccA\\xdey\\xceA\\xd1\\xab\\x80\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@A\\xder\\x91?zh\\x0b\\xc1\\rfu\\xc1\\x85\\xf0\\xe8\\xc1 W8\\xc1[{!\\xc1e\\xe3,?\\xe2\\xf50?\\x00\\x00\\x00@\\xea\\xce\\x97@\\xc5\\xb8hA\\xe8B\\xfb\\xc1\\xacO/\\xc1\\xd7\\xda\\x8eA\\x06*\\x1a\\xc1\\x9e\\xb3w>\\x19\\'\\x9c>\\x00\\x00\\x00@&\\x08\\xafA3\\xbc\\xb2\\xc0\\xc6\\xf6\\x14A\\x9c5\\xccA\\xdey\\xceA\\xd1\\xab\\x80\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\xc7*\\xa3A\\xe7zrA\\x15$\\xd0\\xc1\\xef\\xcf+\\xc1O\\xe6\\x82A\\x90\\xb7\\x03\\xc1\\xaeh\\xa98\\xbf\\xe4\\xc05\\x00\\x00\\x80?c\\xae\\xb1\\xc0\\x18\\xa4p\\xc0\\x1d`\\xac\\xc1\\xc8D%\\xc1v`\\x8f\\xc1\\x87r6\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\x1d8o\\xc1\\r\\xb5\\xb7\\xc0\\x87FX\\xc17o\\xf0\\xc1js\\xfd\\xc05\\xdf9\\xc1\\xaem\\xf5?\\xb0\\xe50?\\x00\\x00\\x80AY8\\xe1A\\xe6\\x9f\\x14\\xc1\\xde\\xf1L\\xc0\\xe5\\x18\\xe6A*M\\xcaAt\\x19a\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80A\\n\\xb8\\x95\\xc0.\\xc9\\x93\\xc0\\x1d\\xa4\\x10A\\x86\\xb8p\\xc0\\xfc\\xbe\\xd1\\xc1z\\x01g\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\x9b\\xca\\x80\\xc0\\x1217\\xc0\\x18\\x97\\xbc\\xc1g\\xea-\\xc1\\x19\\xd9\\xa8\\xc1\\xfb\\xbc(\\xc1]\\xc2\\x0f?\\xb3\\xa5\\xd5>\\x00\\x00\\x00@a\\xd8+A\\xa1\\xcf\\xdeA\\xe1\\xa8F\\xc2\\xe8-Z\\xc1\\x10>\\xa1A\\x01\\xb8\\x8e\\xc0\\x03\\xedb=\\xff\\xc0\\x939\\x00\\x00\\x00@\\x9f\\x91.\\xc0G5\\xfe\\xc0\\xa0\\x08\\nBR\\xe5\\xefA\\x92q|@\\x82m\\x1c\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\n\\xb8\\x95\\xc0.\\xc9\\x93\\xc0\\x1d\\xa4\\x10A\\x86\\xb8p\\xc0\\xfc\\xbe\\xd1\\xc1z\\x01g\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@=~\\x0e?!\\xb1\\xea\\xc0R\\xe2\\xfc\\xc1#\\xa5`\\xc1p\\x80\\x89\\xc1\\xfe\\x9aW\\xc1\\x7f\\xc2E?$\\xb5@?\\x00\\x00@A^\\xc4\\x1b\\xc2\\x13\\xf5\\xb4>:`\\xa7\\xc1\\x04\\xf5\\xb7\\xc1\\xc1\\xc9]\\xc0\\xf9Hf\\xc1\\x87\\x10\\x14>(P\\x0f>\\x00\\x00@A\\xff\\xad\\x1e\\xc1\\xcas\\x80@\\xc2\\xc8\\xd5\\xc0\\x19\\xd1r\\xc0\\xe7\\x1f\\xbf\\xc1\\x165_\\xc0\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@A\\x9b\\xca\\x80\\xc0\\x1217\\xc0\\x18\\x97\\xbc\\xc1g\\xea-\\xc1\\x19\\xd9\\xa8\\xc1\\xfb\\xbc(\\xc1]\\xc2\\x0f?\\xb3\\xa5\\xd5>\\x00\\x00\\xc0@a\\xd8+A\\xa1\\xcf\\xdeA\\xe1\\xa8F\\xc2\\xe8-Z\\xc1\\x10>\\xa1A\\x01\\xb8\\x8e\\xc0\\x03\\xedb=\\xff\\xc0\\x939\\x00\\x00\\xc0@\\x9f\\x91.\\xc0G5\\xfe\\xc0\\xa0\\x08\\nBR\\xe5\\xefA\\x92q|@\\x82m\\x1c\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0@\\xc7*\\xa3A\\xe7zrA\\x15$\\xd0\\xc1\\xef\\xcf+\\xc1O\\xe6\\x82A\\x90\\xb7\\x03\\xc1\\xaeh\\xa98\\xbf\\xe4\\xc05\\x00\\x00\\x80?c\\xae\\xb1\\xc0\\x18\\xa4p\\xc0\\x1d`\\xac\\xc1\\xc8D%\\xc1v`\\x8f\\xc1\\x87r6\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0@=~\\x0e?!\\xb1\\xea\\xc0R\\xe2\\xfc\\xc1#\\xa5`\\xc1p\\x80\\x89\\xc1\\xfe\\x9aW\\xc1\\x7f\\xc2E?$\\xb5@?\\x00\\x00\\x00@^\\xc4\\x1b\\xc2\\x13\\xf5\\xb4>:`\\xa7\\xc1\\x04\\xf5\\xb7\\xc1\\xc1\\xc9]\\xc0\\xf9Hf\\xc1\\x87\\x10\\x14>(P\\x0f>\\x00\\x00\\x00@\\xff\\xad\\x1e\\xc1\\xcas\\x80@\\xc2\\xc8\\xd5\\xc0\\x19\\xd1r\\xc0\\xe7\\x1f\\xbf\\xc1\\x165_\\xc0\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@E\\xde}@\\xe8\\x19\\xcd\\xc0[\\x06sA\\xf5>\\xa4@V\\xb3\\x9aA\\x9a\\xaf\\x99\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0@\\x1d8o\\xc1\\r\\xb5\\xb7\\xc0\\x87FX\\xc17o\\xf0\\xc1js\\xfd\\xc05\\xdf9\\xc1\\xaem\\xf5?\\xb0\\xe50?\\x00\\x00\\x00AY8\\xe1A\\xe6\\x9f\\x14\\xc1\\xde\\xf1L\\xc0\\xe5\\x18\\xe6A*M\\xcaAt\\x19a\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00A\\n\\xb8\\x95\\xc0.\\xc9\\x93\\xc0\\x1d\\xa4\\x10A\\x86\\xb8p\\xc0\\xfc\\xbe\\xd1\\xc1z\\x01g\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80@\\x1d8o\\xc1\\r\\xb5\\xb7\\xc0\\x87FX\\xc17o\\xf0\\xc1js\\xfd\\xc05\\xdf9\\xc1\\xaem\\xf5?\\xb0\\xe50?\\x00\\x00\\x00AY8\\xe1A\\xe6\\x9f\\x14\\xc1\\xde\\xf1L\\xc0\\xe5\\x18\\xe6A*M\\xcaAt\\x19a\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00A=~\\x0e?!\\xb1\\xea\\xc0R\\xe2\\xfc\\xc1#\\xa5`\\xc1p\\x80\\x89\\xc1\\xfe\\x9aW\\xc1\\x7f\\xc2E?$\\xb5@?\\x00\\x00\\x80@^\\xc4\\x1b\\xc2\\x13\\xf5\\xb4>:`\\xa7\\xc1\\x04\\xf5\\xb7\\xc1\\xc1\\xc9]\\xc0\\xf9Hf\\xc1\\x87\\x10\\x14>(P\\x0f>\\x00\\x00\\x80@\\xff\\xad\\x1e\\xc1\\xcas\\x80@\\xc2\\xc8\\xd5\\xc0\\x19\\xd1r\\xc0\\xe7\\x1f\\xbf\\xc1\\x165_\\xc0\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80@DN;A\\xed\"\\xdc\\xc0\\x8b[O\\xc1\\xa0T\\xd8\\xc0\\x9c@\\xbbA\\x86k\\x98\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@A\\xc7*\\xa3A\\xe7zrA\\x15$\\xd0\\xc1\\xef\\xcf+\\xc1O\\xe6\\x82A\\x90\\xb7\\x03\\xc1\\xaeh\\xa98\\xbf\\xe4\\xc05\\x00\\x00\\x80?c\\xae\\xb1\\xc0\\x18\\xa4p\\xc0\\x1d`\\xac\\xc1\\xc8D%\\xc1v`\\x8f\\xc1\\x87r6\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@@\\n\\xb8\\x95\\xc0.\\xc9\\x93\\xc0\\x1d\\xa4\\x10A\\x86\\xb8p\\xc0\\xfc\\xbe\\xd1\\xc1z\\x01g\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0@\\xff\\xe8\\x03\\xc1^\\x1a\\xf8\\xc0\\xd4\\x0c\\x88@\\xef\\xc0U\\xc1\"\\xdb\\xb1\\xc1\\x82\\xac\\x95\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@A\\x8dT\\xc6\\xc1\\xb4y!\\xc1>\\x02\\xe3\\xc1\\xc4\\x05\\xe2\\xc1\\xcf\\xac\\x01Af\\xc7\\x8b\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80A\\xc7*\\xa3A\\xe7zrA\\x15$\\xd0\\xc1\\xef\\xcf+\\xc1O\\xe6\\x82A\\x90\\xb7\\x03\\xc1\\xaeh\\xa98\\xbf\\xe4\\xc05\\x00\\x00\\x80?c\\xae\\xb1\\xc0\\x18\\xa4p\\xc0\\x1d`\\xac\\xc1\\xc8D%\\xc1v`\\x8f\\xc1\\x87r6\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@A*\\xaf\\x8f\\xc0\\xc9\\xd3\\x82\\xc1\\xa0\\x94\\xf0A\\xf4\\xef\\x82A\\x1cn~Aw\\x96f\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80A\\xc7*\\xa3A\\xe7zrA\\x15$\\xd0\\xc1\\xef\\xcf+\\xc1O\\xe6\\x82A\\x90\\xb7\\x03\\xc1\\xaeh\\xa98\\xbf\\xe4\\xc05\\x00\\x00\\x80?c\\xae\\xb1\\xc0\\x18\\xa4p\\xc0\\x1d`\\xac\\xc1\\xc8D%\\xc1v`\\x8f\\xc1\\x87r6\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@A\\x9b\\xca\\x80\\xc0\\x1217\\xc0\\x18\\x97\\xbc\\xc1g\\xea-\\xc1\\x19\\xd9\\xa8\\xc1\\xfb\\xbc(\\xc1]\\xc2\\x0f?\\xb3\\xa5\\xd5>\\x00\\x00\\x80Aa\\xd8+A\\xa1\\xcf\\xdeA\\xe1\\xa8F\\xc2\\xe8-Z\\xc1\\x10>\\xa1A\\x01\\xb8\\x8e\\xc0\\x03\\xedb=\\xff\\xc0\\x939\\x00\\x00\\x80A\\x9f\\x91.\\xc0G5\\xfe\\xc0\\xa0\\x08\\nBR\\xe5\\xefA\\x92q|@\\x82m\\x1c\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80A=~\\x0e?!\\xb1\\xea\\xc0R\\xe2\\xfc\\xc1#\\xa5`\\xc1p\\x80\\x89\\xc1\\xfe\\x9aW\\xc1\\x7f\\xc2E?$\\xb5@?\\x00\\x00@@^\\xc4\\x1b\\xc2\\x13\\xf5\\xb4>:`\\xa7\\xc1\\x04\\xf5\\xb7\\xc1\\xc1\\xc9]\\xc0\\xf9Hf\\xc1\\x87\\x10\\x14>(P\\x0f>\\x00\\x00@@\\xff\\xad\\x1e\\xc1\\xcas\\x80@\\xc2\\xc8\\xd5\\xc0\\x19\\xd1r\\xc0\\xe7\\x1f\\xbf\\xc1\\x165_\\xc0\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@@\\n\\xb8\\x95\\xc0.\\xc9\\x93\\xc0\\x1d\\xa4\\x10A\\x86\\xb8p\\xc0\\xfc\\xbe\\xd1\\xc1z\\x01g\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80A\\x9b\\xca\\x80\\xc0\\x1217\\xc0\\x18\\x97\\xbc\\xc1g\\xea-\\xc1\\x19\\xd9\\xa8\\xc1\\xfb\\xbc(\\xc1]\\xc2\\x0f?\\xb3\\xa5\\xd5>\\x00\\x00@@a\\xd8+A\\xa1\\xcf\\xdeA\\xe1\\xa8F\\xc2\\xe8-Z\\xc1\\x10>\\xa1A\\x01\\xb8\\x8e\\xc0\\x03\\xedb=\\xff\\xc0\\x939\\x00\\x00@@\\x9f\\x91.\\xc0G5\\xfe\\xc0\\xa0\\x08\\nBR\\xe5\\xefA\\x92q|@\\x82m\\x1c\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@@\\xc7*\\xa3A\\xe7zrA\\x15$\\xd0\\xc1\\xef\\xcf+\\xc1O\\xe6\\x82A\\x90\\xb7\\x03\\xc1\\xaeh\\xa98\\xbf\\xe4\\xc05\\x00\\x00\\x80?c\\xae\\xb1\\xc0\\x18\\xa4p\\xc0\\x1d`\\xac\\xc1\\xc8D%\\xc1v`\\x8f\\xc1\\x87r6\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80A?\\x1c\\xb0@\\xf2V\\x82\\xc1n\\xcf\\xed\\xc14M\\xcf\\xc1\\xa3\\xd88\\xc1c\\x0e\\xad\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\n\\xb8\\x95\\xc0.\\xc9\\x93\\xc0\\x1d\\xa4\\x10A\\x86\\xb8p\\xc0\\xfc\\xbe\\xd1\\xc1z\\x01g\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\xder\\x91?zh\\x0b\\xc1\\rfu\\xc1\\x85\\xf0\\xe8\\xc1 W8\\xc1[{!\\xc1e\\xe3,?\\xe2\\xf50?\\x00\\x00\\xc0@\\xea\\xce\\x97@\\xc5\\xb8hA\\xe8B\\xfb\\xc1\\xacO/\\xc1\\xd7\\xda\\x8eA\\x06*\\x1a\\xc1\\x9e\\xb3w>\\x19\\'\\x9c>\\x00\\x00\\xc0@&\\x08\\xafA3\\xbc\\xb2\\xc0\\xc6\\xf6\\x14A\\x9c5\\xccA\\xdey\\xceA\\xd1\\xab\\x80\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0@]\\xd3{A\\x8b\\xedE\\xc1\\xa1\\xacs@4kcA\\xb0\\xbf\\xfcA(\\x07o\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@@\\x9b\\xca\\x80\\xc0\\x1217\\xc0\\x18\\x97\\xbc\\xc1g\\xea-\\xc1\\x19\\xd9\\xa8\\xc1\\xfb\\xbc(\\xc1]\\xc2\\x0f?\\xb3\\xa5\\xd5>\\x00\\x00\\x00Aa\\xd8+A\\xa1\\xcf\\xdeA\\xe1\\xa8F\\xc2\\xe8-Z\\xc1\\x10>\\xa1A\\x01\\xb8\\x8e\\xc0\\x03\\xedb=\\xff\\xc0\\x939\\x00\\x00\\x00A\\x9f\\x91.\\xc0G5\\xfe\\xc0\\xa0\\x08\\nBR\\xe5\\xefA\\x92q|@\\x82m\\x1c\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00A]\\xd3{A\\x8b\\xedE\\xc1\\xa1\\xacs@4kcA\\xb0\\xbf\\xfcA(\\x07o\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80A\\xff\\xe8\\x03\\xc1^\\x1a\\xf8\\xc0\\xd4\\x0c\\x88@\\xef\\xc0U\\xc1\"\\xdb\\xb1\\xc1\\x82\\xac\\x95\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00A?\\x1c\\xb0@\\xf2V\\x82\\xc1n\\xcf\\xed\\xc14M\\xcf\\xc1\\xa3\\xd88\\xc1c\\x0e\\xad\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0@\\n\\xb8\\x95\\xc0.\\xc9\\x93\\xc0\\x1d\\xa4\\x10A\\x86\\xb8p\\xc0\\xfc\\xbe\\xd1\\xc1z\\x01g\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80A]\\xd3{A\\x8b\\xedE\\xc1\\xa1\\xacs@4kcA\\xb0\\xbf\\xfcA(\\x07o\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\x1d8o\\xc1\\r\\xb5\\xb7\\xc0\\x87FX\\xc17o\\xf0\\xc1js\\xfd\\xc05\\xdf9\\xc1\\xaem\\xf5?\\xb0\\xe50?\\x00\\x00\\xc0@Y8\\xe1A\\xe6\\x9f\\x14\\xc1\\xde\\xf1L\\xc0\\xe5\\x18\\xe6A*M\\xcaAt\\x19a\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0@\\n\\xb8\\x95\\xc0.\\xc9\\x93\\xc0\\x1d\\xa4\\x10A\\x86\\xb8p\\xc0\\xfc\\xbe\\xd1\\xc1z\\x01g\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80A\\xder\\x91?zh\\x0b\\xc1\\rfu\\xc1\\x85\\xf0\\xe8\\xc1 W8\\xc1[{!\\xc1e\\xe3,?\\xe2\\xf50?\\x00\\x00@@\\xea\\xce\\x97@\\xc5\\xb8hA\\xe8B\\xfb\\xc1\\xacO/\\xc1\\xd7\\xda\\x8eA\\x06*\\x1a\\xc1\\x9e\\xb3w>\\x19\\'\\x9c>\\x00\\x00@@&\\x08\\xafA3\\xbc\\xb2\\xc0\\xc6\\xf6\\x14A\\x9c5\\xccA\\xdey\\xceA\\xd1\\xab\\x80\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@@*\\xaf\\x8f\\xc0\\xc9\\xd3\\x82\\xc1\\xa0\\x94\\xf0A\\xf4\\xef\\x82A\\x1cn~Aw\\x96f\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80ADN;A\\xed\"\\xdc\\xc0\\x8b[O\\xc1\\xa0T\\xd8\\xc0\\x9c@\\xbbA\\x86k\\x98\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0@\\xc7*\\xa3A\\xe7zrA\\x15$\\xd0\\xc1\\xef\\xcf+\\xc1O\\xe6\\x82A\\x90\\xb7\\x03\\xc1\\xaeh\\xa98\\xbf\\xe4\\xc05\\x00\\x00\\x80?c\\xae\\xb1\\xc0\\x18\\xa4p\\xc0\\x1d`\\xac\\xc1\\xc8D%\\xc1v`\\x8f\\xc1\\x87r6\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@A\\n\\xb8\\x95\\xc0.\\xc9\\x93\\xc0\\x1d\\xa4\\x10A\\x86\\xb8p\\xc0\\xfc\\xbe\\xd1\\xc1z\\x01g\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00A\\xder\\x91?zh\\x0b\\xc1\\rfu\\xc1\\x85\\xf0\\xe8\\xc1 W8\\xc1[{!\\xc1e\\xe3,?\\xe2\\xf50?\\x00\\x00\\xc0@\\xea\\xce\\x97@\\xc5\\xb8hA\\xe8B\\xfb\\xc1\\xacO/\\xc1\\xd7\\xda\\x8eA\\x06*\\x1a\\xc1\\x9e\\xb3w>\\x19\\'\\x9c>\\x00\\x00\\xc0@&\\x08\\xafA3\\xbc\\xb2\\xc0\\xc6\\xf6\\x14A\\x9c5\\xccA\\xdey\\xceA\\xd1\\xab\\x80\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0@\\xder\\x91?zh\\x0b\\xc1\\rfu\\xc1\\x85\\xf0\\xe8\\xc1 W8\\xc1[{!\\xc1e\\xe3,?\\xe2\\xf50?\\x00\\x00\\xc0@\\xea\\xce\\x97@\\xc5\\xb8hA\\xe8B\\xfb\\xc1\\xacO/\\xc1\\xd7\\xda\\x8eA\\x06*\\x1a\\xc1\\x9e\\xb3w>\\x19\\'\\x9c>\\x00\\x00\\xc0@&\\x08\\xafA3\\xbc\\xb2\\xc0\\xc6\\xf6\\x14A\\x9c5\\xccA\\xdey\\xceA\\xd1\\xab\\x80\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0@]\\xd3{A\\x8b\\xedE\\xc1\\xa1\\xacs@4kcA\\xb0\\xbf\\xfcA(\\x07o\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\xff\\xe8\\x03\\xc1^\\x1a\\xf8\\xc0\\xd4\\x0c\\x88@\\xef\\xc0U\\xc1\"\\xdb\\xb1\\xc1\\x82\\xac\\x95\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@@\\xc7*\\xa3A\\xe7zrA\\x15$\\xd0\\xc1\\xef\\xcf+\\xc1O\\xe6\\x82A\\x90\\xb7\\x03\\xc1\\xaeh\\xa98\\xbf\\xe4\\xc05\\x00\\x00\\x80?c\\xae\\xb1\\xc0\\x18\\xa4p\\xc0\\x1d`\\xac\\xc1\\xc8D%\\xc1v`\\x8f\\xc1\\x87r6\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80@E\\xde}@\\xe8\\x19\\xcd\\xc0[\\x06sA\\xf5>\\xa4@V\\xb3\\x9aA\\x9a\\xaf\\x99\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80A\\xff\\xe8\\x03\\xc1^\\x1a\\xf8\\xc0\\xd4\\x0c\\x88@\\xef\\xc0U\\xc1\"\\xdb\\xb1\\xc1\\x82\\xac\\x95\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00A\\n\\xb8\\x95\\xc0.\\xc9\\x93\\xc0\\x1d\\xa4\\x10A\\x86\\xb8p\\xc0\\xfc\\xbe\\xd1\\xc1z\\x01g\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@DN;A\\xed\"\\xdc\\xc0\\x8b[O\\xc1\\xa0T\\xd8\\xc0\\x9c@\\xbbA\\x86k\\x98\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0@\\xc7*\\xa3A\\xe7zrA\\x15$\\xd0\\xc1\\xef\\xcf+\\xc1O\\xe6\\x82A\\x90\\xb7\\x03\\xc1\\xaeh\\xa98\\xbf\\xe4\\xc05\\x00\\x00\\x80?c\\xae\\xb1\\xc0\\x18\\xa4p\\xc0\\x1d`\\xac\\xc1\\xc8D%\\xc1v`\\x8f\\xc1\\x87r6\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00A*\\xaf\\x8f\\xc0\\xc9\\xd3\\x82\\xc1\\xa0\\x94\\xf0A\\xf4\\xef\\x82A\\x1cn~Aw\\x96f\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80@\\xc7*\\xa3A\\xe7zrA\\x15$\\xd0\\xc1\\xef\\xcf+\\xc1O\\xe6\\x82A\\x90\\xb7\\x03\\xc1\\xaeh\\xa98\\xbf\\xe4\\xc05\\x00\\x00\\x80?c\\xae\\xb1\\xc0\\x18\\xa4p\\xc0\\x1d`\\xac\\xc1\\xc8D%\\xc1v`\\x8f\\xc1\\x87r6\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80@E\\xde}@\\xe8\\x19\\xcd\\xc0[\\x06sA\\xf5>\\xa4@V\\xb3\\x9aA\\x9a\\xaf\\x99\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@A\\x9b\\xca\\x80\\xc0\\x1217\\xc0\\x18\\x97\\xbc\\xc1g\\xea-\\xc1\\x19\\xd9\\xa8\\xc1\\xfb\\xbc(\\xc1]\\xc2\\x0f?\\xb3\\xa5\\xd5>\\x00\\x00\\x00Aa\\xd8+A\\xa1\\xcf\\xdeA\\xe1\\xa8F\\xc2\\xe8-Z\\xc1\\x10>\\xa1A\\x01\\xb8\\x8e\\xc0\\x03\\xedb=\\xff\\xc0\\x939\\x00\\x00\\x00A\\x9f\\x91.\\xc0G5\\xfe\\xc0\\xa0\\x08\\nBR\\xe5\\xefA\\x92q|@\\x82m\\x1c\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00A\\xder\\x91?zh\\x0b\\xc1\\rfu\\xc1\\x85\\xf0\\xe8\\xc1 W8\\xc1[{!\\xc1e\\xe3,?\\xe2\\xf50?\\x00\\x00\\x00@\\xea\\xce\\x97@\\xc5\\xb8hA\\xe8B\\xfb\\xc1\\xacO/\\xc1\\xd7\\xda\\x8eA\\x06*\\x1a\\xc1\\x9e\\xb3w>\\x19\\'\\x9c>\\x00\\x00\\x00@&\\x08\\xafA3\\xbc\\xb2\\xc0\\xc6\\xf6\\x14A\\x9c5\\xccA\\xdey\\xceA\\xd1\\xab\\x80\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\n\\xb8\\x95\\xc0.\\xc9\\x93\\xc0\\x1d\\xa4\\x10A\\x86\\xb8p\\xc0\\xfc\\xbe\\xd1\\xc1z\\x01g\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80ADN;A\\xed\"\\xdc\\xc0\\x8b[O\\xc1\\xa0T\\xd8\\xc0\\x9c@\\xbbA\\x86k\\x98\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80AE\\xde}@\\xe8\\x19\\xcd\\xc0[\\x06sA\\xf5>\\xa4@V\\xb3\\x9aA\\x9a\\xaf\\x99\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00AE\\xde}@\\xe8\\x19\\xcd\\xc0[\\x06sA\\xf5>\\xa4@V\\xb3\\x9aA\\x9a\\xaf\\x99\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00AE\\xde}@\\xe8\\x19\\xcd\\xc0[\\x06sA\\xf5>\\xa4@V\\xb3\\x9aA\\x9a\\xaf\\x99\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0@*\\xaf\\x8f\\xc0\\xc9\\xd3\\x82\\xc1\\xa0\\x94\\xf0A\\xf4\\xef\\x82A\\x1cn~Aw\\x96f\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00A]\\xd3{A\\x8b\\xedE\\xc1\\xa1\\xacs@4kcA\\xb0\\xbf\\xfcA(\\x07o\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0@E\\xde}@\\xe8\\x19\\xcd\\xc0[\\x06sA\\xf5>\\xa4@V\\xb3\\x9aA\\x9a\\xaf\\x99\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@A=~\\x0e?!\\xb1\\xea\\xc0R\\xe2\\xfc\\xc1#\\xa5`\\xc1p\\x80\\x89\\xc1\\xfe\\x9aW\\xc1\\x7f\\xc2E?$\\xb5@?\\x00\\x00\\x80@^\\xc4\\x1b\\xc2\\x13\\xf5\\xb4>:`\\xa7\\xc1\\x04\\xf5\\xb7\\xc1\\xc1\\xc9]\\xc0\\xf9Hf\\xc1\\x87\\x10\\x14>(P\\x0f>\\x00\\x00\\x80@\\xff\\xad\\x1e\\xc1\\xcas\\x80@\\xc2\\xc8\\xd5\\xc0\\x19\\xd1r\\xc0\\xe7\\x1f\\xbf\\xc1\\x165_\\xc0\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80@\\xc7*\\xa3A\\xe7zrA\\x15$\\xd0\\xc1\\xef\\xcf+\\xc1O\\xe6\\x82A\\x90\\xb7\\x03\\xc1\\xaeh\\xa98\\xbf\\xe4\\xc05\\x00\\x00\\x80?c\\xae\\xb1\\xc0\\x18\\xa4p\\xc0\\x1d`\\xac\\xc1\\xc8D%\\xc1v`\\x8f\\xc1\\x87r6\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00A\\xder\\x91?zh\\x0b\\xc1\\rfu\\xc1\\x85\\xf0\\xe8\\xc1 W8\\xc1[{!\\xc1e\\xe3,?\\xe2\\xf50?\\x00\\x00@@\\xea\\xce\\x97@\\xc5\\xb8hA\\xe8B\\xfb\\xc1\\xacO/\\xc1\\xd7\\xda\\x8eA\\x06*\\x1a\\xc1\\x9e\\xb3w>\\x19\\'\\x9c>\\x00\\x00@@&\\x08\\xafA3\\xbc\\xb2\\xc0\\xc6\\xf6\\x14A\\x9c5\\xccA\\xdey\\xceA\\xd1\\xab\\x80\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@@\\n\\xb8\\x95\\xc0.\\xc9\\x93\\xc0\\x1d\\xa4\\x10A\\x86\\xb8p\\xc0\\xfc\\xbe\\xd1\\xc1z\\x01g\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@DN;A\\xed\"\\xdc\\xc0\\x8b[O\\xc1\\xa0T\\xd8\\xc0\\x9c@\\xbbA\\x86k\\x98\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\x9b\\xca\\x80\\xc0\\x1217\\xc0\\x18\\x97\\xbc\\xc1g\\xea-\\xc1\\x19\\xd9\\xa8\\xc1\\xfb\\xbc(\\xc1]\\xc2\\x0f?\\xb3\\xa5\\xd5>\\x00\\x00\\x80@a\\xd8+A\\xa1\\xcf\\xdeA\\xe1\\xa8F\\xc2\\xe8-Z\\xc1\\x10>\\xa1A\\x01\\xb8\\x8e\\xc0\\x03\\xedb=\\xff\\xc0\\x939\\x00\\x00\\x80@\\x9f\\x91.\\xc0G5\\xfe\\xc0\\xa0\\x08\\nBR\\xe5\\xefA\\x92q|@\\x82m\\x1c\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80@DN;A\\xed\"\\xdc\\xc0\\x8b[O\\xc1\\xa0T\\xd8\\xc0\\x9c@\\xbbA\\x86k\\x98\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0@\\xder\\x91?zh\\x0b\\xc1\\rfu\\xc1\\x85\\xf0\\xe8\\xc1 W8\\xc1[{!\\xc1e\\xe3,?\\xe2\\xf50?\\x00\\x00@@\\xea\\xce\\x97@\\xc5\\xb8hA\\xe8B\\xfb\\xc1\\xacO/\\xc1\\xd7\\xda\\x8eA\\x06*\\x1a\\xc1\\x9e\\xb3w>\\x19\\'\\x9c>\\x00\\x00@@&\\x08\\xafA3\\xbc\\xb2\\xc0\\xc6\\xf6\\x14A\\x9c5\\xccA\\xdey\\xceA\\xd1\\xab\\x80\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@@E\\xde}@\\xe8\\x19\\xcd\\xc0[\\x06sA\\xf5>\\xa4@V\\xb3\\x9aA\\x9a\\xaf\\x99\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@@\\xff\\xe8\\x03\\xc1^\\x1a\\xf8\\xc0\\xd4\\x0c\\x88@\\xef\\xc0U\\xc1\"\\xdb\\xb1\\xc1\\x82\\xac\\x95\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\n\\xb8\\x95\\xc0.\\xc9\\x93\\xc0\\x1d\\xa4\\x10A\\x86\\xb8p\\xc0\\xfc\\xbe\\xd1\\xc1z\\x01g\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80A\\xff\\xe8\\x03\\xc1^\\x1a\\xf8\\xc0\\xd4\\x0c\\x88@\\xef\\xc0U\\xc1\"\\xdb\\xb1\\xc1\\x82\\xac\\x95\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0@]\\xd3{A\\x8b\\xedE\\xc1\\xa1\\xacs@4kcA\\xb0\\xbf\\xfcA(\\x07o\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00A\\n\\xb8\\x95\\xc0.\\xc9\\x93\\xc0\\x1d\\xa4\\x10A\\x86\\xb8p\\xc0\\xfc\\xbe\\xd1\\xc1z\\x01g\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@@\\xff\\xe8\\x03\\xc1^\\x1a\\xf8\\xc0\\xd4\\x0c\\x88@\\xef\\xc0U\\xc1\"\\xdb\\xb1\\xc1\\x82\\xac\\x95\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@A=~\\x0e?!\\xb1\\xea\\xc0R\\xe2\\xfc\\xc1#\\xa5`\\xc1p\\x80\\x89\\xc1\\xfe\\x9aW\\xc1\\x7f\\xc2E?$\\xb5@?\\x00\\x00\\xc0@^\\xc4\\x1b\\xc2\\x13\\xf5\\xb4>:`\\xa7\\xc1\\x04\\xf5\\xb7\\xc1\\xc1\\xc9]\\xc0\\xf9Hf\\xc1\\x87\\x10\\x14>(P\\x0f>\\x00\\x00\\xc0@\\xff\\xad\\x1e\\xc1\\xcas\\x80@\\xc2\\xc8\\xd5\\xc0\\x19\\xd1r\\xc0\\xe7\\x1f\\xbf\\xc1\\x165_\\xc0\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0@\\n\\xb8\\x95\\xc0.\\xc9\\x93\\xc0\\x1d\\xa4\\x10A\\x86\\xb8p\\xc0\\xfc\\xbe\\xd1\\xc1z\\x01g\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@A\\xff\\xe8\\x03\\xc1^\\x1a\\xf8\\xc0\\xd4\\x0c\\x88@\\xef\\xc0U\\xc1\"\\xdb\\xb1\\xc1\\x82\\xac\\x95\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80A\\xc7*\\xa3A\\xe7zrA\\x15$\\xd0\\xc1\\xef\\xcf+\\xc1O\\xe6\\x82A\\x90\\xb7\\x03\\xc1\\xaeh\\xa98\\xbf\\xe4\\xc05\\x00\\x00\\x80?c\\xae\\xb1\\xc0\\x18\\xa4p\\xc0\\x1d`\\xac\\xc1\\xc8D%\\xc1v`\\x8f\\xc1\\x87r6\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00A\\xff\\xe8\\x03\\xc1^\\x1a\\xf8\\xc0\\xd4\\x0c\\x88@\\xef\\xc0U\\xc1\"\\xdb\\xb1\\xc1\\x82\\xac\\x95\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80A\\xff\\xe8\\x03\\xc1^\\x1a\\xf8\\xc0\\xd4\\x0c\\x88@\\xef\\xc0U\\xc1\"\\xdb\\xb1\\xc1\\x82\\xac\\x95\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80@DN;A\\xed\"\\xdc\\xc0\\x8b[O\\xc1\\xa0T\\xd8\\xc0\\x9c@\\xbbA\\x86k\\x98\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80A\\xff\\xe8\\x03\\xc1^\\x1a\\xf8\\xc0\\xd4\\x0c\\x88@\\xef\\xc0U\\xc1\"\\xdb\\xb1\\xc1\\x82\\xac\\x95\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00A\\xc7*\\xa3A\\xe7zrA\\x15$\\xd0\\xc1\\xef\\xcf+\\xc1O\\xe6\\x82A\\x90\\xb7\\x03\\xc1\\xaeh\\xa98\\xbf\\xe4\\xc05\\x00\\x00\\x80?c\\xae\\xb1\\xc0\\x18\\xa4p\\xc0\\x1d`\\xac\\xc1\\xc8D%\\xc1v`\\x8f\\xc1\\x87r6\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80@\\x9b\\xca\\x80\\xc0\\x1217\\xc0\\x18\\x97\\xbc\\xc1g\\xea-\\xc1\\x19\\xd9\\xa8\\xc1\\xfb\\xbc(\\xc1]\\xc2\\x0f?\\xb3\\xa5\\xd5>\\x00\\x00\\x80@a\\xd8+A\\xa1\\xcf\\xdeA\\xe1\\xa8F\\xc2\\xe8-Z\\xc1\\x10>\\xa1A\\x01\\xb8\\x8e\\xc0\\x03\\xedb=\\xff\\xc0\\x939\\x00\\x00\\x80@\\x9f\\x91.\\xc0G5\\xfe\\xc0\\xa0\\x08\\nBR\\xe5\\xefA\\x92q|@\\x82m\\x1c\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80@\\n\\xb8\\x95\\xc0.\\xc9\\x93\\xc0\\x1d\\xa4\\x10A\\x86\\xb8p\\xc0\\xfc\\xbe\\xd1\\xc1z\\x01g\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@A\\x1d8o\\xc1\\r\\xb5\\xb7\\xc0\\x87FX\\xc17o\\xf0\\xc1js\\xfd\\xc05\\xdf9\\xc1\\xaem\\xf5?\\xb0\\xe50?\\x00\\x00\\x00AY8\\xe1A\\xe6\\x9f\\x14\\xc1\\xde\\xf1L\\xc0\\xe5\\x18\\xe6A*M\\xcaAt\\x19a\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00A=~\\x0e?!\\xb1\\xea\\xc0R\\xe2\\xfc\\xc1#\\xa5`\\xc1p\\x80\\x89\\xc1\\xfe\\x9aW\\xc1\\x7f\\xc2E?$\\xb5@?\\x00\\x00\\x00A^\\xc4\\x1b\\xc2\\x13\\xf5\\xb4>:`\\xa7\\xc1\\x04\\xf5\\xb7\\xc1\\xc1\\xc9]\\xc0\\xf9Hf\\xc1\\x87\\x10\\x14>(P\\x0f>\\x00\\x00\\x00A\\xff\\xad\\x1e\\xc1\\xcas\\x80@\\xc2\\xc8\\xd5\\xc0\\x19\\xd1r\\xc0\\xe7\\x1f\\xbf\\xc1\\x165_\\xc0\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00A\\n\\xb8\\x95\\xc0.\\xc9\\x93\\xc0\\x1d\\xa4\\x10A\\x86\\xb8p\\xc0\\xfc\\xbe\\xd1\\xc1z\\x01g\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\n\\xb8\\x95\\xc0.\\xc9\\x93\\xc0\\x1d\\xa4\\x10A\\x86\\xb8p\\xc0\\xfc\\xbe\\xd1\\xc1z\\x01g\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00A\\n\\xb8\\x95\\xc0.\\xc9\\x93\\xc0\\x1d\\xa4\\x10A\\x86\\xb8p\\xc0\\xfc\\xbe\\xd1\\xc1z\\x01g\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0@*\\xaf\\x8f\\xc0\\xc9\\xd3\\x82\\xc1\\xa0\\x94\\xf0A\\xf4\\xef\\x82A\\x1cn~Aw\\x96f\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80@?\\x1c\\xb0@\\xf2V\\x82\\xc1n\\xcf\\xed\\xc14M\\xcf\\xc1\\xa3\\xd88\\xc1c\\x0e\\xad\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80A\\n\\xb8\\x95\\xc0.\\xc9\\x93\\xc0\\x1d\\xa4\\x10A\\x86\\xb8p\\xc0\\xfc\\xbe\\xd1\\xc1z\\x01g\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@@\\xder\\x91?zh\\x0b\\xc1\\rfu\\xc1\\x85\\xf0\\xe8\\xc1 W8\\xc1[{!\\xc1e\\xe3,?\\xe2\\xf50?\\x00\\x00\\xc0@\\xea\\xce\\x97@\\xc5\\xb8hA\\xe8B\\xfb\\xc1\\xacO/\\xc1\\xd7\\xda\\x8eA\\x06*\\x1a\\xc1\\x9e\\xb3w>\\x19\\'\\x9c>\\x00\\x00\\xc0@&\\x08\\xafA3\\xbc\\xb2\\xc0\\xc6\\xf6\\x14A\\x9c5\\xccA\\xdey\\xceA\\xd1\\xab\\x80\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0@\\x9b\\xca\\x80\\xc0\\x1217\\xc0\\x18\\x97\\xbc\\xc1g\\xea-\\xc1\\x19\\xd9\\xa8\\xc1\\xfb\\xbc(\\xc1]\\xc2\\x0f?\\xb3\\xa5\\xd5>\\x00\\x00\\x00Aa\\xd8+A\\xa1\\xcf\\xdeA\\xe1\\xa8F\\xc2\\xe8-Z\\xc1\\x10>\\xa1A\\x01\\xb8\\x8e\\xc0\\x03\\xedb=\\xff\\xc0\\x939\\x00\\x00\\x00A\\x9f\\x91.\\xc0G5\\xfe\\xc0\\xa0\\x08\\nBR\\xe5\\xefA\\x92q|@\\x82m\\x1c\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00A\\x8dT\\xc6\\xc1\\xb4y!\\xc1>\\x02\\xe3\\xc1\\xc4\\x05\\xe2\\xc1\\xcf\\xac\\x01Af\\xc7\\x8b\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00A\\x9b\\xca\\x80\\xc0\\x1217\\xc0\\x18\\x97\\xbc\\xc1g\\xea-\\xc1\\x19\\xd9\\xa8\\xc1\\xfb\\xbc(\\xc1]\\xc2\\x0f?\\xb3\\xa5\\xd5>\\x00\\x00\\x00Aa\\xd8+A\\xa1\\xcf\\xdeA\\xe1\\xa8F\\xc2\\xe8-Z\\xc1\\x10>\\xa1A\\x01\\xb8\\x8e\\xc0\\x03\\xedb=\\xff\\xc0\\x939\\x00\\x00\\x00A\\x9f\\x91.\\xc0G5\\xfe\\xc0\\xa0\\x08\\nBR\\xe5\\xefA\\x92q|@\\x82m\\x1c\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00A?\\x1c\\xb0@\\xf2V\\x82\\xc1n\\xcf\\xed\\xc14M\\xcf\\xc1\\xa3\\xd88\\xc1c\\x0e\\xad\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00A\\n\\xb8\\x95\\xc0.\\xc9\\x93\\xc0\\x1d\\xa4\\x10A\\x86\\xb8p\\xc0\\xfc\\xbe\\xd1\\xc1z\\x01g\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80A\\x8dT\\xc6\\xc1\\xb4y!\\xc1>\\x02\\xe3\\xc1\\xc4\\x05\\xe2\\xc1\\xcf\\xac\\x01Af\\xc7\\x8b\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00AE\\xde}@\\xe8\\x19\\xcd\\xc0[\\x06sA\\xf5>\\xa4@V\\xb3\\x9aA\\x9a\\xaf\\x99\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@*\\xaf\\x8f\\xc0\\xc9\\xd3\\x82\\xc1\\xa0\\x94\\xf0A\\xf4\\xef\\x82A\\x1cn~Aw\\x96f\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80AE\\xde}@\\xe8\\x19\\xcd\\xc0[\\x06sA\\xf5>\\xa4@V\\xb3\\x9aA\\x9a\\xaf\\x99\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\xc7*\\xa3A\\xe7zrA\\x15$\\xd0\\xc1\\xef\\xcf+\\xc1O\\xe6\\x82A\\x90\\xb7\\x03\\xc1\\xaeh\\xa98\\xbf\\xe4\\xc05\\x00\\x00\\x80?c\\xae\\xb1\\xc0\\x18\\xa4p\\xc0\\x1d`\\xac\\xc1\\xc8D%\\xc1v`\\x8f\\xc1\\x87r6\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@@=~\\x0e?!\\xb1\\xea\\xc0R\\xe2\\xfc\\xc1#\\xa5`\\xc1p\\x80\\x89\\xc1\\xfe\\x9aW\\xc1\\x7f\\xc2E?$\\xb5@?\\x00\\x00\\x00@^\\xc4\\x1b\\xc2\\x13\\xf5\\xb4>:`\\xa7\\xc1\\x04\\xf5\\xb7\\xc1\\xc1\\xc9]\\xc0\\xf9Hf\\xc1\\x87\\x10\\x14>(P\\x0f>\\x00\\x00\\x00@\\xff\\xad\\x1e\\xc1\\xcas\\x80@\\xc2\\xc8\\xd5\\xc0\\x19\\xd1r\\xc0\\xe7\\x1f\\xbf\\xc1\\x165_\\xc0\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@?\\x1c\\xb0@\\xf2V\\x82\\xc1n\\xcf\\xed\\xc14M\\xcf\\xc1\\xa3\\xd88\\xc1c\\x0e\\xad\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@@DN;A\\xed\"\\xdc\\xc0\\x8b[O\\xc1\\xa0T\\xd8\\xc0\\x9c@\\xbbA\\x86k\\x98\\xc1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80@\\n\\x8f\\x01\\n\\x13edges/op2op.#source\\x12x\\x1av\\nt\\x00\\x01\\x05\\x06\\n\\x0b\\r\\x0f\\x10\\x12\\x14\\x15\\x17\\x18\\x1a\\x1b\\x1d\\x1f\"#&\\')*,./2578;@CEFHILMOSTWX_bcgjkmnrx{~\\x7f\\x81\\x01\\x82\\x01\\x8c\\x01\\x8d\\x01\\x8f\\x01\\x91\\x01\\x92\\x01\\x96\\x01\\x97\\x01\\x9a\\x01\\x9b\\x01\\xa4\\x01\\xa5\\x01\\xa9\\x01\\xaf\\x01\\xb1\\x01\\xb2\\x01\\xb5\\x01\\xb7\\x01\\xb8\\x01\\xc0\\x01\\xc1\\x01\\xc3\\x01\\xc4\\x01\\xc7\\x01\\xc8\\x01\\xd0\\x01\\xd2\\x01\\xd3\\x01\\n\\x9d\\x01\\n\\x12nodes/source.#size\\x12\\x86\\x01\\x1a\\x83\\x01\\n\\x80\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\n\\x9f\\x08\\n\\x14context/hidden_state\\x12\\x86\\x08\\x12\\x83\\x08\\n\\x80\\x08\\xef\\xeeFI\\xb3$\\x99F\\x11\\x11\\xdaI\\x89]\\x84Fa\\x85\\x9dL\\xdf\\xb9\\xb7H]\\xb9\\xcaJ\\x81\\xa9EHv\\x8f\\xa8L\\xc5\\x1b\\xc1H\\xbc\\xbb\\xdeJ\\x8a\\xa6WH\\x05\\x0b\\x18K ?\\x94H\\x1f#\\x15L\\x840\\x1fH\\xb0C\\x94I\\x80\\xc2\\x0fG\\xe6k\\xbaK\\xa5\\xfc\\xc6GUU\\x15G\\x11\\xf1\\x80D\\x89\\x88\\x17J\\xeb\\xb8eG#-3J\\'W\\x8bG\\xde\\xdd\\x12J\\x89\\xd9\\xe9F\\xde\\x8f\\xf8Ln\\xa8\\x04I:9\\xfaI\\x006\\x0fF]\\xb9\\xcaJ\\x81\\xa9EHH\\xbf\\xe0K.\\xbd\\x00H\\xbc\\xbb\\xe9I\\xa6\\x86;G]\\xb9\\xcaJ\\x81\\xa9EH\\xad\\x9d\\xaeL\\x884\\x8bI<\\xb8\\xf2G\"\\x06HE33\\xf3G\\x9a1%E\\xe6k:M\\xa5\\xfcFIv\\x8f\\xa8L\\xc5\\x1b\\xc1H\\xe6k:M\\xa5\\xfcFI\\xbe\\x90\\xe4I\\xc9\\x84;G\\xcd\\xcc\\x02Kk\\x86\\xcfG\\xc9A\\xbaJM|\\x94G1\\xd7\\xfcL\\xd3\\xd4\\x10I\\xa4\\x15*K\\xf3!\\xcdGVz\\xb9K\\xd3\\xb33I\\xad\\x9d.M\\x884\\x0bJ\\xab[\\xa8Mqa\\xc4I\\xc9A\\xbaJM|\\x94G>&\\x07LV\\xc6\\x83I\\xde\\xdd=Gf\\x06\\x96DH\\xbf`M.\\xbd\\x80I]\\xb9\\xcaJ\\x81\\xa9EH\\xd26\\x9bL\\xd5ywI1G\\xcaJl\\x0fEHH\\xbf\\xe0K.\\xbd\\x00Ho\\x00\\x9eH\\xcd\\x11\\x02F3s\\x8eJ\\xe6\"\\xa6F\\x00\\x00\\x8aI\\t\\xcb\\x07G\"J\\x92L\\x82x\\xaaH\\x07c\\xd9K\\xd7x\\x83H1G\\xcaJl\\x0fEH\\x9a\\xd9\\x1aKf\\r3Gw\\xb7\\xf6J&\\xc3\\x0fG\\xed\\xd0\\x0bM|=\\x15Iv\\x8f\\xa8M\\xc5\\x1b\\xc1I\\xc8\\x92IK\\x0c\\xc2\\x9cH\\xab[\\xa8Mqa\\xc4I\"\\xa2\\x08J\\x80\\xa5\\xd7F<\\xd2hL`\\x9b9IH\\xbf`L.\\xbd\\x80H\\xdaa\\x06K\\xbb\\x02QH\\xdaa\\x86K\\xbb\\x02\\xd1H,\\x07\\xd2K\\xd4\\xf7\\xf4G\\x9a\\x992J\\x9a\\xa4\\xd7F<\\xd2hL`\\x9b9I\\xa5b5H\\x11-XE\\x07cYL\\xd7x\\x03Iv\\x8f(L\\xc5\\x1bAHcJ6L\\xfb;\\x10I\"b\\xeaJ\\xb5\\xdc\\xbaG\\x00 FK\\xf3\\xfcfG\\xd26\\x9bK\\xd5ywH\\x00\\x00\\x00\\x00wG\\xa5D&\\x90\\x8fI\\x1e\\xa7\\x0cG\\xab\\xaabH\\x9a\\xe3\\xb0EH\\xbf\\xe0L.\\xbd\\x00I\\xd9\\r\\xf3L\\xf9O\\xc0I33\\x13I\\xab\\x1dHF33\\x93G\\xde\\xc5\\xdbD\\xa2\\xcb\\xabFU\\xc5\"D\\x89\\xa0ILY\\x13kHa\\x85\\x9dL\\xdf\\xb9\\xb7H\\xbc\\xbbcH\\xcd\\xa4\\xa1E\"\"\\x92G\"2\\x01E\\xd26\\x1bL\\xd5y\\xf7H\\xc8\\x92IK\\x0c\\xc2\\x9cHH\\xbf\\xe0K.\\xbd\\x00H33\\xebHw\\x0b\\xbaEDD\\x14J\\xc9\\xc3\\x8fG\\x9a/,J\\xd5\\x8d\\x08G\\xef\\xeeZIw\\xa1\\xa9F\\x9a\\x99\\x99E\\xde]BCE\\n\\xa3KC5EHv\\x8f\\xa8M\\xc5\\x1b\\xc1I\\xe1\\xa5\\xadJ\\r\\xf3QG7\\xd1\\xf6J\\x95\\xc3\\x0fGv\\x8f(L\\xc5\\x1bAH\\x10\\xa3\\x90J\\x91\\xab/G\\xfa\\xc0dI\\xb3\\x85\\xbbFv\\x8f\\xa8L\\xc5\\x1b\\xc1H\\x07cYL\\xd7x\\x03I\\xb7WxK\\x11\\xfbEH\\x07cYL\\xd7x\\x03If&\\xeeJW\\xc4\\x8fG\\x11\\x11\\xd2IU<\\xacF>7\\xeeJ`\\xc3\\x8fG\\xd26\\x9bK\\xd5ywHDD\\x94I\"\\xc6\\x0fG\\xcdl@K\\xbcp[Gff3J\\xbc`AF\\xde\\xdd\\x9dH\\xde\\x13\\x14F\\x00\\x00\\x98H\\xbc\\xeb\\xaeD\\xab\\xba\\xfaKnx\\x0fHv\\x8f\\xa8L\\xc5\\x1b\\xc1H:z`L\\xa1\\xeb\\x82H \\xda\\x86K\\x9e_\\x03I\\xd3\\xb3rJ+\\xf6\\x8aF\\xdaa\\x86K\\xbb\\x02\\xd1H\\xff\\xa6\\xb0H363Fw\\xd72K\\\\\\x9e\\xadH]\\xb9\\xcaK\\x81\\xa9EI \\xda\\x86K\\x9e_\\x03IH\\xbf\\xe0L.\\xbd\\x00I33oI\\xab\\xc0\\xeaF\\xab\\xaa*G\\x00\\xc0[D\\xab[\\xa8Mqa\\xc4Iww\\xd7G\\xcdl\\tE\"\"*J\\xeb\\x8c\\x07G\\x80\\xfc\\xf6GD\\x04HE\\xcd\\xcc\\x0eIU\\x06\\x8bF|=\\xb6I\\xe6\\xc3\\x8fF\\n\\x9d\\x01\\n\\x12edges/src2op.#size\\x12\\x86\\x01\\x1a\\x83\\x01\\n\\x80\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x02\\x01\\x01\\x02\\x01\\x01\\x01\\x01\\x02\\x01\\x02\\x02\\x01\\x01\\x01\\x01\\x02\\x01\\x02\\x01\\x01\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x01\\x02\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x02\\x01\\x01\\x01\\x01\\x01\\x02\\x01\\x01\\x01\\x01\\x02\\x01\\x02\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x02\\x02\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x02\\x01\\x01\\x02\\x01\\x01\\x01\\x01\\x02\\x01\\x01\\x01\\x02\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x02\\x02\\x01\\x01\\n\\x9e\\x01\\n\\x13nodes/operate.#size\\x12\\x86\\x01\\x1a\\x83\\x01\\n\\x80\\x01\\x03\\x01\\x01\\x03\\x01\\x01\\x03\\x02\\x03\\x02\\x03\\x03\\x03\\x02\\x02\\x01\\x03\\x01\\x03\\x03\\x02\\x03\\x01\\x02\\x01\\x02\\x03\\x01\\x02\\x01\\x01\\x01\\x02\\x01\\x02\\x03\\x03\\x01\\x03\\x02\\x01\\x01\\x03\\x01\\x03\\x01\\x01\\x01\\x01\\x01\\x02\\x01\\x03\\x01\\x01\\x02\\x01\\x03\\x03\\x01\\x01\\x02\\x01\\x01\\x01\\x01\\x02\\x01\\x02\\x01\\x03\\x03\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x03\\x02\\x03\\x01\\x01\\x03\\x01\\x03\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x03\\x01\\x01\\x02\\x01\\x01\\x01\\x01\\x02\\x03\\x01\\x02\\x03\\x01\\x01\\x01\\x01\\x01\\x01\\x03\\x03\\x01\\x03\\x01\\x01\\x01\\x01\\x01\\x01\\x02\\x03\\x01\\x01\\n\\xa4\\x04\\n\\x19nodes/source.hidden_state\\x12\\x86\\x04\\x12\\x83\\x04\\n\\x80\\x04\\x00\\x00\\x00@\\x00\\x00\\xc0@\\x00\\x00@A\\x00\\x00\\xc0@\\x00\\x00\\x80@\\x00\\x00@A\\x00\\x00@@\\x00\\x00@A\\x00\\x00\\x00@\\x00\\x00@@\\x00\\x00\\x00@\\x00\\x00@A\\x00\\x00\\x00@\\x00\\x00\\x00@\\x00\\x00\\x80A\\x00\\x00\\x00@\\x00\\x00\\x00@\\x00\\x00\\x00@\\x00\\x00@A\\x00\\x00\\xc0@\\x00\\x00\\xc0@\\x00\\x00\\x00@\\x00\\x00\\xc0@\\x00\\x00\\x00A\\x00\\x00\\x80@\\x00\\x00\\x00A\\x00\\x00\\x80@\\x00\\x00@A\\x00\\x00@@\\x00\\x00\\xc0@\\x00\\x00@A\\x00\\x00\\x80A\\x00\\x00@A\\x00\\x00\\x80A\\x00\\x00@A\\x00\\x00\\x80A\\x00\\x00@@\\x00\\x00\\x80A\\x00\\x00@@\\x00\\x00\\x80A\\x00\\x00\\x00@\\x00\\x00\\x00@\\x00\\x00\\xc0@\\x00\\x00@@\\x00\\x00\\x00A\\x00\\x00\\x80A\\x00\\x00\\x00A\\x00\\x00\\xc0@\\x00\\x00\\x80A\\x00\\x00\\x00@\\x00\\x00\\xc0@\\x00\\x00\\x80A\\x00\\x00@@\\x00\\x00\\x80A\\x00\\x00\\xc0@\\x00\\x00@A\\x00\\x00\\x00A\\x00\\x00\\xc0@\\x00\\x00\\xc0@\\x00\\x00\\x00@\\x00\\x00@@\\x00\\x00\\x80@\\x00\\x00\\x80A\\x00\\x00\\x00A\\x00\\x00\\x00@\\x00\\x00\\xc0@\\x00\\x00\\x00A\\x00\\x00\\x80@\\x00\\x00\\x80@\\x00\\x00@A\\x00\\x00\\x00A\\x00\\x00\\x00@\\x00\\x00\\x80A\\x00\\x00\\x80A\\x00\\x00\\x00A\\x00\\x00\\x00A\\x00\\x00\\xc0@\\x00\\x00\\x00A\\x00\\x00\\xc0@\\x00\\x00@A\\x00\\x00\\x80@\\x00\\x00\\x00A\\x00\\x00@@\\x00\\x00\\x00@\\x00\\x00\\x00@\\x00\\x00\\x80@\\x00\\x00\\xc0@\\x00\\x00@@\\x00\\x00@@\\x00\\x00\\x00@\\x00\\x00\\x80A\\x00\\x00\\xc0@\\x00\\x00\\x00A\\x00\\x00@@\\x00\\x00@A\\x00\\x00\\xc0@\\x00\\x00@A\\x00\\x00\\x80A\\x00\\x00\\x00A\\x00\\x00\\x80A\\x00\\x00\\x80@\\x00\\x00\\x80A\\x00\\x00\\x00A\\x00\\x00\\x80@\\x00\\x00\\x80@\\x00\\x00@A\\x00\\x00\\x00A\\x00\\x00\\x00A\\x00\\x00\\x00@\\x00\\x00\\x00A\\x00\\x00\\xc0@\\x00\\x00\\x80@\\x00\\x00\\x80A\\x00\\x00@@\\x00\\x00\\xc0@\\x00\\x00\\x00A\\x00\\x00\\x00A\\x00\\x00\\x00A\\x00\\x00\\x00A\\x00\\x00\\x80A\\x00\\x00\\x00A\\x00\\x00\\x00@\\x00\\x00\\x80A\\x00\\x00\\x00@\\x00\\x00@@\\x00\\x00\\x00@\\x00\\x00@@\\x00\\x00\\x80@\\n\\x90\\x01\\n\\x13edges/op2op.#target\\x12y\\x1aw\\nu\\x01\\x02\\x06\\x07\\x0b\\x0c\\x0e\\x10\\x11\\x13\\x16\\x16\\x18\\x19\\x1b\\x1c\\x1e #$((*+-003699<ADFGJJMNPTUXY`cdhklnosy|\\x7f\\x80\\x01\\x82\\x01\\x83\\x01\\x8e\\x01\\x8e\\x01\\x90\\x01\\x92\\x01\\x93\\x01\\x97\\x01\\x98\\x01\\x9b\\x01\\x9c\\x01\\xa6\\x01\\xa6\\x01\\xaa\\x01\\xb0\\x01\\xb2\\x01\\xb3\\x01\\xb6\\x01\\xb9\\x01\\xb9\\x01\\xc1\\x01\\xc2\\x01\\xc4\\x01\\xc5\\x01\\xc8\\x01\\xc9\\x01\\xd1\\x01\\xd4\\x01\\xd4\\x01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d676cc8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot convert the argument `type_value`: <class 'tensorflow_gnn.graph.graph_tensor.GraphTensor'> to a TensorFlow DType.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtfgnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGraphTensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/yimin/data_explore/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py:762\u001b[0m, in \u001b[0;36mas_dtype\u001b[0;34m(type_value)\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(type_value, _dtypes\u001b[38;5;241m.\u001b[39mDType):\n\u001b[1;32m    760\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _INTERN_TABLE[type_value\u001b[38;5;241m.\u001b[39mas_datatype_enum]\n\u001b[0;32m--> 762\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert the argument `type_value`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_value\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    763\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto a TensorFlow DType.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert the argument `type_value`: <class 'tensorflow_gnn.graph.graph_tensor.GraphTensor'> to a TensorFlow DType."
     ]
    }
   ],
   "source": [
    "tf.as_dtype(tfgnn.graph.graph_tensor.GraphTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4396471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual test for acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdf85f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In traditional PLM, the various life stages of the physical world are usually digitized to generate  product models. A product model is a digital description and representation of product information,  such as design drawings, description documents, and so on. In a traditional enterprise information  system, the product model is often not unified and scattered in different departments or applications.  For example, there are some differences in content, format and form between the geometric model  in product design and the process model in the process stage. In different departments, people  in different positions are responsible for different phases of products and managing them. Fig. 1  shows the five different life stages of the product and the people responsible for them. However,  the reality of product design is not plain sailing. If the original version that the designers designed  was version 1.0, the version that would eventually be sold in the market would be version 1.x or  even version 2.x, version 3.x, and so on. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In traditional PLM, the various life stages of the physical world are usually digitized to generate  product models. A product model is a digital description and representation of product information,  such as design drawings, description documents, and so on. In a traditional enterprise information  system, the product model is often not unified and scattered in different departments or applications.  For example, there are some differences in content, format and form between the geometric model  in product design and the process model in the process stage. In different departments, people  in different positions are responsible for different phases of products and managing them. Fig. 1  shows the five different life stages of the product and the people responsible for them. However,  the reality of product design is not plain sailing. If the original version that the designers designed  was version 1.0, the version that would eventually be sold in the market would be version 1.x or  even version 2.x, version 3.x, and so on. '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaeb064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd309fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0067804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecaabf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
