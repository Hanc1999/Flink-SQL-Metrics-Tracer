{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cec6769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-15 05:40:14.015142: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-15 05:40:14.171349: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-15 05:40:14.176525: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-15 05:40:14.176548: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-15 05:40:14.861659: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-15 05:40:14.861724: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-15 05:40:14.861732: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# basic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# gnn and train\n",
    "import tensorflow as tf\n",
    "import tensorflow_gnn as tfgnn\n",
    "from tensorflow_gnn.models import gat_v2, graph_sage\n",
    "\n",
    "# demo\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8edf1b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fp = './tfgnn_dataset/nexmark_isBP_train.tfrecord'\n",
    "val_fp = './tfgnn_dataset/nexmark_isBP_val.tfrecord'\n",
    "test_fp = './tfgnn_dataset/nexmark_isBP_test.tfrecord'\n",
    "schema_fp = './tfgnn_dataset/schema_poc.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34591a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset of tf.Example protos for training.\n",
    "train_ds = tf.data.TFRecordDataset(filenames=[train_fp]).prefetch(10000)\n",
    "val_ds = tf.data.TFRecordDataset(filenames=[val_fp])\n",
    "test_ds = tf.data.TFRecordDataset(filenames=[test_fp])\n",
    "# Parse the GraphTensor values.\n",
    "graph_schema = tfgnn.read_schema(schema_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2dc5af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decode_fn(record_bytes, graph_schema):\n",
    "#     graph_tensor_spec = tfgnn.create_graph_spec_from_schema_pb(graph_schema)\n",
    "#     graph = tfgnn.parse_single_example(graph_tensor_spec, record_bytes, validate=True)\n",
    "\n",
    "#     # extract label from context and remove from input graph\n",
    "#     context_features = graph.context.get_features_dict()\n",
    "#     label = context_features.pop('label_isBP')\n",
    "#     new_graph = graph.replace_features(context=context_features)\n",
    "#     return new_graph, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5432e8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5413fdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "parse_single_example() missing 1 required positional argument: 'serialized'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m example_input_spec \u001b[38;5;241m=\u001b[39m tfgnn\u001b[38;5;241m.\u001b[39mcreate_graph_spec_from_schema_pb(graph_schema)\n\u001b[0;32m----> 2\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m train_ds\u001b[38;5;241m.\u001b[39mmap(\u001b[43mtfgnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_single_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample_input_spec\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: parse_single_example() missing 1 required positional argument: 'serialized'"
     ]
    }
   ],
   "source": [
    "example_input_spec = tfgnn.create_graph_spec_from_schema_pb(graph_schema)\n",
    "train_ds = train_ds.map(tfgnn.keras.layers.ParseExample(example_input_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bbdb7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eb37564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/flink/workspace/yimin/data_explore/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphTensorSpec({'context': ContextSpec({'features': {'label_isBP': TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), 'bytes_input_rate': TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name=None), 'records_input_rate': TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name=None)}, 'sizes': TensorSpec(shape=(None, 1), dtype=tf.int32, name=None)}, TensorShape([None]), tf.int32, None), 'node_sets': {'operate': NodeSetSpec({'features': {'bytes_selectivity': RaggedTensorSpec(TensorShape([None, None, 1]), tf.float32, 1, tf.int32), 'records_selectivity': RaggedTensorSpec(TensorShape([None, None, 1]), tf.float32, 1, tf.int32), 'parallelism': RaggedTensorSpec(TensorShape([None, None, 1]), tf.float32, 1, tf.int32), 'utilization_embedding': RaggedTensorSpec(TensorShape([None, None, 6]), tf.float32, 1, tf.int32)}, 'sizes': TensorSpec(shape=(None, 1), dtype=tf.int32, name=None)}, TensorShape([None]), tf.int32, None), 'source': NodeSetSpec({'features': {'parallelism': RaggedTensorSpec(TensorShape([None, None, 1]), tf.float32, 1, tf.int32)}, 'sizes': TensorSpec(shape=(None, 1), dtype=tf.int32, name=None)}, TensorShape([None]), tf.int32, None)}, 'edge_sets': {'op2op': EdgeSetSpec({'features': {}, 'sizes': TensorSpec(shape=(None, 1), dtype=tf.int32, name=None), 'adjacency': AdjacencySpec({'#index.0': RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int32), '#index.1': RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int32)}, TensorShape([None]), tf.int32, {'#index.0': 'operate', '#index.1': 'operate'})}, TensorShape([None]), tf.int32, None), 'src2op': EdgeSetSpec({'features': {}, 'sizes': TensorSpec(shape=(None, 1), dtype=tf.int32, name=None), 'adjacency': AdjacencySpec({'#index.0': RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int32), '#index.1': RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int32)}, TensorShape([None]), tf.int32, {'#index.0': 'source', '#index.1': 'operate'})}, TensorShape([None]), tf.int32, None)}}, TensorShape([None]), tf.int32, None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0aa6311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pre-process model for initial hidden states, actually all partial models\n",
    "def node_sets_fn(node_set, *, node_set_name):\n",
    "    if node_set_name == 'source':\n",
    "        return node_set['parallelism']\n",
    "    elif node_set_name == 'operate':\n",
    "        print(node_set)\n",
    "#         stacked_non_embed = tf.stack([node_set['bytes_selectivity'], \n",
    "#                                       node_set['records_selectivity'], \n",
    "#                                       node_set['parallelism']], axis=2)\n",
    "        stacked_non_embed = tf.keras.layers.Concatenate()([node_set['bytes_selectivity'], \n",
    "                                                          node_set['records_selectivity'], \n",
    "                                                            node_set['parallelism']])\n",
    "        print('stacked_non_embed:', stacked_non_embed)\n",
    "        return tf.keras.layers.Concatenate()([ \n",
    "            node_set['utilization_embedding'],\n",
    "            stacked_non_embed,\n",
    "            ])\n",
    "\n",
    "# def edge_sets_fn(): TODO\n",
    "\n",
    "def context_fn(context):\n",
    "#     stacked_cont = tf.stack([context['bytes_input_rate'], \n",
    "#                     context['records_input_rate'],], axis=2)\n",
    "    stacked_cont = tf.keras.layers.Concatenate()([context['bytes_input_rate'], \n",
    "                                                  context['records_input_rate'],],)\n",
    "    return {'hidden_state': stacked_cont,\n",
    "            'label_isBP': context['label_isBP']}\n",
    "\n",
    "def split_fn(graph):\n",
    "    labels = tfgnn.keras.layers.Readout(from_context=True,\n",
    "                                    feature_name=\"label_isBP\")(graph)\n",
    "    graph = graph.remove_features(context=['label_isBP'])\n",
    "    assert \"label_isBP\" not in graph.context.features\n",
    "    return graph, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "596c7ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=NodeSetSpec({'features': {'bytes_selectivity': RaggedTensorSpec(TensorShape([None, None, 1]), tf.float32, 1, tf.int32), 'records_selectivity': RaggedTensorSpec(TensorShape([None, None, 1]), tf.float32, 1, tf.int32), 'parallelism': RaggedTensorSpec(TensorShape([None, None, 1]), tf.float32, 1, tf.int32), 'utilization_embedding': RaggedTensorSpec(TensorShape([None, None, 6]), tf.float32, 1, tf.int32)}, 'sizes': TensorSpec(shape=(None, 1), dtype=tf.int32, name=None)}, TensorShape([None]), tf.int32, None), description=\"created by layer 'input_3'\")\n",
      "stacked_non_embed: KerasTensor(type_spec=RaggedTensorSpec(TensorShape([None, None, 3]), tf.float32, 1, tf.int32), description=\"created by layer 'concatenate_1'\")\n",
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'tensorflow_gnn.graph.graph_tensor._ImmutableMapping'>\n",
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'tensorflow_gnn.graph.graph_tensor._ImmutableMapping'>\n",
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'tensorflow_gnn.graph.graph_tensor._ImmutableMapping'>\n"
     ]
    }
   ],
   "source": [
    "# Define and apply the preprocessing model. (now starts to define a graph model with the view of a scalar sample)\n",
    "preproc_input = tf.keras.layers.Input(type_spec=preproc_input_spec)\n",
    "graph = tfgnn.keras.layers.MapFeatures(node_sets_fn=node_sets_fn,\n",
    "                                      context_fn=context_fn,\n",
    "                                      )(preproc_input)  # With preprocessed features, see below.\n",
    "graph = graph.merge_batch_to_components()  # See section \"Merging a batch\".\n",
    "\n",
    "graph, mask = tfgnn.keras.layers.PadToTotalSizes(size_constraints)(graph) # pad\n",
    "graph, labels = split_fn(graph)  # See section \"Splitting the label off ...\".\n",
    "\n",
    "preproc_model = tf.keras.Model(preproc_input, (graph, labels, mask))  # now we defined the pp-model\n",
    "\n",
    "# above is just a defined computing process, the following is the process process on the whole dataset\n",
    "dataset = dataset.map(preproc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f46b7a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### testing\n",
    "DATASET_SIZE = 5460\n",
    "train_size = int(0.7 * DATASET_SIZE)\n",
    "val_size = int(0.15 * DATASET_SIZE)\n",
    "test_size = int(0.15 * DATASET_SIZE)\n",
    "\n",
    "train_dataset = dataset.take(train_size)\n",
    "test_dataset = dataset.skip(train_size)\n",
    "val_dataset = test_dataset.skip(test_size)\n",
    "test_dataset = test_dataset.take(test_size)\n",
    "\n",
    "dataset = train_dataset\n",
    "### end testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a11f4e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['hidden_state'], ['hidden_state'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assert list(graph.node_sets[\"operate\"].keys()) == [tfgnn.HIDDEN_STATE]\n",
    "# BUG: not working, use manual checking:\n",
    "list(graph.node_sets['operate'].get_features_dict().keys()),list(graph.node_sets['source'].get_features_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a5492e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define gnn update logic (using gatv2)\n",
    "def gnn(graph):\n",
    "    for i in range(2):\n",
    "        graph = gat_v2.GATv2MPNNGraphUpdate(units=5, message_dim=5, num_heads=1, receiver_tag=tfgnn.TARGET)(graph)\n",
    "#         graph = gat_v2.GATv2MPNNGraphUpdate(units=5, message_dim=5, num_heads=1, receiver_tag=tfgnn.SOURCE,)(graph)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd748526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphTensorSpec({'context': ContextSpec({'features': {'hidden_state': TensorSpec(shape=(11, 2), dtype=tf.float32, name=None)}, 'sizes': TensorSpec(shape=(11,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, None), 'node_sets': {'operate': NodeSetSpec({'features': {'hidden_state': TensorSpec(shape=(27, 9), dtype=tf.float32, name=None)}, 'sizes': TensorSpec(shape=(11,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, None), 'source': NodeSetSpec({'features': {'hidden_state': TensorSpec(shape=(11, 1), dtype=tf.float32, name=None)}, 'sizes': TensorSpec(shape=(11,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, None)}, 'edge_sets': {'op2op': EdgeSetSpec({'features': {}, 'sizes': TensorSpec(shape=(11,), dtype=tf.int32, name=None), 'adjacency': AdjacencySpec({'#index.0': TensorSpec(shape=(16,), dtype=tf.int32, name=None), '#index.1': TensorSpec(shape=(16,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, {'#index.0': 'operate', '#index.1': 'operate'})}, TensorShape([]), tf.int32, None), 'src2op': EdgeSetSpec({'features': {}, 'sizes': TensorSpec(shape=(11,), dtype=tf.int32, name=None), 'adjacency': AdjacencySpec({'#index.0': TensorSpec(shape=(16,), dtype=tf.int32, name=None), '#index.1': TensorSpec(shape=(16,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, {'#index.0': 'source', '#index.1': 'operate'})}, TensorShape([]), tf.int32, None)}}, TensorShape([]), tf.int32, None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_input_spec, _, __ = dataset.element_spec\n",
    "model_input_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "728ea06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function check_scalar_graph_piece at 0x7fe8c1aa4b80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: annotated name 'piece_name' can't be nonlocal (__autograph_generated_filecjtikw8n.py, line 18)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function check_scalar_graph_piece at 0x7fe8c1aa4b80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: annotated name 'piece_name' can't be nonlocal (__autograph_generated_filecjtikw8n.py, line 18)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [()]                 0           []                               \n",
      "                                                                                                  \n",
      " graph_update (GraphUpdate)     ()                   270         ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " graph_update_1 (GraphUpdate)   ()                   190         ['graph_update[0][0]']           \n",
      "                                                                                                  \n",
      " pool (Pool)                    (11, 1)              0           ['graph_update_1[0][0]']         \n",
      "                                                                                                  \n",
      " pool_1 (Pool)                  (11, 5)              0           ['graph_update_1[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (11, 6)              0           ['pool[0][0]',                   \n",
      "                                                                  'pool_1[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (11, 1)              7           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 467\n",
      "Trainable params: 467\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define and train the main model.\n",
    "model_input_spec, _, __ = dataset.element_spec  # Drop the spec for the labels.\n",
    "model_input = tf.keras.layers.Input(type_spec=model_input_spec)\n",
    "graph = gnn(model_input) # apply gnn model\n",
    "\n",
    "# Classifying each graph as a whole, based on an aggregation of the node states from one node set\n",
    "pooled_features_s = tfgnn.keras.layers.Pool(tfgnn.CONTEXT, \"mean\", node_set_name=\"source\")(graph)\n",
    "pooled_features_op = tfgnn.keras.layers.Pool(tfgnn.CONTEXT, \"mean\", node_set_name=\"operate\")(graph)\n",
    "\n",
    "pooled_features = tf.keras.layers.concatenate([pooled_features_s, pooled_features_op])\n",
    "\n",
    "# logits = tf.keras.layers.Dense(1)(pooled_features_op) # output\n",
    "logits = tf.keras.layers.Dense(1)(pooled_features) # output\n",
    "\n",
    "model = tf.keras.Model(model_input, logits)\n",
    "\n",
    "# compile this model for binary classification\n",
    "model.compile(tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d646cbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 [==============================] - 4s 7ms/step - loss: 1.7392\n",
      "Epoch 2/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.6617\n",
      "Epoch 3/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.4640\n",
      "Epoch 4/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.4764\n",
      "Epoch 5/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.3316\n",
      "Epoch 6/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.0416\n",
      "Epoch 7/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8865\n",
      "Epoch 8/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8689\n",
      "Epoch 9/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8725\n",
      "Epoch 10/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7396\n",
      "Epoch 11/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7690\n",
      "Epoch 12/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7376\n",
      "Epoch 13/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7507\n",
      "Epoch 14/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7249\n",
      "Epoch 15/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7233\n",
      "Epoch 16/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6491\n",
      "Epoch 17/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6280\n",
      "Epoch 18/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5797\n",
      "Epoch 19/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6898\n",
      "Epoch 20/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6821\n",
      "Epoch 21/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6460\n",
      "Epoch 22/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7032\n",
      "Epoch 23/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6494\n",
      "Epoch 24/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5626\n",
      "Epoch 25/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6237\n",
      "Epoch 26/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6278\n",
      "Epoch 27/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6446\n",
      "Epoch 28/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5774\n",
      "Epoch 29/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6166\n",
      "Epoch 30/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5806\n",
      "Epoch 31/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5996\n",
      "Epoch 32/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5658\n",
      "Epoch 33/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5703\n",
      "Epoch 34/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6451\n",
      "Epoch 35/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5956\n",
      "Epoch 36/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6624\n",
      "Epoch 37/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5664\n",
      "Epoch 38/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5569\n",
      "Epoch 39/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5201\n",
      "Epoch 40/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6328\n",
      "Epoch 41/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5788\n",
      "Epoch 42/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5338\n",
      "Epoch 43/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5915\n",
      "Epoch 44/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5709\n",
      "Epoch 45/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5698\n",
      "Epoch 46/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6594\n",
      "Epoch 47/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5783\n",
      "Epoch 48/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6005\n",
      "Epoch 49/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6007\n",
      "Epoch 50/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5503\n",
      "Epoch 51/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5981\n",
      "Epoch 52/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5642\n",
      "Epoch 53/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5657\n",
      "Epoch 54/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6123\n",
      "Epoch 55/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5619\n",
      "Epoch 56/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6078\n",
      "Epoch 57/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5801\n",
      "Epoch 58/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5594\n",
      "Epoch 59/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5744\n",
      "Epoch 60/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5650\n",
      "Epoch 61/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5252\n",
      "Epoch 62/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5816\n",
      "Epoch 63/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5394\n",
      "Epoch 64/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5681\n",
      "Epoch 65/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5846\n",
      "Epoch 66/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5579\n",
      "Epoch 67/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5498\n",
      "Epoch 68/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5386\n",
      "Epoch 69/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5599\n",
      "Epoch 70/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6147\n",
      "Epoch 71/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4998\n",
      "Epoch 72/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5419\n",
      "Epoch 73/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5499\n",
      "Epoch 74/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5742\n",
      "Epoch 75/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5353\n",
      "Epoch 76/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5443\n",
      "Epoch 77/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5474\n",
      "Epoch 78/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5935\n",
      "Epoch 79/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5547\n",
      "Epoch 80/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5362\n",
      "Epoch 81/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5653\n",
      "Epoch 82/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5847\n",
      "Epoch 83/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5389\n",
      "Epoch 84/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5176\n",
      "Epoch 85/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6087\n",
      "Epoch 86/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5634\n",
      "Epoch 87/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5419\n",
      "Epoch 88/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5322\n",
      "Epoch 89/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5561\n",
      "Epoch 90/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5156\n",
      "Epoch 91/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5624\n",
      "Epoch 92/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6084\n",
      "Epoch 93/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5482\n",
      "Epoch 94/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5597\n",
      "Epoch 95/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5860\n",
      "Epoch 96/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5230\n",
      "Epoch 97/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5358\n",
      "Epoch 98/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5671\n",
      "Epoch 99/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5568\n",
      "Epoch 100/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5168\n",
      "Epoch 101/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5392\n",
      "Epoch 102/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5200\n",
      "Epoch 103/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4684\n",
      "Epoch 104/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5146\n",
      "Epoch 105/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5256\n",
      "Epoch 106/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4921\n",
      "Epoch 107/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5431\n",
      "Epoch 108/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5196\n",
      "Epoch 109/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4926\n",
      "Epoch 110/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5474\n",
      "Epoch 111/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5678\n",
      "Epoch 112/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5430\n",
      "Epoch 113/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5145\n",
      "Epoch 114/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5507\n",
      "Epoch 115/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5521\n",
      "Epoch 116/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5158\n",
      "Epoch 117/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5619\n",
      "Epoch 118/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5291\n",
      "Epoch 119/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4679\n",
      "Epoch 120/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5324\n",
      "Epoch 121/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5584\n",
      "Epoch 122/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4795\n",
      "Epoch 123/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4933\n",
      "Epoch 124/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5051\n",
      "Epoch 125/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5014\n",
      "Epoch 126/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5240\n",
      "Epoch 127/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5020\n",
      "Epoch 128/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5043\n",
      "Epoch 129/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4868\n",
      "Epoch 130/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5462\n",
      "Epoch 131/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6259\n",
      "Epoch 132/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5291\n",
      "Epoch 133/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6108\n",
      "Epoch 134/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5716\n",
      "Epoch 135/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5423\n",
      "Epoch 136/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5100\n",
      "Epoch 137/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5396\n",
      "Epoch 138/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5280\n",
      "Epoch 139/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5177\n",
      "Epoch 140/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5096\n",
      "Epoch 141/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5004\n",
      "Epoch 142/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5509\n",
      "Epoch 143/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5110\n",
      "Epoch 144/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5712\n",
      "Epoch 145/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5096\n",
      "Epoch 146/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5621\n",
      "Epoch 147/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5307\n",
      "Epoch 148/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5418\n",
      "Epoch 149/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5332\n",
      "Epoch 150/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6032\n",
      "Epoch 151/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4909\n",
      "Epoch 152/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4790\n",
      "Epoch 153/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5969\n",
      "Epoch 154/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5314\n",
      "Epoch 155/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5812\n",
      "Epoch 156/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5163\n",
      "Epoch 157/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5615\n",
      "Epoch 158/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4701\n",
      "Epoch 159/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5074\n",
      "Epoch 160/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5081\n",
      "Epoch 161/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4999\n",
      "Epoch 162/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5339\n",
      "Epoch 163/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5420\n",
      "Epoch 164/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5083\n",
      "Epoch 165/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5524\n",
      "Epoch 166/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4870\n",
      "Epoch 167/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5396\n",
      "Epoch 168/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5544\n",
      "Epoch 169/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5441\n",
      "Epoch 170/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6079\n",
      "Epoch 171/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5605\n",
      "Epoch 172/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5006\n",
      "Epoch 173/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5032\n",
      "Epoch 174/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5543\n",
      "Epoch 175/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5397\n",
      "Epoch 176/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5830\n",
      "Epoch 177/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5457\n",
      "Epoch 178/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4856\n",
      "Epoch 179/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5071\n",
      "Epoch 180/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4969\n",
      "Epoch 181/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5717\n",
      "Epoch 182/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5489\n",
      "Epoch 183/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5070\n",
      "Epoch 184/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4797\n",
      "Epoch 185/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5663\n",
      "Epoch 186/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5216\n",
      "Epoch 187/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4767"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nassertion failed: [Could not pad <op2op> as it already has more edges then it is allowed by the `total_sizes.total_num_edges[<op2op>]`.] [Condition x == y did not hold element-wise:] [x (model/pad_to_total_sizes/LessEqual_5:0) = ] [0] [y (model/pad_to_total_sizes/assert_equal_15/y:0) = ] [1]\n\t [[{{node model/pad_to_total_sizes/assert_equal_15/Assert/AssertGuard/Assert}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_9521]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                     \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/yimin/data_explore/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/workspace/yimin/data_explore/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nassertion failed: [Could not pad <op2op> as it already has more edges then it is allowed by the `total_sizes.total_num_edges[<op2op>]`.] [Condition x == y did not hold element-wise:] [x (model/pad_to_total_sizes/LessEqual_5:0) = ] [0] [y (model/pad_to_total_sizes/assert_equal_15/y:0) = ] [1]\n\t [[{{node model/pad_to_total_sizes/assert_equal_15/Assert/AssertGuard/Assert}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_9521]"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit( dataset,\n",
    "                     steps_per_epoch=10,\n",
    "                     epochs=200,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bf9f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the combined SavedModel for serving.\n",
    "# this part can be waived for current situation..\n",
    "# serving_input = tf.keras.layers.Input(shape=[],  # The batch dim is implied.\n",
    "#                                       dtype=tf.string, name=\"examples\")\n",
    "# preproc_input = tfgnn.keras.layers.ParseExample(example_input_spec)(serving_input)\n",
    "# serving_model_input, _ = preproc_model(preproc_input)  # Drop labels.\n",
    "# serving_logits = model(serving_model_input)\n",
    "# serving_output = {\"logits\": tf.keras.layers.Layer(name=\"logits\")(serving_logits)}\n",
    "# exported_model = tf.keras.Model(serving_input, serving_output)\n",
    "# exported_model.save(\"/tmp/exported_keras_model\", include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16d5f58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.stack([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9fe1521c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k, hist in history.history.items():\n",
    "    plt.plot(hist)\n",
    "    plt.title(k)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a0a2d100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=(GraphTensorSpec({'context': ContextSpec({'features': {'hidden_state': TensorSpec(shape=(11, 2), dtype=tf.float32, name=None)}, 'sizes': TensorSpec(shape=(11,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, None), 'node_sets': {'source': NodeSetSpec({'features': {'hidden_state': TensorSpec(shape=(11, 1), dtype=tf.float32, name=None)}, 'sizes': TensorSpec(shape=(11,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, None), 'operate': NodeSetSpec({'features': {'hidden_state': TensorSpec(shape=(27, 9), dtype=tf.float32, name=None)}, 'sizes': TensorSpec(shape=(11,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, None)}, 'edge_sets': {'op2op': EdgeSetSpec({'features': {}, 'sizes': TensorSpec(shape=(11,), dtype=tf.int32, name=None), 'adjacency': AdjacencySpec({'#index.0': TensorSpec(shape=(16,), dtype=tf.int32, name=None), '#index.1': TensorSpec(shape=(16,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, {'#index.0': 'operate', '#index.1': 'operate'})}, TensorShape([]), tf.int32, None), 'src2op': EdgeSetSpec({'features': {}, 'sizes': TensorSpec(shape=(11,), dtype=tf.int32, name=None), 'adjacency': AdjacencySpec({'#index.0': TensorSpec(shape=(16,), dtype=tf.int32, name=None), '#index.1': TensorSpec(shape=(16,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, {'#index.0': 'source', '#index.1': 'operate'})}, TensorShape([]), tf.int32, None)}}, TensorShape([]), tf.int32, None), TensorSpec(shape=(11,), dtype=tf.int64, name=None), TensorSpec(shape=(11,), dtype=tf.bool, name=None))>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31759c97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
