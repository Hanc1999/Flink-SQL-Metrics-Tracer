{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbd9c152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-08 07:49:23.825921: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-08 07:49:23.966354: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-08 07:49:23.970381: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-08 07:49:23.970396: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-08 07:49:24.656119: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-08 07:49:24.656177: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-08 07:49:24.656185: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_gnn as tfgnn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f396eced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test follow tut-doc\n",
    "schema = tfgnn.read_schema('./tfgnn_test/schema_test.pbtxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0efe921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (issue proposed)\n",
    "# with tf.io.TFRecordWriter('./tfgnn_test/dummy/try_write.tfrecord') as writer:\n",
    "#     for _ in range(10):\n",
    "#         graph = tfgnn.random_graph_tensor(schema)\n",
    "#         example = tfgnn.write_example(graph)\n",
    "#         writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79b80887",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter('./tfgnn_test/dummy/try_write.tfrecord') as writer:\n",
    "    for _ in range(1):\n",
    "        spec = tfgnn.create_graph_spec_from_schema_pb(schema)\n",
    "        graph = tfgnn.random_graph_tensor(spec)\n",
    "        example = tfgnn.write_example(graph)\n",
    "        writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4c8c884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphTensor(\n",
       "  context=Context(features={'label_isBP': <tf.Tensor: shape=(1,), dtype=tf.int64>, 'bytes_input_rate': <tf.Tensor: shape=(1,), dtype=tf.float32>, 'records_input_rate': <tf.Tensor: shape=(1,), dtype=tf.float32>}, sizes=[1], shape=(), indices_dtype=tf.int32),\n",
       "  node_set_names=['source', 'operate'],\n",
       "  edge_set_names=['op2op', 'src2op'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015a5aab",
   "metadata": {},
   "source": [
    "### here we try to make a hand-made in-memory GraphTensor instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5c70501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "context {\n",
       "  features {\n",
       "    key: \"bytes_input_rate\"\n",
       "    value {\n",
       "      description: \"Bytes input rate from the source vertex.\"\n",
       "      dtype: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  features {\n",
       "    key: \"label_isBP\"\n",
       "    value {\n",
       "      description: \"Label: whether job back-pressured.\"\n",
       "      dtype: DT_INT64\n",
       "    }\n",
       "  }\n",
       "  features {\n",
       "    key: \"records_input_rate\"\n",
       "    value {\n",
       "      description: \"Records input rate from the source vertex.\"\n",
       "      dtype: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node_sets {\n",
       "  key: \"operate\"\n",
       "  value {\n",
       "    description: \"The non-source vertex.\"\n",
       "    features {\n",
       "      key: \"bytes_selectivity\"\n",
       "      value {\n",
       "        description: \"Vertex\\342\\200\\231s selectivity for out/in-bytes.\"\n",
       "        dtype: DT_FLOAT\n",
       "      }\n",
       "    }\n",
       "    features {\n",
       "      key: \"parallelism\"\n",
       "      value {\n",
       "        description: \"Vertex\\342\\200\\231s set parallelism.\"\n",
       "        dtype: DT_INT64\n",
       "      }\n",
       "    }\n",
       "    features {\n",
       "      key: \"records_selectivity\"\n",
       "      value {\n",
       "        description: \"Vertex\\342\\200\\231s selectivity for out/in-records.\"\n",
       "        dtype: DT_FLOAT\n",
       "      }\n",
       "    }\n",
       "    features {\n",
       "      key: \"utilization_embedding\"\n",
       "      value {\n",
       "        description: \"Vertex\\342\\200\\231s learned embedding for utilization.\"\n",
       "        dtype: DT_FLOAT\n",
       "        shape {\n",
       "          dim {\n",
       "            size: 6\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node_sets {\n",
       "  key: \"source\"\n",
       "  value {\n",
       "    description: \"The vertex with source-operator.\"\n",
       "    features {\n",
       "      key: \"parallelism\"\n",
       "      value {\n",
       "        description: \"Vertex\\342\\200\\231s set parallelism.\"\n",
       "        dtype: DT_INT64\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "edge_sets {\n",
       "  key: \"op2op\"\n",
       "  value {\n",
       "    description: \"Intermediate stream between operate vertices.\"\n",
       "    features {\n",
       "      key: \"type\"\n",
       "      value {\n",
       "        description: \"Stream type.\"\n",
       "        dtype: DT_INT64\n",
       "        shape {\n",
       "          dim {\n",
       "            size: 3\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "    source: \"operate\"\n",
       "    target: \"operate\"\n",
       "  }\n",
       "}\n",
       "edge_sets {\n",
       "  key: \"src2op\"\n",
       "  value {\n",
       "    description: \"Input stream from the source vertex.\"\n",
       "    features {\n",
       "      key: \"type\"\n",
       "      value {\n",
       "        description: \"Stream type.\"\n",
       "        dtype: DT_INT64\n",
       "        shape {\n",
       "          dim {\n",
       "            size: 3\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "    source: \"source\"\n",
       "    target: \"operate\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first review the schema\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5b63314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tfgnn.GraphTensor.from_pieces(\n",
    "    node_sets={\n",
    "        'source': tfgnn.NodeSet.from_fields(\n",
    "            sizes=tf.constant([1]),\n",
    "            features={\n",
    "                'parallelism': tf.constant([4,])\n",
    "            }),\n",
    "        'operate': tfgnn.NodeSet.from_fields(\n",
    "            sizes=tf.constant([2]),\n",
    "            features={\n",
    "                'bytes_selectivity': tf.constant([0.9, 0.0,]),\n",
    "                'records_selectivity': tf.constant([0.1, 0.0,]),\n",
    "                'parallelism': tf.constant([4, 4,]),\n",
    "                'utilization_embedding': tf.constant([[1,2,3,4,5,6,],[6,5,4,3,2,1,]]),\n",
    "            }),\n",
    "    },\n",
    "    edge_sets={\n",
    "        'src2op': tfgnn.EdgeSet.from_fields(\n",
    "            sizes=tf.constant([1]),\n",
    "            adjacency=tfgnn.Adjacency.from_indices(\n",
    "                source=('source', tf.constant([0,])),\n",
    "                target=('operate', tf.constant([0,])))),\n",
    "\n",
    "#         'op2op': tfgnn.EdgeSet.from_fields(\n",
    "#             sizes=tf.constant([1]),\n",
    "#             adjacency=tfgnn.Adjacency.from_indices(\n",
    "#                 source=('operate', tf.constant([0,])),\n",
    "#                 target=('operate', tf.constant([1,])))),\n",
    "\n",
    "        ### test what if no op2op edge:\n",
    "            'op2op': tfgnn.EdgeSet.from_fields(\n",
    "            sizes=tf.constant([0]),\n",
    "            adjacency=tfgnn.Adjacency.from_indices(\n",
    "                source=('operate', tf.constant([], dtype=tf.int64)),\n",
    "                target=('operate', tf.constant([], dtype=tf.int64)))),\n",
    "        ### test result: no err raised\n",
    "\n",
    "    },\n",
    "    context=tfgnn.Context.from_fields(\n",
    "            features={\n",
    "                'bytes_input_rate': tf.constant([200,]),\n",
    "                'records_input_rate': tf.constant([20,]),\n",
    "                'label_isBP': tf.constant([1]),\n",
    "            })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e5e3680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph.spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f616440d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"context/bytes_input_rate\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 200\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"context/label_isBP\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"context/records_input_rate\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 20\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"edges/op2op.#size\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"edges/op2op.#source\"\n",
      "    value {\n",
      "      int64_list {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"edges/op2op.#target\"\n",
      "    value {\n",
      "      int64_list {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"edges/src2op.#size\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"edges/src2op.#source\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"edges/src2op.#target\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"nodes/operate.#size\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 2\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"nodes/operate.bytes_selectivity\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.8999999761581421\n",
      "        value: 0.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"nodes/operate.parallelism\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 4\n",
      "        value: 4\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"nodes/operate.records_selectivity\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.10000000149011612\n",
      "        value: 0.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"nodes/operate.utilization_embedding\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "        value: 2\n",
      "        value: 3\n",
      "        value: 4\n",
      "        value: 5\n",
      "        value: 6\n",
      "        value: 6\n",
      "        value: 5\n",
      "        value: 4\n",
      "        value: 3\n",
      "        value: 2\n",
      "        value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"nodes/source.#size\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"nodes/source.parallelism\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 4\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.io.TFRecordWriter('./tfgnn_test/dummy/try_write.tfrecord') as writer:\n",
    "    example = tfgnn.write_example(graph)\n",
    "    print(example)\n",
    "#     writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f44c6eb",
   "metadata": {},
   "source": [
    "### here we try to implement the GraphTensor maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d9552952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22, 6), 22)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape, len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "26183018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudo data\n",
    "embeddings = np.array([[ 3.57395299e-02,  8.06235150e-03, -3.74955907e-02,\n",
    "        -3.39482054e-02,  1.23462565e-02, -1.59011856e-02],\n",
    "       [ 1.13631797e+00, -8.71300697e+00, -1.53374147e+01,\n",
    "        -2.91174412e+01, -1.15212708e+01, -1.00926161e+01],\n",
    "       [ 4.74400806e+00,  1.45451097e+01, -3.14076691e+01,\n",
    "        -1.09569511e+01,  1.78568554e+01, -9.63525963e+00],\n",
    "       [ 2.18789787e+01, -5.58547354e+00,  9.31024742e+00,\n",
    "         2.55261765e+01,  2.58095055e+01, -1.60838947e+01],\n",
    "       [-4.02473211e+00, -2.86237001e+00, -2.35737762e+01,\n",
    "        -1.08697271e+01, -2.11060047e+01, -1.05461378e+01],\n",
    "       [ 1.07403269e+01,  2.78513813e+01, -4.96649208e+01,\n",
    "        -1.36362076e+01,  2.01553040e+01, -4.45996141e+00],\n",
    "       [-2.72763801e+00, -7.94400358e+00,  3.45084229e+01,\n",
    "         2.99869728e+01,  3.94443178e+00, -9.77673531e+00],\n",
    "       [-5.55253744e+00, -3.76001549e+00, -2.15469303e+01,\n",
    "        -1.03292923e+01, -1.79221001e+01, -1.14029608e+01],\n",
    "       [-1.49511995e+01, -5.74085093e+00, -1.35172186e+01,\n",
    "        -3.00543041e+01, -7.92033863e+00, -1.16169939e+01],\n",
    "       [ 2.81525135e+01, -9.28903770e+00, -3.20226240e+00,\n",
    "         2.87621555e+01,  2.52876778e+01, -1.40687141e+01],\n",
    "       [ 3.96669126e+00, -6.40941238e+00,  1.51890516e+01,\n",
    "         5.13268518e+00,  1.93375664e+01, -1.92107430e+01],\n",
    "       [ 5.56613743e-01, -7.33412218e+00, -3.16105080e+01,\n",
    "        -1.40403166e+01, -1.71877136e+01, -1.34753399e+01],\n",
    "       [-3.89417648e+01,  3.53432268e-01, -2.09219856e+01,\n",
    "        -2.29946365e+01, -3.46543908e+00, -1.43928156e+01],\n",
    "       [-9.91747952e+00,  4.01413441e+00, -6.68075657e+00,\n",
    "        -3.79401231e+00, -2.38905773e+01, -3.48761511e+00],\n",
    "       [ 5.50344801e+00, -1.62924538e+01, -2.97262840e+01,\n",
    "        -2.59126968e+01, -1.15528898e+01, -2.16320248e+01],\n",
    "       [-2.47912846e+01, -1.00922127e+01, -2.83760948e+01,\n",
    "        -2.82528152e+01,  8.10468960e+00, -1.74723625e+01],\n",
    "       [-8.24438381e+00, -7.75321865e+00,  4.25156593e+00,\n",
    "        -1.33596029e+01, -2.22319984e+01, -1.87092323e+01],\n",
    "       [ 1.17066078e+01, -6.87926340e+00, -1.29598494e+01,\n",
    "        -6.76033020e+00,  2.34065475e+01, -1.90525017e+01],\n",
    "       [-4.49013233e+00, -1.63534107e+01,  3.00725708e+01,\n",
    "         1.63671646e+01,  1.59018822e+01, -1.44117346e+01],\n",
    "       [ 1.57391024e+01, -1.23704939e+01,  3.80741143e+00,\n",
    "         1.42136726e+01,  3.15935974e+01, -1.49392471e+01],\n",
    "       [-4.67871571e+00, -4.61830807e+00,  9.04006672e+00,\n",
    "        -3.76126242e+00, -2.62182541e+01, -1.44378605e+01],\n",
    "       [ 2.03958874e+01,  1.51550055e+01, -2.60176182e+01,\n",
    "        -1.07382650e+01,  1.63624554e+01, -8.23231506e+00]],)\n",
    "\n",
    "keys = ['', 'q4v1', 'q4v2', 'q4v3', 'q5v1', 'q5v2', 'q5v3', 'q7v2', 'q9v1', 'q9v2', 'q3v1', 'q8v1', 'q8v2', 'q8v3', 'q11v1', 'q12v1', 'q16v1', 'q17v1', 'q18v1', 'q19v1', 'q20v1', 'q7v1']\n",
    "\n",
    "row = {'qid': 4, 'pseudoInputBytesRate': 6.826667e+04, 'pseudoInputRecordsRate': 1.677400e+03, 'vPs': '[2,2,2,2]', 'isBP': False }\n",
    "\n",
    "DAG = {4: [[0,1,2,],[1,2,3]]}\n",
    "\n",
    "selectivities = {'true_selectivity_records': {(3, 1): 0.0,\n",
    "  (4, 1): 0.6912518503136663,\n",
    "  (4, 2): 0.30498580132267283,\n",
    "  (4, 3): 0.0,\n",
    "  (5, 1): 0.41727981517418555,\n",
    "  (5, 2): 0.0002818181698208069,\n",
    "  (5, 3): 0.0,\n",
    "  (7, 1): 1.4371688367287183e-06,\n",
    "  (7, 2): 0.0,\n",
    "  (8, 1): 0.7527639835282449,\n",
    "  (8, 2): 0.13995420932258765,\n",
    "  (8, 3): 0.0,\n",
    "  (9, 1): 0.6910047481349646,\n",
    "  (9, 2): 0.0,\n",
    "  (10, 1): 0.0,\n",
    "  (11, 1): 0.0,\n",
    "  (12, 1): 0.0,\n",
    "  (15, 1): 0.0,\n",
    "  (16, 1): 0.0,\n",
    "  (17, 1): 0.0,\n",
    "  (18, 1): 0.0,\n",
    "  (19, 1): 0.0,\n",
    "  (20, 1): 0.0},\n",
    " 'true_selectivity_bytes': {(3, 1): 0.0,\n",
    "  (4, 1): 0.6753447790534584,\n",
    "  (4, 2): 0.24189611914570447,\n",
    "  (4, 3): 0.0,\n",
    "  (5, 1): 0.561559493159304,\n",
    "  (5, 2): 0.05540181310893824,\n",
    "  (5, 3): 0.0,\n",
    "  (7, 1): 8.078045795509282e-05,\n",
    "  (7, 2): 0.0,\n",
    "  (8, 1): 0.7724989981804398,\n",
    "  (8, 2): 0.14459429349535358,\n",
    "  (8, 3): 0.0,\n",
    "  (9, 1): 1.9174096940261498,\n",
    "  (9, 2): 0.0,\n",
    "  (10, 1): 0.0,\n",
    "  (11, 1): 0.0,\n",
    "  (12, 1): 0.0,\n",
    "  (15, 1): 0.0,\n",
    "  (16, 1): 0.0,\n",
    "  (17, 1): 0.0,\n",
    "  (18, 1): 0.0,\n",
    "  (19, 1): 0.0,\n",
    "  (20, 1): 0.0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2f869d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph_tensor(**kwargs):\n",
    "    # function for job-level \n",
    "    \n",
    "    nodes = kwargs['nodes']     # {source: [parallelisms], \n",
    "                                #  operate: [parallelisms, \n",
    "#                                            bytes_selectivities,\n",
    "#                                            records_selectivities,\n",
    "#                                            utilization_embeddings]}\n",
    "    edges = kwargs['edges']     # {[[sources,],[targets,]]}, {src2op, op2op}\n",
    "    context = kwargs['context'] # [3], [bytes_inpute_rate, records_input_rate, label_isBP,]\n",
    "    \n",
    "    graph = tfgnn.GraphTensor.from_pieces(\n",
    "        # make node_sets\n",
    "        node_sets={\n",
    "            'source': tfgnn.NodeSet.from_fields(\n",
    "                sizes=tf.constant([len(nodes['source'])]),\n",
    "                features={\n",
    "                    'parallelism': tf.constant(nodes['source'])\n",
    "                }),\n",
    "            'operate': tfgnn.NodeSet.from_fields(\n",
    "                sizes=tf.constant([len(nodes['operate'][0])]),\n",
    "                features={\n",
    "                    'parallelism': tf.constant(nodes['operate'][0]),\n",
    "                    'bytes_selectivity': tf.constant(nodes['operate'][1]),\n",
    "                    'records_selectivity': tf.constant(nodes['operate'][2]),\n",
    "                    'utilization_embedding': tf.constant(nodes['operate'][3]),\n",
    "                }),\n",
    "        },\n",
    "        # make edge_sets\n",
    "        edge_sets={\n",
    "            'src2op': tfgnn.EdgeSet.from_fields(\n",
    "                sizes=tf.constant([len(edges['src2op'][0])]),\n",
    "                adjacency=tfgnn.Adjacency.from_indices(\n",
    "                    source=('source', tf.constant(edges['src2op'][0])),\n",
    "                    target=('operate', tf.constant(edges['src2op'][1])))),\n",
    "            'op2op': tfgnn.EdgeSet.from_fields(\n",
    "                sizes=tf.constant([len(edges['op2op'][0])]),\n",
    "                adjacency=tfgnn.Adjacency.from_indices(\n",
    "                    source=('operate', tf.constant(edges['op2op'][0])),\n",
    "                    target=('operate', tf.constant(edges['op2op'][1])))),\n",
    "        },\n",
    "        # make context\n",
    "        context=tfgnn.Context.from_fields(\n",
    "                features={\n",
    "                    'bytes_input_rate': tf.constant([context[0],]),\n",
    "                    'records_input_rate': tf.constant([context[1],]),\n",
    "                    'label_isBP': tf.constant([context[2]]),\n",
    "                })\n",
    "    )\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "16ef6c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class graph_tensor_dataset_maker:\n",
    "    def __init__(self, embeddings, keys, DAG, selectivities, o_fp='./tfgnn_test/dummy/try_write.tfrecord'):\n",
    "        self.embeddings = embeddings\n",
    "        self.keys = list(keys) # ndarray -> list\n",
    "        self.DAG = DAG\n",
    "        self.selectivities = selectivities\n",
    "        self.o_fp = o_fp\n",
    "    \n",
    "    def single_writer(self, graph, demo=True):\n",
    "        with tf.io.TFRecordWriter(self.o_fp) as writer:\n",
    "            example = tfgnn.write_example(graph)\n",
    "            if demo:\n",
    "                print(example)\n",
    "            writer.write(example.SerializeToString())\n",
    "        \n",
    "#     row = {'qid': 4, 'pseudoInputBytesRate': 0.9, 'pseudoInputRecordsRate': 0.1, 'vPs': '[2,2,2,2]', 'isBP': False }\n",
    "    def make(self, row):\n",
    "        # encode sample row data\n",
    "        qid = row['qid']\n",
    "        inBrate = row['pseudoInputBytesRate']\n",
    "        inRrate = row['pseudoInputRecordsRate']\n",
    "        parallels = eval(row['vPs'])\n",
    "        label = row['isBP']\n",
    "        vnum = len(parallels)\n",
    "        \n",
    "        # find coress-information        \n",
    "        dag = self.DAG[qid]\n",
    "        embeds = [] # length should be vnum-1, since no embedding for the source vertex\n",
    "        for i in range(1, vnum):\n",
    "            vkeyname = ''.join(['q', str(qid), 'v', str(i)])\n",
    "            embeds.append(self.embeddings[self.keys.index(vkeyname)])\n",
    "        \n",
    "        # make context\n",
    "        context = [row['pseudoInputBytesRate'],\n",
    "                   row['pseudoInputRecordsRate'],\n",
    "                   1 if row['isBP'] else 0]\n",
    "        \n",
    "        # make edges\n",
    "#         edges = {'src2op':[], 'op2op':[],}\n",
    "        src2op_edges = []\n",
    "        op2op_edges = []\n",
    "        for i in range(len(dag[0])):\n",
    "            s = dag[0][i]\n",
    "            t = dag[1][i]\n",
    "            if s == 0:\n",
    "                src2op_edges.append([s,t])\n",
    "            else:\n",
    "                op2op_edges.append([s,t])\n",
    "        edges = {\n",
    "            'src2op': [[e[0] for e in src2op_edges],\n",
    "                       [e[1] for e in src2op_edges]],\n",
    "            'op2op': [[e[0]-1 for e in op2op_edges],\n",
    "                      [e[1]-1 for e in op2op_edges]],\n",
    "        }\n",
    "        \n",
    "        # make nodes\n",
    "        nodes = {}\n",
    "        nodes['source'] = [parallels[0]]\n",
    "        vselects = []\n",
    "        for i in range(1, vnum):\n",
    "            vselects.append([\n",
    "                self.selectivities['true_selectivity_bytes'][(qid, i)],\n",
    "                self.selectivities['true_selectivity_records'][(qid, i)],\n",
    "            ])\n",
    "        nodes['operate'] = [\n",
    "            parallels[1:],\n",
    "            [e[0] for e in vselects],\n",
    "            [e[1] for e in vselects],\n",
    "            embeds,\n",
    "        ]\n",
    "        \n",
    "        # convert to tfgnn graph tensor\n",
    "        graph = make_graph_tensor(nodes=nodes, edges=edges, context=context)\n",
    "        \n",
    "        # write it down\n",
    "        self.single_writer(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "898beb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "amaker = graph_tensor_dataset_maker(embeddings, keys, DAG, selectivities,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d2f3b57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"context/bytes_input_rate\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 68266.671875\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"context/label_isBP\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"context/records_input_rate\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 1677.4000244140625\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"edges/op2op.#size\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 2\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"edges/op2op.#source\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "        value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"edges/op2op.#target\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "        value: 2\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"edges/src2op.#size\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"edges/src2op.#source\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"edges/src2op.#target\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"nodes/operate.#size\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 3\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"nodes/operate.bytes_selectivity\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.6753447651863098\n",
      "        value: 0.2418961226940155\n",
      "        value: 0.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"nodes/operate.parallelism\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 2\n",
      "        value: 2\n",
      "        value: 2\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"nodes/operate.records_selectivity\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.6912518739700317\n",
      "        value: 0.30498579144477844\n",
      "        value: 0.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"nodes/operate.utilization_embedding\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 1.1363179683685303\n",
      "        value: -8.713006973266602\n",
      "        value: -15.337414741516113\n",
      "        value: -29.117441177368164\n",
      "        value: -11.521270751953125\n",
      "        value: -10.092616081237793\n",
      "        value: 4.7440080642700195\n",
      "        value: 14.545109748840332\n",
      "        value: -31.407669067382812\n",
      "        value: -10.956951141357422\n",
      "        value: 17.856855392456055\n",
      "        value: -9.635259628295898\n",
      "        value: 21.878978729248047\n",
      "        value: -5.585473537445068\n",
      "        value: 9.310247421264648\n",
      "        value: 25.52617645263672\n",
      "        value: 25.809505462646484\n",
      "        value: -16.083894729614258\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"nodes/source.#size\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"nodes/source.parallelism\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 2\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "amaker.make(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ecabbcb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys.index('q4v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "157019e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeSet(features={}, sizes=[2], adjacency=Adjacency(source=('operate', <tf.Tensor: shape=(2,), dtype=tf.int32>), target=('operate', <tf.Tensor: shape=(2,), dtype=tf.int32>)))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = {'op2op':[[0, 1], [1, 2]]}\n",
    "\n",
    "tfgnn.EdgeSet.from_fields(\n",
    "    sizes=tf.constant([len(edges['op2op'][0])]),\n",
    "    adjacency=tfgnn.Adjacency.from_indices(\n",
    "    source=('operate', tf.constant(edges['op2op'][0])),\n",
    "    target=('operate', tf.constant(edges['op2op'][1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd5ed5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfgnn.create_graph_spec_f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
